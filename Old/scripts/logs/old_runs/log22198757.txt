WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/jet/home/mmisra/miniconda3/envs/benchmark/lib/python3.8/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/jet/home/mmisra/miniconda3/envs/benchmark/lib/python3.8/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
02/12/2024 19:49:43 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
02/12/2024 19:49:43 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/runs/Feb12_19-49-43_v010.ib.bridges2.psc.edu,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
output_dir=/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
02/12/2024 19:49:43 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, 16-bits training: False
Overwrite dataset info from restored data version if exists.
02/12/2024 19:49:44 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
02/12/2024 19:49:44 - INFO - datasets.info - Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
Found cached dataset glue (/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)
02/12/2024 19:49:45 - INFO - datasets.builder - Found cached dataset glue (/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)
Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
02/12/2024 19:49:45 - INFO - datasets.info - Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
[INFO|configuration_utils.py:729] 2024-02-12 19:49:45,361 >> loading configuration file config.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/config.json
[INFO|configuration_utils.py:792] 2024-02-12 19:49:45,363 >> Model config LlamaConfig {
  "_name_or_path": "datajuicer/LLaMA-1B-dj-refine-100B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "finetuning_task": "mrpc",
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5504,
  "max_position_embeddings": 2048,
  "max_sequence_length": 2048,
  "model_type": "llama",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_key_value_heads": 16,
  "pad_token_id": 32004,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:2029] 2024-02-12 19:49:45,395 >> loading file tokenizer.model from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/tokenizer.model
[INFO|tokenization_utils_base.py:2029] 2024-02-12 19:49:45,395 >> loading file tokenizer.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/tokenizer.json
[INFO|tokenization_utils_base.py:2029] 2024-02-12 19:49:45,395 >> loading file added_tokens.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/added_tokens.json
[INFO|tokenization_utils_base.py:2029] 2024-02-12 19:49:45,396 >> loading file special_tokens_map.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/special_tokens_map.json
[INFO|tokenization_utils_base.py:2029] 2024-02-12 19:49:45,396 >> loading file tokenizer_config.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/tokenizer_config.json
[WARNING|logging.py:314] 2024-02-12 19:49:45,520 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:314] 2024-02-12 19:49:45,521 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|modeling_utils.py:3259] 2024-02-12 19:49:45,663 >> loading weights file pytorch_model.bin from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/pytorch_model.bin
[WARNING|modeling_utils.py:3996] 2024-02-12 19:50:07,039 >> Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at datajuicer/LLaMA-1B-dj-refine-100B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|modeling_utils.py:3984] 2024-02-12 19:50:07,041 >> Some weights of the model checkpoint at datajuicer/LLaMA-1B-dj-refine-100B were not used when initializing LlamaForSequenceClassification: ['lm_head.weight']
- This IS expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3996] 2024-02-12 19:50:07,041 >> Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at datajuicer/LLaMA-1B-dj-refine-100B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-d53d7a09499f5bfb.arrow
02/12/2024 19:50:07 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-d53d7a09499f5bfb.arrow
Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-12e393c323965c42.arrow
02/12/2024 19:50:07 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-12e393c323965c42.arrow
Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-65fa5a7617106458.arrow
02/12/2024 19:50:07 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-65fa5a7617106458.arrow
02/12/2024 19:50:08 - INFO - __main__ - Sample 2619 of the training set: {'sentence1': 'The proceedings were taken up with prosecutors outlining their case against Amrozi , reading 33 pages of documents outlining allegations against him .', 'sentence2': 'Proceedings were taken up with prosecutors outlining their case against Amrozi , reading a 33-page accusation letter to the court .', 'label': 1, 'idx': 2916, 'input_ids': [32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 1, 450, 8469, 886, 892, 4586, 701, 411, 410, 3471, 29560, 714, 1915, 292, 1009, 1206, 2750, 1913, 307, 2526, 1919, 5183, 29871, 29941, 29941, 6515, 310, 10701, 714, 1915, 292, 16831, 800, 2750, 1075, 869, 1, 1019, 3947, 886, 892, 4586, 701, 411, 410, 3471, 29560, 714, 1915, 292, 1009, 1206, 2750, 1913, 307, 2526, 1919, 5183, 263, 29871, 29941, 29941, 29899, 3488, 26142, 362, 5497, 304, 278, 8973, 869], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
02/12/2024 19:50:08 - INFO - __main__ - Sample 456 of the training set: {'sentence1': "Chechen officials working for the Moscow-backed government are a frequent target for rebels and tension is running high ahead of next Sunday 's presidential election in war-torn Chechnya .", 'sentence2': "Officials in Chechnya 's Moscow-backed government are a frequent target for rebels , and tension is running high ahead of Sunday 's presidential election in the war-ravaged region .", 'label': 1, 'idx': 509, 'input_ids': [32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 1, 6561, 2724, 24921, 1985, 363, 278, 25820, 29899, 1627, 287, 5874, 526, 263, 17091, 3646, 363, 15121, 1379, 322, 260, 2673, 338, 2734, 1880, 14432, 310, 2446, 16340, 525, 29879, 6673, 616, 8271, 297, 1370, 29899, 29873, 1398, 6561, 305, 1460, 29874, 869, 1, 10564, 29879, 297, 6561, 305, 1460, 29874, 525, 29879, 25820, 29899, 1627, 287, 5874, 526, 263, 17091, 3646, 363, 15121, 1379, 1919, 322, 260, 2673, 338, 2734, 1880, 14432, 310, 16340, 525, 29879, 6673, 616, 8271, 297, 278, 1370, 29899, 5705, 4063, 5120, 869], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
02/12/2024 19:50:08 - INFO - __main__ - Sample 102 of the training set: {'sentence1': "Standard & Poor 's 500 stock index futures declined 4.40 points to 983.50 , while Nasdaq futures fell 6.5 points to 1,206.50 .", 'sentence2': "The Standard & Poor 's 500 Index was up 1.75 points , or 0.18 percent , to 977.68 .", 'label': 0, 'idx': 116, 'input_ids': [32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 1, 10117, 669, 3929, 272, 525, 29879, 29871, 29945, 29900, 29900, 10961, 2380, 3105, 1973, 4845, 1312, 29871, 29946, 29889, 29946, 29900, 3291, 304, 29871, 29929, 29947, 29941, 29889, 29945, 29900, 1919, 1550, 22318, 1388, 29939, 3105, 1973, 8379, 29871, 29953, 29889, 29945, 3291, 304, 29871, 29896, 29892, 29906, 29900, 29953, 29889, 29945, 29900, 869, 1, 450, 10117, 669, 3929, 272, 525, 29879, 29871, 29945, 29900, 29900, 11374, 471, 701, 29871, 29896, 29889, 29955, 29945, 3291, 1919, 470, 29871, 29900, 29889, 29896, 29947, 10151, 1919, 304, 29871, 29929, 29955, 29955, 29889, 29953, 29947, 869], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
02/12/2024 19:50:08 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:737] 2024-02-12 19:50:11,760 >> The following columns in the training set don't have a corresponding argument in `LlamaForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `LlamaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1747] 2024-02-12 19:50:11,925 >> ***** Running training *****
[INFO|trainer.py:1748] 2024-02-12 19:50:11,926 >>   Num examples = 3,668
[INFO|trainer.py:1749] 2024-02-12 19:50:11,926 >>   Num Epochs = 3
[INFO|trainer.py:1750] 2024-02-12 19:50:11,927 >>   Instantaneous batch size per device = 8
[INFO|trainer.py:1753] 2024-02-12 19:50:11,927 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:1754] 2024-02-12 19:50:11,927 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1755] 2024-02-12 19:50:11,927 >>   Total optimization steps = 690
[INFO|trainer.py:1756] 2024-02-12 19:50:11,928 >>   Number of trainable parameters = 1,280,153,600
  0%|          | 0/690 [00:00<?, ?it/s][rank1]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/690 [00:02<34:21,  2.99s/it]  0%|          | 2/690 [00:03<19:18,  1.68s/it]  0%|          | 3/690 [00:04<14:59,  1.31s/it]  1%|          | 4/690 [00:05<12:56,  1.13s/it]  1%|          | 5/690 [00:06<11:46,  1.03s/it]  1%|          | 6/690 [00:07<11:13,  1.01it/s]  1%|          | 7/690 [00:08<10:43,  1.06it/s]  1%|          | 8/690 [00:08<10:22,  1.10it/s]  1%|▏         | 9/690 [00:09<10:09,  1.12it/s]  1%|▏         | 10/690 [00:10<10:04,  1.13it/s]  2%|▏         | 11/690 [00:11<09:53,  1.14it/s]  2%|▏         | 12/690 [00:12<09:47,  1.15it/s]  2%|▏         | 13/690 [00:13<09:45,  1.16it/s]  2%|▏         | 14/690 [00:14<09:47,  1.15it/s]  2%|▏         | 15/690 [00:14<09:44,  1.15it/s]  2%|▏         | 16/690 [00:15<09:43,  1.16it/s]  2%|▏         | 17/690 [00:16<09:45,  1.15it/s]  3%|▎         | 18/690 [00:17<09:43,  1.15it/s]  3%|▎         | 19/690 [00:18<09:37,  1.16it/s]  3%|▎         | 20/690 [00:19<09:35,  1.16it/s]  3%|▎         | 21/690 [00:20<09:35,  1.16it/s]  3%|▎         | 22/690 [00:20<09:36,  1.16it/s]  3%|▎         | 23/690 [00:21<09:32,  1.16it/s]  3%|▎         | 24/690 [00:22<09:34,  1.16it/s]  4%|▎         | 25/690 [00:23<09:32,  1.16it/s]  4%|▍         | 26/690 [00:24<09:35,  1.15it/s]  4%|▍         | 27/690 [00:25<09:32,  1.16it/s]  4%|▍         | 28/690 [00:26<09:30,  1.16it/s]  4%|▍         | 29/690 [00:27<09:31,  1.16it/s]  4%|▍         | 30/690 [00:27<09:29,  1.16it/s]  4%|▍         | 31/690 [00:28<09:32,  1.15it/s]  5%|▍         | 32/690 [00:29<09:28,  1.16it/s]  5%|▍         | 33/690 [00:30<09:25,  1.16it/s]  5%|▍         | 34/690 [00:31<09:25,  1.16it/s]  5%|▌         | 35/690 [00:32<09:22,  1.16it/s]  5%|▌         | 36/690 [00:33<09:20,  1.17it/s]  5%|▌         | 37/690 [00:33<09:18,  1.17it/s]  6%|▌         | 38/690 [00:34<09:23,  1.16it/s]  6%|▌         | 39/690 [00:35<09:23,  1.15it/s]  6%|▌         | 40/690 [00:36<09:22,  1.16it/s]  6%|▌         | 41/690 [00:37<09:18,  1.16it/s]  6%|▌         | 42/690 [00:38<09:16,  1.17it/s]  6%|▌         | 43/690 [00:39<09:15,  1.16it/s]  6%|▋         | 44/690 [00:39<09:13,  1.17it/s]  7%|▋         | 45/690 [00:40<09:16,  1.16it/s]  7%|▋         | 46/690 [00:41<09:15,  1.16it/s]  7%|▋         | 47/690 [00:42<09:11,  1.17it/s]  7%|▋         | 48/690 [00:43<09:16,  1.15it/s]  7%|▋         | 49/690 [00:44<09:11,  1.16it/s]  7%|▋         | 50/690 [00:45<09:13,  1.16it/s]  7%|▋         | 51/690 [00:45<09:08,  1.17it/s]  8%|▊         | 52/690 [00:46<09:08,  1.16it/s]  8%|▊         | 53/690 [00:47<09:10,  1.16it/s]  8%|▊         | 54/690 [00:48<09:12,  1.15it/s]  8%|▊         | 55/690 [00:49<09:08,  1.16it/s]  8%|▊         | 56/690 [00:50<09:09,  1.15it/s]  8%|▊         | 57/690 [00:51<09:09,  1.15it/s]  8%|▊         | 58/690 [00:52<09:06,  1.16it/s]  9%|▊         | 59/690 [00:52<09:02,  1.16it/s]  9%|▊         | 60/690 [00:53<09:03,  1.16it/s]  9%|▉         | 61/690 [00:54<09:02,  1.16it/s]  9%|▉         | 62/690 [00:55<09:02,  1.16it/s]  9%|▉         | 63/690 [00:56<08:58,  1.16it/s]  9%|▉         | 64/690 [00:57<08:58,  1.16it/s]  9%|▉         | 65/690 [00:58<08:58,  1.16it/s] 10%|▉         | 66/690 [00:58<08:57,  1.16it/s] 10%|▉         | 67/690 [00:59<08:52,  1.17it/s] 10%|▉         | 68/690 [01:00<08:51,  1.17it/s] 10%|█         | 69/690 [01:01<08:53,  1.16it/s] 10%|█         | 70/690 [01:02<08:57,  1.15it/s] 10%|█         | 71/690 [01:03<08:57,  1.15it/s] 10%|█         | 72/690 [01:04<08:52,  1.16it/s] 11%|█         | 73/690 [01:04<08:52,  1.16it/s] 11%|█         | 74/690 [01:05<08:52,  1.16it/s] 11%|█         | 75/690 [01:06<08:54,  1.15it/s] 11%|█         | 76/690 [01:07<08:49,  1.16it/s] 11%|█         | 77/690 [01:08<08:48,  1.16it/s] 11%|█▏        | 78/690 [01:09<08:50,  1.15it/s] 11%|█▏        | 79/690 [01:10<08:47,  1.16it/s] 12%|█▏        | 80/690 [01:11<08:49,  1.15it/s] 12%|█▏        | 81/690 [01:11<08:47,  1.16it/s] 12%|█▏        | 82/690 [01:12<08:45,  1.16it/s] 12%|█▏        | 83/690 [01:13<08:46,  1.15it/s] 12%|█▏        | 84/690 [01:14<08:45,  1.15it/s] 12%|█▏        | 85/690 [01:15<08:41,  1.16it/s] 12%|█▏        | 86/690 [01:16<08:42,  1.16it/s] 13%|█▎        | 87/690 [01:17<08:44,  1.15it/s] 13%|█▎        | 88/690 [01:17<08:41,  1.16it/s] 13%|█▎        | 89/690 [01:18<08:38,  1.16it/s] 13%|█▎        | 90/690 [01:19<08:35,  1.16it/s] 13%|█▎        | 91/690 [01:20<08:35,  1.16it/s] 13%|█▎        | 92/690 [01:21<08:37,  1.16it/s] 13%|█▎        | 93/690 [01:22<08:32,  1.17it/s] 14%|█▎        | 94/690 [01:23<08:33,  1.16it/s] 14%|█▍        | 95/690 [01:23<08:31,  1.16it/s] 14%|█▍        | 96/690 [01:24<08:29,  1.17it/s] 14%|█▍        | 97/690 [01:25<08:30,  1.16it/s] 14%|█▍        | 98/690 [01:26<08:31,  1.16it/s] 14%|█▍        | 99/690 [01:27<08:29,  1.16it/s] 14%|█▍        | 100/690 [01:28<08:28,  1.16it/s] 15%|█▍        | 101/690 [01:29<08:27,  1.16it/s] 15%|█▍        | 102/690 [01:29<08:23,  1.17it/s] 15%|█▍        | 103/690 [01:30<08:24,  1.16it/s] 15%|█▌        | 104/690 [01:31<08:24,  1.16it/s] 15%|█▌        | 105/690 [01:32<08:24,  1.16it/s] 15%|█▌        | 106/690 [01:33<08:25,  1.15it/s] 16%|█▌        | 107/690 [01:34<08:28,  1.15it/s] 16%|█▌        | 108/690 [01:35<08:22,  1.16it/s] 16%|█▌        | 109/690 [01:36<08:22,  1.16it/s] 16%|█▌        | 110/690 [01:36<08:21,  1.16it/s] 16%|█▌        | 111/690 [01:37<08:16,  1.17it/s] 16%|█▌        | 112/690 [01:38<08:20,  1.16it/s] 16%|█▋        | 113/690 [01:39<08:18,  1.16it/s] 17%|█▋        | 114/690 [01:40<08:16,  1.16it/s] 17%|█▋        | 115/690 [01:41<08:15,  1.16it/s] 17%|█▋        | 116/690 [01:42<08:15,  1.16it/s] 17%|█▋        | 117/690 [01:42<08:13,  1.16it/s] 17%|█▋        | 118/690 [01:43<08:15,  1.15it/s] 17%|█▋        | 119/690 [01:44<08:13,  1.16it/s] 17%|█▋        | 120/690 [01:45<08:10,  1.16it/s] 18%|█▊        | 121/690 [01:46<08:12,  1.15it/s] 18%|█▊        | 122/690 [01:47<08:10,  1.16it/s] 18%|█▊        | 123/690 [01:48<08:07,  1.16it/s] 18%|█▊        | 124/690 [01:48<08:07,  1.16it/s] 18%|█▊        | 125/690 [01:49<08:06,  1.16it/s] 18%|█▊        | 126/690 [01:50<08:05,  1.16it/s] 18%|█▊        | 127/690 [01:51<08:07,  1.15it/s] 19%|█▊        | 128/690 [01:52<08:06,  1.16it/s] 19%|█▊        | 129/690 [01:53<08:05,  1.16it/s] 19%|█▉        | 130/690 [01:54<08:06,  1.15it/s] 19%|█▉        | 131/690 [01:55<08:02,  1.16it/s] 19%|█▉        | 132/690 [01:55<07:59,  1.16it/s] 19%|█▉        | 133/690 [01:56<07:59,  1.16it/s] 19%|█▉        | 134/690 [01:57<07:56,  1.17it/s] 20%|█▉        | 135/690 [01:58<07:58,  1.16it/s] 20%|█▉        | 136/690 [01:59<07:57,  1.16it/s] 20%|█▉        | 137/690 [02:00<07:52,  1.17it/s] 20%|██        | 138/690 [02:01<07:56,  1.16it/s] 20%|██        | 139/690 [02:01<07:54,  1.16it/s] 20%|██        | 140/690 [02:02<07:55,  1.16it/s] 20%|██        | 141/690 [02:03<07:53,  1.16it/s] 21%|██        | 142/690 [02:04<07:51,  1.16it/s] 21%|██        | 143/690 [02:05<07:51,  1.16it/s] 21%|██        | 144/690 [02:06<07:48,  1.17it/s] 21%|██        | 145/690 [02:07<07:49,  1.16it/s] 21%|██        | 146/690 [02:07<07:46,  1.17it/s] 21%|██▏       | 147/690 [02:08<07:43,  1.17it/s] 21%|██▏       | 148/690 [02:09<07:45,  1.16it/s] 22%|██▏       | 149/690 [02:10<07:46,  1.16it/s] 22%|██▏       | 150/690 [02:11<07:43,  1.16it/s] 22%|██▏       | 151/690 [02:12<07:44,  1.16it/s] 22%|██▏       | 152/690 [02:13<07:40,  1.17it/s] 22%|██▏       | 153/690 [02:13<07:43,  1.16it/s] 22%|██▏       | 154/690 [02:14<07:42,  1.16it/s] 22%|██▏       | 155/690 [02:15<07:41,  1.16it/s] 23%|██▎       | 156/690 [02:16<07:39,  1.16it/s] 23%|██▎       | 157/690 [02:17<07:38,  1.16it/s] 23%|██▎       | 158/690 [02:18<07:39,  1.16it/s] 23%|██▎       | 159/690 [02:19<07:37,  1.16it/s] 23%|██▎       | 160/690 [02:19<07:36,  1.16it/s] 23%|██▎       | 161/690 [02:20<07:33,  1.17it/s] 23%|██▎       | 162/690 [02:21<07:34,  1.16it/s] 24%|██▎       | 163/690 [02:22<07:31,  1.17it/s] 24%|██▍       | 164/690 [02:23<07:31,  1.17it/s] 24%|██▍       | 165/690 [02:24<07:32,  1.16it/s] 24%|██▍       | 166/690 [02:25<07:29,  1.17it/s] 24%|██▍       | 167/690 [02:25<07:29,  1.16it/s] 24%|██▍       | 168/690 [02:26<07:33,  1.15it/s] 24%|██▍       | 169/690 [02:27<07:28,  1.16it/s] 25%|██▍       | 170/690 [02:28<07:27,  1.16it/s] 25%|██▍       | 171/690 [02:29<07:26,  1.16it/s] 25%|██▍       | 172/690 [02:30<07:29,  1.15it/s] 25%|██▌       | 173/690 [02:31<07:28,  1.15it/s] 25%|██▌       | 174/690 [02:32<07:25,  1.16it/s] 25%|██▌       | 175/690 [02:32<07:26,  1.15it/s] 26%|██▌       | 176/690 [02:33<07:24,  1.16it/s] 26%|██▌       | 177/690 [02:34<07:23,  1.16it/s] 26%|██▌       | 178/690 [02:35<07:19,  1.16it/s] 26%|██▌       | 179/690 [02:36<07:18,  1.16it/s] 26%|██▌       | 180/690 [02:37<07:18,  1.16it/s] 26%|██▌       | 181/690 [02:38<07:20,  1.15it/s] 26%|██▋       | 182/690 [02:38<07:16,  1.16it/s] 27%|██▋       | 183/690 [02:39<07:13,  1.17it/s] 27%|██▋       | 184/690 [02:40<07:13,  1.17it/s] 27%|██▋       | 185/690 [02:41<07:11,  1.17it/s] 27%|██▋       | 186/690 [02:42<07:13,  1.16it/s] 27%|██▋       | 187/690 [02:43<07:10,  1.17it/s] 27%|██▋       | 188/690 [02:44<07:12,  1.16it/s] 27%|██▋       | 189/690 [02:44<07:13,  1.16it/s] 28%|██▊       | 190/690 [02:45<07:07,  1.17it/s] 28%|██▊       | 191/690 [02:46<07:06,  1.17it/s] 28%|██▊       | 192/690 [02:47<07:07,  1.17it/s] 28%|██▊       | 193/690 [02:48<07:06,  1.17it/s] 28%|██▊       | 194/690 [02:49<07:07,  1.16it/s] 28%|██▊       | 195/690 [02:50<07:07,  1.16it/s] 28%|██▊       | 196/690 [02:50<07:04,  1.16it/s] 29%|██▊       | 197/690 [02:51<07:04,  1.16it/s] 29%|██▊       | 198/690 [02:52<07:05,  1.16it/s] 29%|██▉       | 199/690 [02:53<07:07,  1.15it/s] 29%|██▉       | 200/690 [02:54<07:04,  1.16it/s] 29%|██▉       | 201/690 [02:55<07:00,  1.16it/s] 29%|██▉       | 202/690 [02:56<06:59,  1.16it/s] 29%|██▉       | 203/690 [02:57<06:59,  1.16it/s] 30%|██▉       | 204/690 [02:57<06:58,  1.16it/s] 30%|██▉       | 205/690 [02:58<06:57,  1.16it/s] 30%|██▉       | 206/690 [02:59<06:53,  1.17it/s] 30%|███       | 207/690 [03:00<06:54,  1.17it/s] 30%|███       | 208/690 [03:01<06:55,  1.16it/s] 30%|███       | 209/690 [03:02<06:53,  1.16it/s] 30%|███       | 210/690 [03:03<06:51,  1.17it/s] 31%|███       | 211/690 [03:03<06:50,  1.17it/s] 31%|███       | 212/690 [03:04<06:52,  1.16it/s] 31%|███       | 213/690 [03:05<06:51,  1.16it/s] 31%|███       | 214/690 [03:06<06:52,  1.15it/s] 31%|███       | 215/690 [03:07<06:51,  1.15it/s] 31%|███▏      | 216/690 [03:08<06:50,  1.15it/s] 31%|███▏      | 217/690 [03:09<06:49,  1.15it/s] 32%|███▏      | 218/690 [03:09<06:46,  1.16it/s] 32%|███▏      | 219/690 [03:10<06:50,  1.15it/s] 32%|███▏      | 220/690 [03:11<06:46,  1.16it/s] 32%|███▏      | 221/690 [03:12<06:46,  1.15it/s] 32%|███▏      | 222/690 [03:13<06:44,  1.16it/s] 32%|███▏      | 223/690 [03:14<06:42,  1.16it/s] 32%|███▏      | 224/690 [03:15<06:43,  1.16it/s] 33%|███▎      | 225/690 [03:15<06:41,  1.16it/s] 33%|███▎      | 226/690 [03:16<06:40,  1.16it/s] 33%|███▎      | 227/690 [03:17<06:37,  1.16it/s] 33%|███▎      | 228/690 [03:18<06:36,  1.17it/s] 33%|███▎      | 229/690 [03:19<06:39,  1.15it/s] 33%|███▎      | 230/690 [03:20<06:37,  1.16it/s] 33%|███▎      | 231/690 [03:21<06:35,  1.16it/s] 34%|███▎      | 232/690 [03:22<06:33,  1.16it/s] 34%|███▍      | 233/690 [03:22<06:34,  1.16it/s] 34%|███▍      | 234/690 [03:23<06:35,  1.15it/s] 34%|███▍      | 235/690 [03:24<06:34,  1.15it/s] 34%|███▍      | 236/690 [03:25<06:33,  1.15it/s] 34%|███▍      | 237/690 [03:26<06:32,  1.15it/s] 34%|███▍      | 238/690 [03:27<06:31,  1.16it/s] 35%|███▍      | 239/690 [03:28<06:29,  1.16it/s] 35%|███▍      | 240/690 [03:28<06:28,  1.16it/s] 35%|███▍      | 241/690 [03:29<06:28,  1.16it/s] 35%|███▌      | 242/690 [03:30<06:26,  1.16it/s] 35%|███▌      | 243/690 [03:31<06:26,  1.16it/s] 35%|███▌      | 244/690 [03:32<06:26,  1.15it/s] 36%|███▌      | 245/690 [03:33<06:25,  1.15it/s] 36%|███▌      | 246/690 [03:34<06:26,  1.15it/s] 36%|███▌      | 247/690 [03:35<06:23,  1.16it/s] 36%|███▌      | 248/690 [03:35<06:19,  1.16it/s] 36%|███▌      | 249/690 [03:36<06:21,  1.16it/s] 36%|███▌      | 250/690 [03:37<06:19,  1.16it/s] 36%|███▋      | 251/690 [03:38<06:21,  1.15it/s] 37%|███▋      | 252/690 [03:39<06:18,  1.16it/s] 37%|███▋      | 253/690 [03:40<06:18,  1.16it/s] 37%|███▋      | 254/690 [03:41<06:17,  1.15it/s] 37%|███▋      | 255/690 [03:41<06:15,  1.16it/s] 37%|███▋      | 256/690 [03:42<06:14,  1.16it/s] 37%|███▋      | 257/690 [03:43<06:13,  1.16it/s] 37%|███▋      | 258/690 [03:44<06:13,  1.16it/s] 38%|███▊      | 259/690 [03:45<06:11,  1.16it/s] 38%|███▊      | 260/690 [03:46<06:09,  1.16it/s] 38%|███▊      | 261/690 [03:47<06:07,  1.17it/s] 38%|███▊      | 262/690 [03:47<06:11,  1.15it/s] 38%|███▊      | 263/690 [03:48<06:07,  1.16it/s] 38%|███▊      | 264/690 [03:49<06:09,  1.15it/s] 38%|███▊      | 265/690 [03:50<06:08,  1.15it/s] 39%|███▊      | 266/690 [03:51<06:06,  1.16it/s] 39%|███▊      | 267/690 [03:52<06:05,  1.16it/s] 39%|███▉      | 268/690 [03:53<06:07,  1.15it/s] 39%|███▉      | 269/690 [03:54<06:04,  1.16it/s] 39%|███▉      | 270/690 [03:54<06:05,  1.15it/s] 39%|███▉      | 271/690 [03:55<06:03,  1.15it/s] 39%|███▉      | 272/690 [03:56<06:01,  1.15it/s] 40%|███▉      | 273/690 [03:57<06:01,  1.15it/s] 40%|███▉      | 274/690 [03:58<05:59,  1.16it/s] 40%|███▉      | 275/690 [03:59<05:59,  1.16it/s] 40%|████      | 276/690 [04:00<05:57,  1.16it/s] 40%|████      | 277/690 [04:00<05:56,  1.16it/s] 40%|████      | 278/690 [04:01<05:56,  1.16it/s] 40%|████      | 279/690 [04:02<05:56,  1.15it/s] 41%|████      | 280/690 [04:03<05:54,  1.16it/s] 41%|████      | 281/690 [04:04<05:51,  1.16it/s] 41%|████      | 282/690 [04:05<05:50,  1.16it/s] 41%|████      | 283/690 [04:06<05:49,  1.16it/s] 41%|████      | 284/690 [04:06<05:50,  1.16it/s] 41%|████▏     | 285/690 [04:07<05:51,  1.15it/s] 41%|████▏     | 286/690 [04:08<05:48,  1.16it/s] 42%|████▏     | 287/690 [04:09<05:48,  1.15it/s] 42%|████▏     | 288/690 [04:10<05:48,  1.15it/s] 42%|████▏     | 289/690 [04:11<05:47,  1.15it/s] 42%|████▏     | 290/690 [04:12<05:47,  1.15it/s] 42%|████▏     | 291/690 [04:13<05:47,  1.15it/s] 42%|████▏     | 292/690 [04:13<05:44,  1.15it/s] 42%|████▏     | 293/690 [04:14<05:43,  1.16it/s] 43%|████▎     | 294/690 [04:15<05:43,  1.15it/s] 43%|████▎     | 295/690 [04:16<05:40,  1.16it/s] 43%|████▎     | 296/690 [04:17<05:40,  1.16it/s] 43%|████▎     | 297/690 [04:18<05:38,  1.16it/s] 43%|████▎     | 298/690 [04:19<05:38,  1.16it/s] 43%|████▎     | 299/690 [04:19<05:36,  1.16it/s] 43%|████▎     | 300/690 [04:20<05:36,  1.16it/s] 44%|████▎     | 301/690 [04:21<05:35,  1.16it/s] 44%|████▍     | 302/690 [04:22<05:36,  1.15it/s] 44%|████▍     | 303/690 [04:23<05:35,  1.15it/s] 44%|████▍     | 304/690 [04:24<05:33,  1.16it/s] 44%|████▍     | 305/690 [04:25<05:32,  1.16it/s] 44%|████▍     | 306/690 [04:26<05:31,  1.16it/s] 44%|████▍     | 307/690 [04:26<05:29,  1.16it/s] 45%|████▍     | 308/690 [04:27<05:27,  1.17it/s] 45%|████▍     | 309/690 [04:28<05:26,  1.17it/s] 45%|████▍     | 310/690 [04:29<05:26,  1.16it/s] 45%|████▌     | 311/690 [04:30<05:27,  1.16it/s] 45%|████▌     | 312/690 [04:31<05:25,  1.16it/s] 45%|████▌     | 313/690 [04:32<05:27,  1.15it/s] 46%|████▌     | 314/690 [04:32<05:26,  1.15it/s] 46%|████▌     | 315/690 [04:33<05:25,  1.15it/s] 46%|████▌     | 316/690 [04:34<05:23,  1.16it/s] 46%|████▌     | 317/690 [04:35<05:22,  1.16it/s] 46%|████▌     | 318/690 [04:36<05:21,  1.16it/s] 46%|████▌     | 319/690 [04:37<05:19,  1.16it/s] 46%|████▋     | 320/690 [04:38<05:18,  1.16it/s] 47%|████▋     | 321/690 [04:38<05:18,  1.16it/s] 47%|████▋     | 322/690 [04:39<05:16,  1.16it/s] 47%|████▋     | 323/690 [04:40<05:17,  1.16it/s] 47%|████▋     | 324/690 [04:41<05:18,  1.15it/s] 47%|████▋     | 325/690 [04:42<05:14,  1.16it/s] 47%|████▋     | 326/690 [04:43<05:14,  1.16it/s] 47%|████▋     | 327/690 [04:44<05:13,  1.16it/s] 48%|████▊     | 328/690 [04:45<05:14,  1.15it/s] 48%|████▊     | 329/690 [04:45<05:12,  1.16it/s] 48%|████▊     | 330/690 [04:46<05:10,  1.16it/s] 48%|████▊     | 331/690 [04:47<05:11,  1.15it/s] 48%|████▊     | 332/690 [04:48<05:08,  1.16it/s] 48%|████▊     | 333/690 [04:49<05:07,  1.16it/s] 48%|████▊     | 334/690 [04:50<05:05,  1.17it/s] 49%|████▊     | 335/690 [04:51<05:06,  1.16it/s] 49%|████▊     | 336/690 [04:51<05:04,  1.16it/s] 49%|████▉     | 337/690 [04:52<05:03,  1.16it/s] 49%|████▉     | 338/690 [04:53<05:04,  1.16it/s] 49%|████▉     | 339/690 [04:54<05:04,  1.15it/s] 49%|████▉     | 340/690 [04:55<05:02,  1.16it/s] 49%|████▉     | 341/690 [04:56<05:03,  1.15it/s] 50%|████▉     | 342/690 [04:57<05:01,  1.16it/s] 50%|████▉     | 343/690 [04:57<05:02,  1.15it/s] 50%|████▉     | 344/690 [04:58<04:59,  1.15it/s] 50%|█████     | 345/690 [04:59<04:57,  1.16it/s] 50%|█████     | 346/690 [05:00<04:59,  1.15it/s] 50%|█████     | 347/690 [05:01<04:58,  1.15it/s] 50%|█████     | 348/690 [05:02<04:56,  1.15it/s] 51%|█████     | 349/690 [05:03<04:57,  1.15it/s] 51%|█████     | 350/690 [05:04<04:55,  1.15it/s] 51%|█████     | 351/690 [05:04<04:51,  1.16it/s] 51%|█████     | 352/690 [05:05<04:52,  1.16it/s] 51%|█████     | 353/690 [05:06<04:52,  1.15it/s] 51%|█████▏    | 354/690 [05:07<04:48,  1.16it/s] 51%|█████▏    | 355/690 [05:08<04:50,  1.16it/s] 52%|█████▏    | 356/690 [05:09<04:51,  1.15it/s] 52%|█████▏    | 357/690 [05:10<04:47,  1.16it/s] 52%|█████▏    | 358/690 [05:10<04:47,  1.15it/s] 52%|█████▏    | 359/690 [05:11<04:46,  1.16it/s] 52%|█████▏    | 360/690 [05:12<04:43,  1.16it/s] 52%|█████▏    | 361/690 [05:13<04:44,  1.16it/s] 52%|█████▏    | 362/690 [05:14<04:43,  1.16it/s] 53%|█████▎    | 363/690 [05:15<04:41,  1.16it/s] 53%|█████▎    | 364/690 [05:16<04:42,  1.16it/s] 53%|█████▎    | 365/690 [05:17<04:43,  1.15it/s] 53%|█████▎    | 366/690 [05:17<04:43,  1.14it/s] 53%|█████▎    | 367/690 [05:18<04:42,  1.14it/s] 53%|█████▎    | 368/690 [05:19<04:39,  1.15it/s] 53%|█████▎    | 369/690 [05:20<04:39,  1.15it/s] 54%|█████▎    | 370/690 [05:21<04:37,  1.15it/s] 54%|█████▍    | 371/690 [05:22<04:36,  1.15it/s] 54%|█████▍    | 372/690 [05:23<04:37,  1.15it/s] 54%|█████▍    | 373/690 [05:23<04:35,  1.15it/s] 54%|█████▍    | 374/690 [05:24<04:34,  1.15it/s] 54%|█████▍    | 375/690 [05:25<04:35,  1.14it/s] 54%|█████▍    | 376/690 [05:26<04:31,  1.16it/s] 55%|█████▍    | 377/690 [05:27<04:31,  1.15it/s] 55%|█████▍    | 378/690 [05:28<04:30,  1.15it/s] 55%|█████▍    | 379/690 [05:29<04:29,  1.15it/s] 55%|█████▌    | 380/690 [05:30<04:29,  1.15it/s] 55%|█████▌    | 381/690 [05:30<04:26,  1.16it/s] 55%|█████▌    | 382/690 [05:31<04:25,  1.16it/s] 56%|█████▌    | 383/690 [05:32<04:26,  1.15it/s] 56%|█████▌    | 384/690 [05:33<04:24,  1.16it/s] 56%|█████▌    | 385/690 [05:34<04:23,  1.16it/s] 56%|█████▌    | 386/690 [05:35<04:21,  1.16it/s] 56%|█████▌    | 387/690 [05:36<04:22,  1.15it/s] 56%|█████▌    | 388/690 [05:36<04:19,  1.16it/s] 56%|█████▋    | 389/690 [05:37<04:18,  1.16it/s] 57%|█████▋    | 390/690 [05:38<04:18,  1.16it/s] 57%|█████▋    | 391/690 [05:39<04:18,  1.15it/s] 57%|█████▋    | 392/690 [05:40<04:17,  1.16it/s] 57%|█████▋    | 393/690 [05:41<04:15,  1.16it/s] 57%|█████▋    | 394/690 [05:42<04:15,  1.16it/s] 57%|█████▋    | 395/690 [05:43<04:14,  1.16it/s] 57%|█████▋    | 396/690 [05:43<04:14,  1.16it/s] 58%|█████▊    | 397/690 [05:44<04:13,  1.16it/s] 58%|█████▊    | 398/690 [05:45<04:12,  1.16it/s] 58%|█████▊    | 399/690 [05:46<04:11,  1.16it/s] 58%|█████▊    | 400/690 [05:47<04:08,  1.17it/s] 58%|█████▊    | 401/690 [05:48<04:09,  1.16it/s] 58%|█████▊    | 402/690 [05:49<04:09,  1.16it/s] 58%|█████▊    | 403/690 [05:49<04:08,  1.15it/s] 59%|█████▊    | 404/690 [05:50<04:06,  1.16it/s] 59%|█████▊    | 405/690 [05:51<04:05,  1.16it/s] 59%|█████▉    | 406/690 [05:52<04:03,  1.17it/s] 59%|█████▉    | 407/690 [05:53<04:04,  1.16it/s] 59%|█████▉    | 408/690 [05:54<04:03,  1.16it/s] 59%|█████▉    | 409/690 [05:55<04:00,  1.17it/s] 59%|█████▉    | 410/690 [05:55<04:00,  1.16it/s] 60%|█████▉    | 411/690 [05:56<04:00,  1.16it/s] 60%|█████▉    | 412/690 [05:57<03:59,  1.16it/s] 60%|█████▉    | 413/690 [05:58<04:00,  1.15it/s] 60%|██████    | 414/690 [05:59<03:58,  1.16it/s] 60%|██████    | 415/690 [06:00<03:57,  1.16it/s] 60%|██████    | 416/690 [06:01<03:56,  1.16it/s] 60%|██████    | 417/690 [06:01<03:54,  1.16it/s] 61%|██████    | 418/690 [06:02<03:54,  1.16it/s] 61%|██████    | 419/690 [06:03<03:54,  1.16it/s] 61%|██████    | 420/690 [06:04<03:54,  1.15it/s] 61%|██████    | 421/690 [06:05<03:51,  1.16it/s] 61%|██████    | 422/690 [06:06<03:51,  1.16it/s] 61%|██████▏   | 423/690 [06:07<03:50,  1.16it/s] 61%|██████▏   | 424/690 [06:08<03:50,  1.15it/s] 62%|██████▏   | 425/690 [06:08<03:48,  1.16it/s] 62%|██████▏   | 426/690 [06:09<03:48,  1.16it/s] 62%|██████▏   | 427/690 [06:10<03:49,  1.15it/s] 62%|██████▏   | 428/690 [06:11<03:46,  1.15it/s] 62%|██████▏   | 429/690 [06:12<03:46,  1.15it/s] 62%|██████▏   | 430/690 [06:13<03:45,  1.15it/s] 62%|██████▏   | 431/690 [06:14<03:43,  1.16it/s] 63%|██████▎   | 432/690 [06:14<03:41,  1.16it/s] 63%|██████▎   | 433/690 [06:15<03:41,  1.16it/s] 63%|██████▎   | 434/690 [06:16<03:39,  1.17it/s] 63%|██████▎   | 435/690 [06:17<03:39,  1.16it/s] 63%|██████▎   | 436/690 [06:18<03:39,  1.16it/s] 63%|██████▎   | 437/690 [06:19<03:38,  1.16it/s] 63%|██████▎   | 438/690 [06:20<03:38,  1.15it/s] 64%|██████▎   | 439/690 [06:21<03:36,  1.16it/s] 64%|██████▍   | 440/690 [06:21<03:34,  1.16it/s] 64%|██████▍   | 441/690 [06:22<03:35,  1.16it/s] 64%|██████▍   | 442/690 [06:23<03:35,  1.15it/s] 64%|██████▍   | 443/690 [06:24<03:32,  1.16it/s] 64%|██████▍   | 444/690 [06:25<03:32,  1.16it/s] 64%|██████▍   | 445/690 [06:26<03:31,  1.16it/s] 65%|██████▍   | 446/690 [06:27<03:30,  1.16it/s] 65%|██████▍   | 447/690 [06:27<03:28,  1.16it/s] 65%|██████▍   | 448/690 [06:28<03:27,  1.16it/s] 65%|██████▌   | 449/690 [06:29<03:28,  1.16it/s] 65%|██████▌   | 450/690 [06:30<03:26,  1.16it/s] 65%|██████▌   | 451/690 [06:31<03:26,  1.16it/s] 66%|██████▌   | 452/690 [06:32<03:25,  1.16it/s] 66%|██████▌   | 453/690 [06:33<03:25,  1.15it/s] 66%|██████▌   | 454/690 [06:33<03:23,  1.16it/s] 66%|██████▌   | 455/690 [06:34<03:24,  1.15it/s] 66%|██████▌   | 456/690 [06:35<03:21,  1.16it/s] 66%|██████▌   | 457/690 [06:36<03:20,  1.16it/s] 66%|██████▋   | 458/690 [06:37<03:19,  1.16it/s] 67%|██████▋   | 459/690 [06:38<03:19,  1.16it/s] 67%|██████▋   | 460/690 [06:39<03:18,  1.16it/s] 67%|██████▋   | 461/690 [06:39<03:17,  1.16it/s] 67%|██████▋   | 462/690 [06:40<03:16,  1.16it/s] 67%|██████▋   | 463/690 [06:41<03:16,  1.16it/s] 67%|██████▋   | 464/690 [06:42<03:14,  1.16it/s] 67%|██████▋   | 465/690 [06:43<03:12,  1.17it/s] 68%|██████▊   | 466/690 [06:44<03:11,  1.17it/s] 68%|██████▊   | 467/690 [06:45<03:12,  1.16it/s] 68%|██████▊   | 468/690 [06:46<03:12,  1.15it/s] 68%|██████▊   | 469/690 [06:46<03:13,  1.14it/s] 68%|██████▊   | 470/690 [06:47<03:11,  1.15it/s] 68%|██████▊   | 471/690 [06:48<03:09,  1.15it/s] 68%|██████▊   | 472/690 [06:49<03:09,  1.15it/s] 69%|██████▊   | 473/690 [06:50<03:08,  1.15it/s] 69%|██████▊   | 474/690 [06:51<03:06,  1.16it/s] 69%|██████▉   | 475/690 [06:52<03:05,  1.16it/s] 69%|██████▉   | 476/690 [06:52<03:04,  1.16it/s] 69%|██████▉   | 477/690 [06:53<03:03,  1.16it/s] 69%|██████▉   | 478/690 [06:54<03:02,  1.16it/s] 69%|██████▉   | 479/690 [06:55<03:01,  1.16it/s] 70%|██████▉   | 480/690 [06:56<03:01,  1.16it/s] 70%|██████▉   | 481/690 [06:57<03:00,  1.16it/s] 70%|██████▉   | 482/690 [06:58<03:00,  1.15it/s] 70%|███████   | 483/690 [06:59<02:59,  1.15it/s] 70%|███████   | 484/690 [06:59<02:59,  1.15it/s] 70%|███████   | 485/690 [07:00<02:57,  1.15it/s] 70%|███████   | 486/690 [07:01<02:57,  1.15it/s] 71%|███████   | 487/690 [07:02<02:56,  1.15it/s] 71%|███████   | 488/690 [07:03<02:54,  1.16it/s] 71%|███████   | 489/690 [07:04<02:53,  1.16it/s] 71%|███████   | 490/690 [07:05<02:52,  1.16it/s] 71%|███████   | 491/690 [07:05<02:51,  1.16it/s] 71%|███████▏  | 492/690 [07:06<02:49,  1.17it/s] 71%|███████▏  | 493/690 [07:07<02:50,  1.16it/s] 72%|███████▏  | 494/690 [07:08<02:50,  1.15it/s] 72%|███████▏  | 495/690 [07:09<02:49,  1.15it/s] 72%|███████▏  | 496/690 [07:10<02:48,  1.15it/s] 72%|███████▏  | 49{'loss': 0.6291, 'learning_rate': 1.3768115942028985e-05, 'epoch': 2.17}
7/690 [07:11<02:47,  1.16it/s] 72%|███████▏  | 498/690 [07:12<02:46,  1.15it/s] 72%|███████▏  | 499/690 [07:12<02:45,  1.16it/s] 72%|███████▏  | 500/690 [07:13<02:44,  1.16it/s]                                                  72%|███████▏  | 500/690 [07:13<02:44,  1.16it/s][INFO|trainer.py:2985] 2024-02-12 19:57:25,859 >> Saving model checkpoint to /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/tmp-checkpoint-500
[INFO|configuration_utils.py:473] 2024-02-12 19:57:25,862 >> Configuration saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/tmp-checkpoint-500/config.json
[INFO|modeling_utils.py:2462] 2024-02-12 19:57:50,028 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/tmp-checkpoint-500/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-02-12 19:57:50,039 >> tokenizer config file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/tmp-checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-02-12 19:57:50,041 >> Special tokens file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/tmp-checkpoint-500/special_tokens_map.json
 73%|███████▎  | 501/690 [08:19<1:03:58, 20.31s/it] 73%|███████▎  | 502/690 [08:20<45:20, 14.47s/it]   73%|███████▎  | 503/690 [08:21<32:22, 10.39s/it] 73%|███████▎  | 504/690 [08:21<23:20,  7.53s/it] 73%|███████▎  | 505/690 [08:22<17:03,  5.53s/it] 73%|███████▎  | 506/690 [08:23<12:40,  4.13s/it] 73%|███████▎  | 507/690 [08:24<09:35,  3.15s/it] 74%|███████▎  | 508/690 [08:25<07:28,  2.46s/it] 74%|███████▍  | 509/690 [08:26<05:57,  1.98s/it] 74%|███████▍  | 510/690 [08:27<04:56,  1.65s/it] 74%|███████▍  | 511/690 [08:27<04:12,  1.41s/it] 74%|███████▍  | 512/690 [08:28<03:42,  1.25s/it] 74%|███████▍  | 513/690 [08:29<03:19,  1.12s/it] 74%|███████▍  | 514/690 [08:30<03:03,  1.04s/it] 75%|███████▍  | 515/690 [08:31<02:51,  1.02it/s] 75%|███████▍  | 516/690 [08:32<02:44,  1.06it/s] 75%|███████▍  | 517/690 [08:33<02:38,  1.09it/s] 75%|███████▌  | 518/690 [08:33<02:34,  1.11it/s] 75%|███████▌  | 519/690 [08:34<02:30,  1.13it/s] 75%|███████▌  | 520/690 [08:35<02:30,  1.13it/s] 76%|███████▌  | 521/690 [08:36<02:26,  1.15it/s] 76%|███████▌  | 522/690 [08:37<02:26,  1.14it/s] 76%|███████▌  | 523/690 [08:38<02:24,  1.16it/s] 76%|███████▌  | 524/690 [08:39<02:23,  1.16it/s] 76%|███████▌  | 525/690 [08:39<02:22,  1.16it/s] 76%|███████▌  | 526/690 [08:40<02:21,  1.16it/s] 76%|███████▋  | 527/690 [08:41<02:20,  1.16it/s] 77%|███████▋  | 528/690 [08:42<02:19,  1.16it/s] 77%|███████▋  | 529/690 [08:43<02:18,  1.17it/s] 77%|███████▋  | 530/690 [08:44<02:17,  1.17it/s] 77%|███████▋  | 531/690 [08:45<02:15,  1.17it/s] 77%|███████▋  | 532/690 [08:45<02:16,  1.16it/s] 77%|███████▋  | 533/690 [08:46<02:14,  1.17it/s] 77%|███████▋  | 534/690 [08:47<02:14,  1.16it/s] 78%|███████▊  | 535/690 [08:48<02:13,  1.16it/s] 78%|███████▊  | 536/690 [08:49<02:13,  1.16it/s] 78%|███████▊  | 537/690 [08:50<02:11,  1.16it/s] 78%|███████▊  | 538/690 [08:51<02:11,  1.16it/s] 78%|███████▊  | 539/690 [08:52<02:09,  1.17it/s] 78%|███████▊  | 540/690 [08:52<02:09,  1.16it/s] 78%|███████▊  | 541/690 [08:53<02:08,  1.16it/s] 79%|███████▊  | 542/690 [08:54<02:07,  1.16it/s] 79%|███████▊  | 543/690 [08:55<02:06,  1.16it/s] 79%|███████▉  | 544/690 [08:56<02:06,  1.16it/s] 79%|███████▉  | 545/690 [08:57<02:04,  1.16it/s] 79%|███████▉  | 546/690 [08:58<02:04,  1.16it/s] 79%|███████▉  | 547/690 [08:58<02:03,  1.16it/s] 79%|███████▉  | 548/690 [08:59<02:02,  1.16it/s] 80%|███████▉  | 549/690 [09:00<02:01,  1.17it/s] 80%|███████▉  | 550/690 [09:01<02:00,  1.16it/s] 80%|███████▉  | 551/690 [09:02<01:59,  1.16it/s] 80%|████████  | 552/690 [09:03<01:58,  1.17it/s] 80%|████████  | 553/690 [09:04<01:57,  1.16it/s] 80%|████████  | 554/690 [09:04<01:56,  1.16it/s] 80%|████████  | 555/690 [09:05<01:56,  1.16it/s] 81%|████████  | 556/690 [09:06<01:55,  1.16it/s] 81%|████████  | 557/690 [09:07<01:55,  1.15it/s] 81%|████████  | 558/690 [09:08<01:54,  1.16it/s] 81%|████████  | 559/690 [09:09<01:52,  1.16it/s] 81%|████████  | 560/690 [09:10<01:52,  1.16it/s] 81%|████████▏ | 561/690 [09:10<01:50,  1.16it/s] 81%|████████▏ | 562/690 [09:11<01:50,  1.16it/s] 82%|████████▏ | 563/690 [09:12<01:49,  1.16it/s] 82%|████████▏ | 564/690 [09:13<01:48,  1.16it/s] 82%|████████▏ | 565/690 [09:14<01:47,  1.16it/s] 82%|████████▏ | 566/690 [09:15<01:47,  1.15it/s] 82%|████████▏ | 567/690 [09:16<01:45,  1.17it/s] 82%|████████▏ | 568/690 [09:16<01:44,  1.16it/s] 82%|████████▏ | 569/690 [09:17<01:44,  1.16it/s] 83%|████████▎ | 570/690 [09:18<01:44,  1.15it/s] 83%|████████▎ | 571/690 [09:19<01:43,  1.15it/s] 83%|████████▎ | 572/690 [09:20<01:41,  1.16it/s] 83%|████████▎ | 573/690 [09:21<01:41,  1.16it/s] 83%|████████▎ | 574/690 [09:22<01:40,  1.15it/s] 83%|████████▎ | 575/690 [09:23<01:39,  1.16it/s] 83%|████████▎ | 576/690 [09:23<01:38,  1.15it/s] 84%|████████▎ | 577/690 [09:24<01:38,  1.15it/s] 84%|████████▍ | 578/690 [09:25<01:37,  1.15it/s] 84%|████████▍ | 579/690 [09:26<01:35,  1.16it/s] 84%|████████▍ | 580/690 [09:27<01:34,  1.16it/s] 84%|████████▍ | 581/690 [09:28<01:34,  1.15it/s] 84%|████████▍ | 582/690 [09:29<01:33,  1.16it/s] 84%|████████▍ | 583/690 [09:29<01:32,  1.16it/s] 85%|████████▍ | 584/690 [09:30<01:32,  1.15it/s] 85%|████████▍ | 585/690 [09:31<01:31,  1.15it/s] 85%|████████▍ | 586/690 [09:32<01:30,  1.15it/s] 85%|████████▌ | 587/690 [09:33<01:29,  1.16it/s] 85%|████████▌ | 588/690 [09:34<01:28,  1.16it/s] 85%|████████▌ | 589/690 [09:35<01:26,  1.17it/s] 86%|████████▌ | 590/690 [09:36<01:25,  1.16it/s] 86%|████████▌ | 591/690 [09:36<01:25,  1.16it/s] 86%|████████▌ | 592/690 [09:37<01:24,  1.16it/s] 86%|████████▌ | 593/690 [09:38<01:23,  1.16it/s] 86%|████████▌ | 594/690 [09:39<01:22,  1.16it/s] 86%|████████▌ | 595/690 [09:40<01:21,  1.16it/s] 86%|████████▋ | 596/690 [09:41<01:21,  1.16it/s] 87%|████████▋ | 597/690 [09:42<01:20,  1.16it/s] 87%|████████▋ | 598/690 [09:42<01:19,  1.16it/s] 87%|████████▋ | 599/690 [09:43<01:17,  1.17it/s] 87%|████████▋ | 600/690 [09:44<01:17,  1.17it/s] 87%|████████▋ | 601/690 [09:45<01:16,  1.17it/s] 87%|████████▋ | 602/690 [09:46<01:15,  1.17it/s] 87%|████████▋ | 603/690 [09:47<01:15,  1.16it/s] 88%|████████▊ | 604/690 [09:48<01:14,  1.16it/s] 88%|████████▊ | 605/690 [09:48<01:13,  1.16it/s] 88%|████████▊ | 606/690 [09:49<01:13,  1.15it/s] 88%|████████▊ | 607/690 [09:50<01:11,  1.16it/s] 88%|████████▊ | 608/690 [09:51<01:11,  1.15it/s] 88%|████████▊ | 609/690 [09:52<01:09,  1.17it/s] 88%|████████▊ | 610/690 [09:53<01:08,  1.16it/s] 89%|████████▊ | 611/690 [09:54<01:08,  1.16it/s] 89%|████████▊ | 612/690 [09:54<01:07,  1.16it/s] 89%|████████▉ | 613/690 [09:55<01:06,  1.15it/s] 89%|████████▉ | 614/690 [09:56<01:05,  1.16it/s] 89%|████████▉ | 615/690 [09:57<01:04,  1.16it/s] 89%|████████▉ | 616/690 [09:58<01:03,  1.16it/s] 89%|████████▉ | 617/690 [09:59<01:02,  1.16it/s] 90%|████████▉ | 618/690 [10:00<01:01,  1.16it/s] 90%|████████▉ | 619/690 [10:01<01:01,  1.16it/s] 90%|████████▉ | 620/690 [10:01<01:00,  1.16it/s] 90%|█████████ | 621/690 [10:02<00:59,  1.15it/s] 90%|█████████ | 622/690 [10:03<00:58,  1.16it/s] 90%|█████████ | 623/690 [10:04<00:57,  1.17it/s] 90%|█████████ | 624/690 [10:05<00:56,  1.16it/s] 91%|█████████ | 625/690 [10:06<00:56,  1.16it/s] 91%|█████████ | 626/690 [10:07<00:55,  1.16it/s] 91%|█████████ | 627/690 [10:07<00:54,  1.16it/s] 91%|█████████ | 628/690 [10:08<00:53,  1.16it/s] 91%|█████████ | 629/690 [10:09<00:52,  1.16it/s] 91%|█████████▏| 630/690 [10:10<00:52,  1.15it/s] 91%|█████████▏| 631/690 [10:11<00:51,  1.15it/s] 92%|█████████▏| 632/690 [10:12<00:50,  1.16it/s] 92%|█████████▏| 633/690 [10:13<00:49,  1.15it/s] 92%|█████████▏| 634/690 [10:13<00:48,  1.16it/s] 92%|█████████▏| 635/690 [10:14<00:47,  1.16it/s] 92%|█████████▏| 636/690 [10:15<00:46,  1.16it/s] 92%|█████████▏| 637/690 [10:16<00:45,  1.16it/s] 92%|█████████▏| 638/690 [10:17<00:44,  1.16it/s] 93%|█████████▎| 639/690 [10:18<00:44,  1.16it/s] 93%|█████████▎| 640/690 [10:19<00:43,  1.16it/s] 93%|█████████▎| 641/690 [10:20<00:42,  1.16it/s] 93%|█████████▎| 642/690 [10:20<00:41,  1.16it/s] 93%|█████████▎| 643/690 [10:21<00:40,  1.16it/s] 93%|█████████▎| 644/690 [10:22<00:39,  1.16it/s] 93%|█████████▎| 645/690 [10:23<00:38,  1.16it/s] 94%|█████████▎| 646/690 [10:24<00:37,  1.16it/s] 94%|█████████▍| 647/690 [10:25<00:36,  1.17it/s] 94%|█████████▍| 648/690 [10:26<00:36,  1.17it/s] 94%|█████████▍| 649/690 [10:26<00:35,  1.16it/s] 94%|█████████▍| 650/690 [10:27<00:34,  1.16it/s] 94%|█████████▍| 651/690 [10:28<00:33,  1.15it/s] 94%|█████████▍| 652/690 [10:29<00:32,  1.16it/s] 95%|█████████▍| 653/690 [10:30<00:31,  1.17it/s] 95%|█████████▍| 654/690 [10:31<00:30,  1.17it/s] 95%|█████████▍| 655/690 [10:32<00:30,  1.16it/s] 95%|█████████▌| 656/690 [10:32<00:29,  1.16it/s] 95%|█████████▌| 657/690 [10:33<00:28,  1.16it/s] 95%|█████████▌| 658/690 [10:34<00:27,  1.15it/s] 96%|█████████▌| 659/690 [10:35<00:26,  1.16it/s] 96%|█████████▌| 660/690 [10:36<00:25,  1.16it/s] 96%|█████████▌| 661/690 [10:37<00:25,  1.15it/s] 96%|█████████▌| 662/690 [10:38<00:24,  1.15it/s] 96%|█████████▌| 663/690 [10:39<00:23,  1.15it/s] 96%|█████████▌| 664/690 [10:39<00:22,  1.16it/s] 96%|█████████▋| 665/690 [10:40<00:21,  1.16it/s] 97%|█████████▋| 666/690 [10:41<00:20,  1.16it/s] 97%|█████████▋| 667/690 [10:42<00:19,  1.15it/s] 97%|█████████▋| 668/690 [10:43<00:19,  1.15it/s] 97%|█████████▋| 669/690 [10:44<00:18,  1.16it/s] 97%|█████████▋| 670/690 [10:45<00:17,  1.15it/s] 97%|█████████▋| 671/690 [10:45<00:16,  1.16it/s] 97%|█████████▋| 672/690 [10:46<00:15,  1.16it/s] 98%|█████████▊| 673/690 [10:47<00:14,  1.14it/s] 98%|█████████▊| 674/690 [10:48<00:13,  1.15it/s] 98%|█████████▊| 675/690 [10:49<00:13,  1.15it/s] 98%|█████████▊| 676/690 [10:50<00:12,  1.16it/s] 98%|█████████▊| 677/690 [10:51<00:11,  1.16it/s] 98%|█████████▊| 678/690 [10:51<00:10,  1.16it/s] 98%|█████████▊| 679/690 [10:52<00:09,  1.16it/s] 99%|█████████▊| 680/690 [10:53<00:08,  1.16it/s] 99%|█████████▊| 681/690 [10:54<00:07,  1.17it/s] 99%|█████████▉| 682/690 [10:55<00:06,  1.16it/s] 99%|█████████▉| 683/690 [10:56<00:05,  1.17it/s] 99%|█████████▉| 684/690 [10:57<00:05,  1.17it/s] 99%|█████████▉| 685/690 [10:57<00:04,  1.16it/s] 99%|█████████▉| 686/690 [10:58<00:03,  1.16it/s]100%|█████████▉| 687/690 [10:59<00:02,  1.15it/s]100%|█████████▉| 688/690 [11:00<00:01,  1.16it/s]100%|█████████▉| 689/690 [11:01<00:00,  1.15it/s]100%|██████████| 690/690 [11:02<00:00,  1.16it/s][INFO|trainer.py:1988] 2024-02-12 20:01:14,299 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


{'train_runtime': 662.504, 'train_samples_per_second': 16.61, 'train_steps_per_second': 1.042, 'train_loss': 0.5416578209918478, 'epoch': 3.0}
                                                 100%|██████████| 690/690 [11:02<00:00,  1.16it/s]100%|██████████| 690/690 [11:02<00:00,  1.04it/s]
[INFO|trainer.py:2985] 2024-02-12 20:01:14,472 >> Saving model checkpoint to /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757
[INFO|configuration_utils.py:473] 2024-02-12 20:01:14,475 >> Configuration saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/config.json
[INFO|modeling_utils.py:2462] 2024-02-12 20:01:35,440 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-02-12 20:01:35,443 >> tokenizer config file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-02-12 20:01:35,444 >> Special tokens file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/22198757/special_tokens_map.json
***** train metrics *****
  epoch                    =        3.0
  train_loss               =     0.5417
  train_runtime            = 0:11:02.50
  train_samples            =       3668
  train_samples_per_second =      16.61
  train_steps_per_second   =      1.042
02/12/2024 20:01:35 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:737] 2024-02-12 20:01:35,501 >> The following columns in the evaluation set don't have a corresponding argument in `LlamaForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `LlamaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3291] 2024-02-12 20:01:35,503 >> ***** Running Evaluation *****
[INFO|trainer.py:3293] 2024-02-12 20:01:35,503 >>   Num examples = 408
[INFO|trainer.py:3296] 2024-02-12 20:01:35,503 >>   Batch size = 8
  0%|          | 0/26 [00:00<?, ?it/s]  8%|▊         | 2/26 [00:00<00:02,  8.45it/s] 12%|█▏        | 3/26 [00:00<00:04,  5.57it/s] 15%|█▌        | 4/26 [00:00<00:04,  4.88it/s] 19%|█▉        | 5/26 [00:01<00:04,  4.35it/s] 23%|██▎       | 6/26 [00:01<00:04,  4.25it/s] 27%|██▋       | 7/26 [00:01<00:04,  4.15it/s] 31%|███       | 8/26 [00:01<00:04,  4.05it/s] 35%|███▍      | 9/26 [00:02<00:04,  4.05it/s] 38%|███▊      | 10/26 [00:02<00:04,  3.98it/s] 42%|████▏     | 11/26 [00:02<00:03,  4.02it/s] 46%|████▌     | 12/26 [00:02<00:03,  3.98it/s] 50%|█████     | 13/26 [00:03<00:03,  3.90it/s] 54%|█████▍    | 14/26 [00:03<00:03,  3.83it/s] 58%|█████▊    | 15/26 [00:03<00:02,  3.89it/s] 62%|██████▏   | 16/26 [00:03<00:02,  3.93it/s] 65%|██████▌   | 17/26 [00:04<00:02,  3.94it/s] 69%|██████▉   | 18/26 [00:04<00:02,  3.76it/s] 73%|███████▎  | 19/26 [00:04<00:01,  3.83it/s] 77%|███████▋  | 20/26 [00:04<00:01,  3.76it/s] 81%|████████  | 21/26 [00:05<00:01,  3.82it/s] 85%|████████▍ | 22/26 [00:05<00:01,  3.83it/s] 88%|████████▊ | 23/26 [00:05<00:00,  3.89it/s] 92%|█████████▏| 24/26 [00:05<00:00,  3.97it/s] 96%|█████████▌| 25/26 [00:06<00:00,  3.93it/s]100%|██████████| 26/26 [00:06<00:00,  4.04it/s]100%|██████████| 26/26 [00:06<00:00,  3.89it/s]
***** eval metrics *****
  epoch                   =        3.0
  eval_accuracy           =     0.7132
  eval_combined_score     =     0.7576
  eval_f1                 =      0.802
  eval_loss               =     0.8239
  eval_runtime            = 0:00:06.94
  eval_samples            =        408
  eval_samples_per_second =     58.789
  eval_steps_per_second   =      3.746
/usr/bin/bash: line 1: --token: command not found
srun: error: v010: task 0: Exited with exit code 127
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/jet/home/mmisra/miniconda3/envs/benchmark/lib/python3.8/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/jet/home/mmisra/miniconda3/envs/benchmark/lib/python3.8/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
02/12/2024 20:03:54 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
02/12/2024 20:03:54 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/runs/Feb12_20-03-54_v010.ib.bridges2.psc.edu,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
output_dir=/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
02/12/2024 20:03:54 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, 16-bits training: False
Overwrite dataset info from restored data version if exists.
02/12/2024 20:03:55 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
02/12/2024 20:03:55 - INFO - datasets.info - Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
Found cached dataset glue (/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)
02/12/2024 20:03:55 - INFO - datasets.builder - Found cached dataset glue (/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)
Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
02/12/2024 20:03:55 - INFO - datasets.info - Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
[INFO|configuration_utils.py:729] 2024-02-12 20:03:55,998 >> loading configuration file config.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/config.json
[INFO|configuration_utils.py:792] 2024-02-12 20:03:55,999 >> Model config LlamaConfig {
  "_name_or_path": "datajuicer/LLaMA-1B-dj-refine-100B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "finetuning_task": "mrpc",
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5504,
  "max_position_embeddings": 2048,
  "max_sequence_length": 2048,
  "model_type": "llama",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_key_value_heads": 16,
  "pad_token_id": 32004,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:03:56,037 >> loading file tokenizer.model from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/tokenizer.model
[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:03:56,037 >> loading file tokenizer.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/tokenizer.json
[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:03:56,038 >> loading file added_tokens.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/added_tokens.json
[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:03:56,038 >> loading file special_tokens_map.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/special_tokens_map.json
[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:03:56,038 >> loading file tokenizer_config.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/tokenizer_config.json
[WARNING|logging.py:314] 2024-02-12 20:03:56,124 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|modeling_utils.py:3259] 2024-02-12 20:03:56,221 >> loading weights file pytorch_model.bin from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/pytorch_model.bin
[WARNING|logging.py:314] 2024-02-12 20:03:56,290 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|modeling_utils.py:3984] 2024-02-12 20:04:03,359 >> Some weights of the model checkpoint at datajuicer/LLaMA-1B-dj-refine-100B were not used when initializing LlamaForSequenceClassification: ['lm_head.weight']
- This IS expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3996] 2024-02-12 20:04:03,360 >> Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at datajuicer/LLaMA-1B-dj-refine-100B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[WARNING|modeling_utils.py:3996] 2024-02-12 20:04:03,361 >> Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at datajuicer/LLaMA-1B-dj-refine-100B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-d53d7a09499f5bfb.arrow
02/12/2024 20:04:03 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-d53d7a09499f5bfb.arrow
Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-12e393c323965c42.arrow
02/12/2024 20:04:03 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-12e393c323965c42.arrow
Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-65fa5a7617106458.arrow
02/12/2024 20:04:03 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/mrpc/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-65fa5a7617106458.arrow
02/12/2024 20:04:04 - INFO - __main__ - Sample 2619 of the training set: {'sentence1': 'The proceedings were taken up with prosecutors outlining their case against Amrozi , reading 33 pages of documents outlining allegations against him .', 'sentence2': 'Proceedings were taken up with prosecutors outlining their case against Amrozi , reading a 33-page accusation letter to the court .', 'label': 1, 'idx': 2916, 'input_ids': [32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 1, 450, 8469, 886, 892, 4586, 701, 411, 410, 3471, 29560, 714, 1915, 292, 1009, 1206, 2750, 1913, 307, 2526, 1919, 5183, 29871, 29941, 29941, 6515, 310, 10701, 714, 1915, 292, 16831, 800, 2750, 1075, 869, 1, 1019, 3947, 886, 892, 4586, 701, 411, 410, 3471, 29560, 714, 1915, 292, 1009, 1206, 2750, 1913, 307, 2526, 1919, 5183, 263, 29871, 29941, 29941, 29899, 3488, 26142, 362, 5497, 304, 278, 8973, 869], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
02/12/2024 20:04:04 - INFO - __main__ - Sample 456 of the training set: {'sentence1': "Chechen officials working for the Moscow-backed government are a frequent target for rebels and tension is running high ahead of next Sunday 's presidential election in war-torn Chechnya .", 'sentence2': "Officials in Chechnya 's Moscow-backed government are a frequent target for rebels , and tension is running high ahead of Sunday 's presidential election in the war-ravaged region .", 'label': 1, 'idx': 509, 'input_ids': [32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 1, 6561, 2724, 24921, 1985, 363, 278, 25820, 29899, 1627, 287, 5874, 526, 263, 17091, 3646, 363, 15121, 1379, 322, 260, 2673, 338, 2734, 1880, 14432, 310, 2446, 16340, 525, 29879, 6673, 616, 8271, 297, 1370, 29899, 29873, 1398, 6561, 305, 1460, 29874, 869, 1, 10564, 29879, 297, 6561, 305, 1460, 29874, 525, 29879, 25820, 29899, 1627, 287, 5874, 526, 263, 17091, 3646, 363, 15121, 1379, 1919, 322, 260, 2673, 338, 2734, 1880, 14432, 310, 16340, 525, 29879, 6673, 616, 8271, 297, 278, 1370, 29899, 5705, 4063, 5120, 869], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
02/12/2024 20:04:04 - INFO - __main__ - Sample 102 of the training set: {'sentence1': "Standard & Poor 's 500 stock index futures declined 4.40 points to 983.50 , while Nasdaq futures fell 6.5 points to 1,206.50 .", 'sentence2': "The Standard & Poor 's 500 Index was up 1.75 points , or 0.18 percent , to 977.68 .", 'label': 0, 'idx': 116, 'input_ids': [32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 1, 10117, 669, 3929, 272, 525, 29879, 29871, 29945, 29900, 29900, 10961, 2380, 3105, 1973, 4845, 1312, 29871, 29946, 29889, 29946, 29900, 3291, 304, 29871, 29929, 29947, 29941, 29889, 29945, 29900, 1919, 1550, 22318, 1388, 29939, 3105, 1973, 8379, 29871, 29953, 29889, 29945, 3291, 304, 29871, 29896, 29892, 29906, 29900, 29953, 29889, 29945, 29900, 869, 1, 450, 10117, 669, 3929, 272, 525, 29879, 29871, 29945, 29900, 29900, 11374, 471, 701, 29871, 29896, 29889, 29955, 29945, 3291, 1919, 470, 29871, 29900, 29889, 29896, 29947, 10151, 1919, 304, 29871, 29929, 29955, 29955, 29889, 29953, 29947, 869], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
02/12/2024 20:04:04 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:737] 2024-02-12 20:04:07,448 >> The following columns in the training set don't have a corresponding argument in `LlamaForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `LlamaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1747] 2024-02-12 20:04:07,578 >> ***** Running training *****
[INFO|trainer.py:1748] 2024-02-12 20:04:07,578 >>   Num examples = 3,668
[INFO|trainer.py:1749] 2024-02-12 20:04:07,579 >>   Num Epochs = 3
[INFO|trainer.py:1750] 2024-02-12 20:04:07,579 >>   Instantaneous batch size per device = 8
[INFO|trainer.py:1753] 2024-02-12 20:04:07,579 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:1754] 2024-02-12 20:04:07,579 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1755] 2024-02-12 20:04:07,579 >>   Total optimization steps = 690
[INFO|trainer.py:1756] 2024-02-12 20:04:07,580 >>   Number of trainable parameters = 1,280,153,600
  0%|          | 0/690 [00:00<?, ?it/s][rank1]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/690 [00:02<28:28,  2.48s/it]  0%|          | 2/690 [00:03<16:59,  1.48s/it]  0%|          | 3/690 [00:04<13:50,  1.21s/it]  1%|          | 4/690 [00:04<12:12,  1.07s/it]  1%|          | 5/690 [00:05<11:15,  1.01it/s]  1%|          | 6/690 [00:06<10:44,  1.06it/s]  1%|          | 7/690 [00:07<10:25,  1.09it/s]  1%|          | 8/690 [00:08<10:09,  1.12it/s]  1%|▏         | 9/690 [00:09<09:58,  1.14it/s]  1%|▏         | 10/690 [00:10<09:54,  1.14it/s]  2%|▏         | 11/690 [00:10<09:49,  1.15it/s]  2%|▏         | 12/690 [00:11<09:46,  1.16it/s]  2%|▏         | 13/690 [00:12<09:46,  1.15it/s]  2%|▏         | 14/690 [00:13<09:46,  1.15it/s]  2%|▏         | 15/690 [00:14<09:39,  1.16it/s]  2%|▏         | 16/690 [00:15<09:40,  1.16it/s]  2%|▏         | 17/690 [00:16<09:38,  1.16it/s]  3%|▎         | 18/690 [00:17<09:40,  1.16it/s]  3%|▎         | 19/690 [00:17<09:37,  1.16it/s]  3%|▎         | 20/690 [00:18<09:39,  1.16it/s]  3%|▎         | 21/690 [00:19<09:37,  1.16it/s]  3%|▎         | 22/690 [00:20<09:33,  1.16it/s]  3%|▎         | 23/690 [00:21<09:39,  1.15it/s]  3%|▎         | 24/690 [00:22<09:35,  1.16it/s]  4%|▎         | 25/690 [00:23<09:37,  1.15it/s]  4%|▍         | 26/690 [00:23<09:37,  1.15it/s]  4%|▍         | 27/690 [00:24<09:35,  1.15it/s]  4%|▍         | 28/690 [00:25<09:30,  1.16it/s]  4%|▍         | 29/690 [00:26<09:28,  1.16it/s]  4%|▍         | 30/690 [00:27<09:24,  1.17it/s]  4%|▍         | 31/690 [00:28<09:22,  1.17it/s]  5%|▍         | 32/690 [00:29<09:25,  1.16it/s]  5%|▍         | 33/690 [00:29<09:23,  1.17it/s]  5%|▍         | 34/690 [00:30<09:22,  1.17it/s]  5%|▌         | 35/690 [00:31<09:22,  1.16it/s]  5%|▌         | 36/690 [00:32<09:21,  1.16it/s]  5%|▌         | 37/690 [00:33<09:20,  1.16it/s]  6%|▌         | 38/690 [00:34<09:19,  1.17it/s]  6%|▌         | 39/690 [00:35<09:21,  1.16it/s]  6%|▌         | 40/690 [00:35<09:17,  1.17it/s]  6%|▌         | 41/690 [00:36<09:19,  1.16it/s]  6%|▌         | 42/690 [00:37<09:19,  1.16it/s]  6%|▌         | 43/690 [00:38<09:13,  1.17it/s]  6%|▋         | 44/690 [00:39<09:16,  1.16it/s]  7%|▋         | 45/690 [00:40<09:10,  1.17it/s]  7%|▋         | 46/690 [00:41<09:10,  1.17it/s]  7%|▋         | 47/690 [00:41<09:08,  1.17it/s]  7%|▋         | 48/690 [00:42<09:10,  1.17it/s]  7%|▋         | 49/690 [00:43<09:10,  1.16it/s]  7%|▋         | 50/690 [00:44<09:08,  1.17it/s]  7%|▋         | 51/690 [00:45<09:10,  1.16it/s]  8%|▊         | 52/690 [00:46<09:09,  1.16it/s]  8%|▊         | 53/690 [00:47<09:04,  1.17it/s]  8%|▊         | 54/690 [00:47<09:04,  1.17it/s]  8%|▊         | 55/690 [00:48<09:02,  1.17it/s]  8%|▊         | 56/690 [00:49<09:04,  1.16it/s]  8%|▊         | 57/690 [00:50<09:01,  1.17it/s]  8%|▊         | 58/690 [00:51<09:05,  1.16it/s]  9%|▊         | 59/690 [00:52<09:02,  1.16it/s]  9%|▊         | 60/690 [00:53<09:03,  1.16it/s]  9%|▉         | 61/690 [00:53<08:59,  1.17it/s]  9%|▉         | 62/690 [00:54<09:00,  1.16it/s]  9%|▉         | 63/690 [00:55<09:00,  1.16it/s]  9%|▉         | 64/690 [00:56<09:00,  1.16it/s]  9%|▉         | 65/690 [00:57<08:57,  1.16it/s] 10%|▉         | 66/690 [00:58<08:55,  1.17it/s] 10%|▉         | 67/690 [00:59<08:53,  1.17it/s] 10%|▉         | 68/690 [00:59<08:55,  1.16it/s] 10%|█         | 69/690 [01:00<08:49,  1.17it/s] 10%|█         | 70/690 [01:01<08:50,  1.17it/s] 10%|█         | 71/690 [01:02<08:49,  1.17it/s] 10%|█         | 72/690 [01:03<08:50,  1.17it/s] 11%|█         | 73/690 [01:04<08:48,  1.17it/s] 11%|█         | 74/690 [01:05<08:46,  1.17it/s] 11%|█         | 75/690 [01:05<08:43,  1.18it/s] 11%|█         | 76/690 [01:06<08:46,  1.17it/s] 11%|█         | 77/690 [01:07<08:45,  1.17it/s] 11%|█▏        | 78/690 [01:08<08:46,  1.16it/s] 11%|█▏        | 79/690 [01:09<08:40,  1.17it/s] 12%|█▏        | 80/690 [01:10<08:48,  1.15it/s] 12%|█▏        | 81/690 [01:11<08:45,  1.16it/s] 12%|█▏        | 82/690 [01:12<08:45,  1.16it/s] 12%|█▏        | 83/690 [01:12<08:41,  1.16it/s] 12%|█▏        | 84/690 [01:13<08:44,  1.16it/s] 12%|█▏        | 85/690 [01:14<08:43,  1.16it/s] 12%|█▏        | 86/690 [01:15<08:39,  1.16it/s] 13%|█▎        | 87/690 [01:16<08:42,  1.15it/s] 13%|█▎        | 88/690 [01:17<08:40,  1.16it/s] 13%|█▎        | 89/690 [01:18<08:42,  1.15it/s] 13%|█▎        | 90/690 [01:18<08:40,  1.15it/s] 13%|█▎        | 91/690 [01:19<08:38,  1.16it/s] 13%|█▎        | 92/690 [01:20<08:40,  1.15it/s] 13%|█▎        | 93/690 [01:21<08:38,  1.15it/s] 14%|█▎        | 94/690 [01:22<08:34,  1.16it/s] 14%|█▍        | 95/690 [01:23<08:33,  1.16it/s] 14%|█▍        | 96/690 [01:24<08:33,  1.16it/s] 14%|█▍        | 97/690 [01:24<08:30,  1.16it/s] 14%|█▍        | 98/690 [01:25<08:31,  1.16it/s] 14%|█▍        | 99/690 [01:26<08:29,  1.16it/s] 14%|█▍        | 100/690 [01:27<08:31,  1.15it/s] 15%|█▍        | 101/690 [01:28<08:33,  1.15it/s] 15%|█▍        | 102/690 [01:29<08:26,  1.16it/s] 15%|█▍        | 103/690 [01:30<08:24,  1.16it/s] 15%|█▌        | 104/690 [01:31<08:28,  1.15it/s] 15%|█▌        | 105/690 [01:31<08:25,  1.16it/s] 15%|█▌        | 106/690 [01:32<08:21,  1.16it/s] 16%|█▌        | 107/690 [01:33<08:23,  1.16it/s] 16%|█▌        | 108/690 [01:34<08:21,  1.16it/s] 16%|█▌        | 109/690 [01:35<08:22,  1.16it/s] 16%|█▌        | 110/690 [01:36<08:18,  1.16it/s] 16%|█▌        | 111/690 [01:37<08:20,  1.16it/s] 16%|█▌        | 112/690 [01:37<08:16,  1.16it/s] 16%|█▋        | 113/690 [01:38<08:16,  1.16it/s] 17%|█▋        | 114/690 [01:39<08:17,  1.16it/s] 17%|█▋        | 115/690 [01:40<08:12,  1.17it/s] 17%|█▋        | 116/690 [01:41<08:13,  1.16it/s] 17%|█▋        | 117/690 [01:42<08:11,  1.16it/s] 17%|█▋        | 118/690 [01:43<08:12,  1.16it/s] 17%|█▋        | 119/690 [01:43<08:11,  1.16it/s] 17%|█▋        | 120/690 [01:44<08:07,  1.17it/s] 18%|█▊        | 121/690 [01:45<08:09,  1.16it/s] 18%|█▊        | 122/690 [01:46<08:07,  1.16it/s] 18%|█▊        | 123/690 [01:47<08:07,  1.16it/s] 18%|█▊        | 124/690 [01:48<08:09,  1.16it/s] 18%|█▊        | 125/690 [01:49<08:08,  1.16it/s] 18%|█▊        | 126/690 [01:49<08:06,  1.16it/s] 18%|█▊        | 127/690 [01:50<08:03,  1.16it/s] 19%|█▊        | 128/690 [01:51<08:02,  1.17it/s] 19%|█▊        | 129/690 [01:52<08:02,  1.16it/s] 19%|█▉        | 130/690 [01:53<08:03,  1.16it/s] 19%|█▉        | 131/690 [01:54<08:00,  1.16it/s] 19%|█▉        | 132/690 [01:55<08:02,  1.16it/s] 19%|█▉        | 133/690 [01:55<07:58,  1.16it/s] 19%|█▉        | 134/690 [01:56<08:00,  1.16it/s] 20%|█▉        | 135/690 [01:57<07:59,  1.16it/s] 20%|█▉        | 136/690 [01:58<07:56,  1.16it/s] 20%|█▉        | 137/690 [01:59<07:55,  1.16it/s] 20%|██        | 138/690 [02:00<07:54,  1.16it/s] 20%|██        | 139/690 [02:01<07:55,  1.16it/s] 20%|██        | 140/690 [02:02<07:56,  1.15it/s] 20%|██        | 141/690 [02:02<07:50,  1.17it/s] 21%|██        | 142/690 [02:03<07:52,  1.16it/s] 21%|██        | 143/690 [02:04<07:48,  1.17it/s] 21%|██        | 144/690 [02:05<07:51,  1.16it/s] 21%|██        | 145/690 [02:06<07:50,  1.16it/s] 21%|██        | 146/690 [02:07<07:50,  1.16it/s] 21%|██▏       | 147/690 [02:08<07:48,  1.16it/s] 21%|██▏       | 148/690 [02:08<07:47,  1.16it/s] 22%|██▏       | 149/690 [02:09<07:46,  1.16it/s] 22%|██▏       | 150/690 [02:10<07:43,  1.16it/s] 22%|██▏       | 151/690 [02:11<07:43,  1.16it/s] 22%|██▏       | 152/690 [02:12<07:45,  1.16it/s] 22%|██▏       | 153/690 [02:13<07:45,  1.15it/s] 22%|██▏       | 154/690 [02:14<07:42,  1.16it/s] 22%|██▏       | 155/690 [02:14<07:41,  1.16it/s] 23%|██▎       | 156/690 [02:15<07:42,  1.15it/s] 23%|██▎       | 157/690 [02:16<07:42,  1.15it/s] 23%|██▎       | 158/690 [02:17<07:38,  1.16it/s] 23%|██▎       | 159/690 [02:18<07:39,  1.16it/s] 23%|██▎       | 160/690 [02:19<07:37,  1.16it/s] 23%|██▎       | 161/690 [02:20<07:38,  1.15it/s] 23%|██▎       | 162/690 [02:21<07:35,  1.16it/s] 24%|██▎       | 163/690 [02:21<07:34,  1.16it/s] 24%|██▍       | 164/690 [02:22<07:34,  1.16it/s] 24%|██▍       | 165/690 [02:23<07:32,  1.16it/s] 24%|██▍       | 166/690 [02:24<07:32,  1.16it/s] 24%|██▍       | 167/690 [02:25<07:27,  1.17it/s] 24%|██▍       | 168/690 [02:26<07:31,  1.15it/s] 24%|██▍       | 169/690 [02:27<07:29,  1.16it/s] 25%|██▍       | 170/690 [02:27<07:27,  1.16it/s] 25%|██▍       | 171/690 [02:28<07:29,  1.16it/s] 25%|██▍       | 172/690 [02:29<07:29,  1.15it/s] 25%|██▌       | 173/690 [02:30<07:26,  1.16it/s] 25%|██▌       | 174/690 [02:31<07:25,  1.16it/s] 25%|██▌       | 175/690 [02:32<07:23,  1.16it/s] 26%|██▌       | 176/690 [02:33<07:26,  1.15it/s] 26%|██▌       | 177/690 [02:33<07:21,  1.16it/s] 26%|██▌       | 178/690 [02:34<07:18,  1.17it/s] 26%|██▌       | 179/690 [02:35<07:20,  1.16it/s] 26%|██▌       | 180/690 [02:36<07:19,  1.16it/s] 26%|██▌       | 181/690 [02:37<07:19,  1.16it/s] 26%|██▋       | 182/690 [02:38<07:18,  1.16it/s] 27%|██▋       | 183/690 [02:39<07:16,  1.16it/s] 27%|██▋       | 184/690 [02:39<07:16,  1.16it/s] 27%|██▋       | 185/690 [02:40<07:17,  1.15it/s] 27%|██▋       | 186/690 [02:41<07:14,  1.16it/s] 27%|██▋       | 187/690 [02:42<07:13,  1.16it/s] 27%|██▋       | 188/690 [02:43<07:12,  1.16it/s] 27%|██▋       | 189/690 [02:44<07:12,  1.16it/s] 28%|██▊       | 190/690 [02:45<07:10,  1.16it/s] 28%|██▊       | 191/690 [02:46<07:10,  1.16it/s] 28%|██▊       | 192/690 [02:46<07:09,  1.16it/s] 28%|██▊       | 193/690 [02:47<07:07,  1.16it/s] 28%|██▊       | 194/690 [02:48<07:06,  1.16it/s] 28%|██▊       | 195/690 [02:49<07:06,  1.16it/s] 28%|██▊       | 196/690 [02:50<07:09,  1.15it/s] 29%|██▊       | 197/690 [02:51<07:06,  1.16it/s] 29%|██▊       | 198/690 [02:52<07:06,  1.15it/s] 29%|██▉       | 199/690 [02:52<07:05,  1.15it/s] 29%|██▉       | 200/690 [02:53<07:06,  1.15it/s] 29%|██▉       | 201/690 [02:54<07:03,  1.16it/s] 29%|██▉       | 202/690 [02:55<07:02,  1.15it/s] 29%|██▉       | 203/690 [02:56<07:01,  1.15it/s] 30%|██▉       | 204/690 [02:57<07:00,  1.16it/s] 30%|██▉       | 205/690 [02:58<06:59,  1.16it/s] 30%|██▉       | 206/690 [02:59<07:00,  1.15it/s] 30%|███       | 207/690 [02:59<06:57,  1.16it/s] 30%|███       | 208/690 [03:00<06:56,  1.16it/s] 30%|███       | 209/690 [03:01<06:53,  1.16it/s] 30%|███       | 210/690 [03:02<06:55,  1.15it/s] 31%|███       | 211/690 [03:03<06:55,  1.15it/s] 31%|███       | 212/690 [03:04<06:58,  1.14it/s] 31%|███       | 213/690 [03:05<06:58,  1.14it/s] 31%|███       | 214/690 [03:05<06:51,  1.16it/s] 31%|███       | 215/690 [03:06<06:51,  1.16it/s] 31%|███▏      | 216/690 [03:07<06:48,  1.16it/s] 31%|███▏      | 217/690 [03:08<06:47,  1.16it/s] 32%|███▏      | 218/690 [03:09<06:47,  1.16it/s] 32%|███▏      | 219/690 [03:10<06:46,  1.16it/s] 32%|███▏      | 220/690 [03:11<06:45,  1.16it/s] 32%|███▏      | 221/690 [03:11<06:44,  1.16it/s] 32%|███▏      | 222/690 [03:12<06:43,  1.16it/s] 32%|███▏      | 223/690 [03:13<06:42,  1.16it/s] 32%|███▏      | 224/690 [03:14<06:39,  1.17it/s] 33%|███▎      | 225/690 [03:15<06:41,  1.16it/s] 33%|███▎      | 226/690 [03:16<06:41,  1.16it/s] 33%|███▎      | 227/690 [03:17<06:39,  1.16it/s] 33%|███▎      | 228/690 [03:18<06:37,  1.16it/s] 33%|███▎      | 229/690 [03:18<06:38,  1.16it/s] 33%|███▎      | 230/690 [03:19<06:36,  1.16it/s] 33%|███▎      | 231/690 [03:20<06:37,  1.15it/s] 34%|███▎      | 232/690 [03:21<06:35,  1.16it/s] 34%|███▍      | 233/690 [03:22<06:36,  1.15it/s] 34%|███▍      | 234/690 [03:23<06:32,  1.16it/s] 34%|███▍      | 235/690 [03:24<06:31,  1.16it/s] 34%|███▍      | 236/690 [03:24<06:32,  1.16it/s] 34%|███▍      | 237/690 [03:25<06:30,  1.16it/s] 34%|███▍      | 238/690 [03:26<06:28,  1.16it/s] 35%|███▍      | 239/690 [03:27<06:27,  1.16it/s] 35%|███▍      | 240/690 [03:28<06:27,  1.16it/s] 35%|███▍      | 241/690 [03:29<06:26,  1.16it/s] 35%|███▌      | 242/690 [03:30<06:25,  1.16it/s] 35%|███▌      | 243/690 [03:30<06:28,  1.15it/s] 35%|███▌      | 244/690 [03:31<06:24,  1.16it/s] 36%|███▌      | 245/690 [03:32<06:23,  1.16it/s] 36%|███▌      | 246/690 [03:33<06:26,  1.15it/s] 36%|███▌      | 247/690 [03:34<06:25,  1.15it/s] 36%|███▌      | 248/690 [03:35<06:23,  1.15it/s] 36%|███▌      | 249/690 [03:36<06:23,  1.15it/s] 36%|███▌      | 250/690 [03:37<06:21,  1.15it/s] 36%|███▋      | 251/690 [03:37<06:22,  1.15it/s] 37%|███▋      | 252/690 [03:38<06:20,  1.15it/s] 37%|███▋      | 253/690 [03:39<06:20,  1.15it/s] 37%|███▋      | 254/690 [03:40<06:17,  1.15it/s] 37%|███▋      | 255/690 [03:41<06:14,  1.16it/s] 37%|███▋      | 256/690 [03:42<06:18,  1.15it/s] 37%|███▋      | 257/690 [03:43<06:16,  1.15it/s] 37%|███▋      | 258/690 [03:43<06:13,  1.16it/s] 38%|███▊      | 259/690 [03:44<06:12,  1.16it/s] 38%|███▊      | 260/690 [03:45<06:13,  1.15it/s] 38%|███▊      | 261/690 [03:46<06:11,  1.16it/s] 38%|███▊      | 262/690 [03:47<06:07,  1.16it/s] 38%|███▊      | 263/690 [03:48<06:08,  1.16it/s] 38%|███▊      | 264/690 [03:49<06:08,  1.15it/s] 38%|███▊      | 265/690 [03:50<06:05,  1.16it/s] 39%|███▊      | 266/690 [03:50<06:05,  1.16it/s] 39%|███▊      | 267/690 [03:51<06:08,  1.15it/s] 39%|███▉      | 268/690 [03:52<06:07,  1.15it/s] 39%|███▉      | 269/690 [03:53<06:04,  1.16it/s] 39%|███▉      | 270/690 [03:54<06:04,  1.15it/s] 39%|███▉      | 271/690 [03:55<06:02,  1.16it/s] 39%|███▉      | 272/690 [03:56<05:59,  1.16it/s] 40%|███▉      | 273/690 [03:56<06:04,  1.14it/s] 40%|███▉      | 274/690 [03:57<06:01,  1.15it/s] 40%|███▉      | 275/690 [03:58<06:00,  1.15it/s] 40%|████      | 276/690 [03:59<05:59,  1.15it/s] 40%|████      | 277/690 [04:00<05:55,  1.16it/s] 40%|████      | 278/690 [04:01<05:56,  1.16it/s] 40%|████      | 279/690 [04:02<05:57,  1.15it/s] 41%|████      | 280/690 [04:03<05:57,  1.15it/s] 41%|████      | 281/690 [04:03<05:54,  1.15it/s] 41%|████      | 282/690 [04:04<05:57,  1.14it/s] 41%|████      | 283/690 [04:05<05:54,  1.15it/s] 41%|████      | 284/690 [04:06<05:52,  1.15it/s] 41%|████▏     | 285/690 [04:07<05:52,  1.15it/s] 41%|████▏     | 286/690 [04:08<05:49,  1.16it/s] 42%|████▏     | 287/690 [04:09<05:48,  1.16it/s] 42%|████▏     | 288/690 [04:09<05:45,  1.16it/s] 42%|████▏     | 289/690 [04:10<05:44,  1.16it/s] 42%|████▏     | 290/690 [04:11<05:44,  1.16it/s] 42%|████▏     | 291/690 [04:12<05:44,  1.16it/s] 42%|████▏     | 292/690 [04:13<05:43,  1.16it/s] 42%|████▏     | 293/690 [04:14<05:41,  1.16it/s] 43%|████▎     | 294/690 [04:15<05:40,  1.16it/s] 43%|████▎     | 295/690 [04:16<05:41,  1.16it/s] 43%|████▎     | 296/690 [04:16<05:44,  1.14it/s] 43%|████▎     | 297/690 [04:17<05:40,  1.16it/s] 43%|████▎     | 298/690 [04:18<05:41,  1.15it/s] 43%|████▎     | 299/690 [04:19<05:38,  1.15it/s] 43%|████▎     | 300/690 [04:20<05:39,  1.15it/s] 44%|████▎     | 301/690 [04:21<05:38,  1.15it/s] 44%|████▍     | 302/690 [04:22<05:36,  1.15it/s] 44%|████▍     | 303/690 [04:22<05:32,  1.16it/s] 44%|████▍     | 304/690 [04:23<05:34,  1.15it/s] 44%|████▍     | 305/690 [04:24<05:33,  1.16it/s] 44%|████▍     | 306/690 [04:25<05:33,  1.15it/s] 44%|████▍     | 307/690 [04:26<05:32,  1.15it/s] 45%|████▍     | 308/690 [04:27<05:31,  1.15it/s] 45%|████▍     | 309/690 [04:28<05:28,  1.16it/s] 45%|████▍     | 310/690 [04:29<05:29,  1.15it/s] 45%|████▌     | 311/690 [04:29<05:28,  1.16it/s] 45%|████▌     | 312/690 [04:30<05:28,  1.15it/s] 45%|████▌     | 313/690 [04:31<05:27,  1.15it/s] 46%|████▌     | 314/690 [04:32<05:25,  1.15it/s] 46%|████▌     | 315/690 [04:33<05:27,  1.14it/s] 46%|████▌     | 316/690 [04:34<05:22,  1.16it/s] 46%|████▌     | 317/690 [04:35<05:22,  1.16it/s] 46%|████▌     | 318/690 [04:35<05:21,  1.16it/s] 46%|████▌     | 319/690 [04:36<05:22,  1.15it/s] 46%|████▋     | 320/690 [04:37<05:20,  1.16it/s] 47%|████▋     | 321/690 [04:38<05:19,  1.16it/s] 47%|████▋     | 322/690 [04:39<05:18,  1.15it/s] 47%|████▋     | 323/690 [04:40<05:17,  1.15it/s] 47%|████▋     | 324/690 [04:41<05:16,  1.16it/s] 47%|████▋     | 325/690 [04:42<05:15,  1.16it/s] 47%|████▋     | 326/690 [04:42<05:14,  1.16it/s] 47%|████▋     | 327/690 [04:43<05:12,  1.16it/s] 48%|████▊     | 328/690 [04:44<05:12,  1.16it/s] 48%|████▊     | 329/690 [04:45<05:08,  1.17it/s] 48%|████▊     | 330/690 [04:46<05:09,  1.16it/s] 48%|████▊     | 331/690 [04:47<05:09,  1.16it/s] 48%|████▊     | 332/690 [04:48<05:09,  1.16it/s] 48%|████▊     | 333/690 [04:48<05:08,  1.16it/s] 48%|████▊     | 334/690 [04:49<05:09,  1.15it/s] 49%|████▊     | 335/690 [04:50<05:07,  1.15it/s] 49%|████▊     | 336/690 [04:51<05:04,  1.16it/s] 49%|████▉     | 337/690 [04:52<05:07,  1.15it/s] 49%|████▉     | 338/690 [04:53<05:04,  1.16it/s] 49%|████▉     | 339/690 [04:54<05:03,  1.16it/s] 49%|████▉     | 340/690 [04:54<05:03,  1.15it/s] 49%|████▉     | 341/690 [04:55<05:00,  1.16it/s] 50%|████▉     | 342/690 [04:56<05:02,  1.15it/s] 50%|████▉     | 343/690 [04:57<04:59,  1.16it/s] 50%|████▉     | 344/690 [04:58<04:58,  1.16it/s] 50%|█████     | 345/690 [04:59<04:58,  1.16it/s] 50%|█████     | 346/690 [05:00<04:56,  1.16it/s] 50%|█████     | 347/690 [05:00<04:53,  1.17it/s] 50%|█████     | 348/690 [05:01<04:54,  1.16it/s] 51%|█████     | 349/690 [05:02<04:54,  1.16it/s] 51%|█████     | 350/690 [05:03<04:54,  1.16it/s] 51%|█████     | 351/690 [05:04<04:52,  1.16it/s] 51%|█████     | 352/690 [05:05<04:51,  1.16it/s] 51%|█████     | 353/690 [05:06<04:51,  1.16it/s] 51%|█████▏    | 354/690 [05:07<04:49,  1.16it/s] 51%|█████▏    | 355/690 [05:07<04:47,  1.16it/s] 52%|█████▏    | 356/690 [05:08<04:48,  1.16it/s] 52%|█████▏    | 357/690 [05:09<04:48,  1.15it/s] 52%|█████▏    | 358/690 [05:10<04:46,  1.16it/s] 52%|█████▏    | 359/690 [05:11<04:46,  1.16it/s] 52%|█████▏    | 360/690 [05:12<04:44,  1.16it/s] 52%|█████▏    | 361/690 [05:13<04:44,  1.16it/s] 52%|█████▏    | 362/690 [05:13<04:44,  1.15it/s] 53%|█████▎    | 363/690 [05:14<04:41,  1.16it/s] 53%|█████▎    | 364/690 [05:15<04:44,  1.15it/s] 53%|█████▎    | 365/690 [05:16<04:42,  1.15it/s] 53%|█████▎    | 366/690 [05:17<04:40,  1.16it/s] 53%|█████▎    | 367/690 [05:18<04:40,  1.15it/s] 53%|█████▎    | 368/690 [05:19<04:38,  1.16it/s] 53%|█████▎    | 369/690 [05:20<04:36,  1.16it/s] 54%|█████▎    | 370/690 [05:20<04:35,  1.16it/s] 54%|█████▍    | 371/690 [05:21<04:36,  1.15it/s] 54%|█████▍    | 372/690 [05:22<04:34,  1.16it/s] 54%|█████▍    | 373/690 [05:23<04:32,  1.16it/s] 54%|█████▍    | 374/690 [05:24<04:31,  1.16it/s] 54%|█████▍    | 375/690 [05:25<04:31,  1.16it/s] 54%|█████▍    | 376/690 [05:26<04:31,  1.16it/s] 55%|█████▍    | 377/690 [05:26<04:31,  1.15it/s] 55%|█████▍    | 378/690 [05:27<04:30,  1.16it/s] 55%|█████▍    | 379/690 [05:28<04:29,  1.15it/s] 55%|█████▌    | 380/690 [05:29<04:28,  1.15it/s] 55%|█████▌    | 381/690 [05:30<04:26,  1.16it/s] 55%|█████▌    | 382/690 [05:31<04:25,  1.16it/s] 56%|█████▌    | 383/690 [05:32<04:25,  1.16it/s] 56%|█████▌    | 384/690 [05:33<04:26,  1.15it/s] 56%|█████▌    | 385/690 [05:33<04:24,  1.16it/s] 56%|█████▌    | 386/690 [05:34<04:24,  1.15it/s] 56%|█████▌    | 387/690 [05:35<04:22,  1.15it/s] 56%|█████▌    | 388/690 [05:36<04:20,  1.16it/s] 56%|█████▋    | 389/690 [05:37<04:18,  1.16it/s] 57%|█████▋    | 390/690 [05:38<04:20,  1.15it/s] 57%|█████▋    | 391/690 [05:39<04:17,  1.16it/s] 57%|█████▋    | 392/690 [05:39<04:18,  1.15it/s] 57%|█████▋    | 393/690 [05:40<04:16,  1.16it/s] 57%|█████▋    | 394/690 [05:41<04:15,  1.16it/s] 57%|█████▋    | 395/690 [05:42<04:14,  1.16it/s] 57%|█████▋    | 396/690 [05:43<04:14,  1.16it/s] 58%|█████▊    | 397/690 [05:44<04:12,  1.16it/s] 58%|█████▊    | 398/690 [05:45<04:12,  1.16it/s] 58%|█████▊    | 399/690 [05:45<04:09,  1.17it/s] 58%|█████▊    | 400/690 [05:46<04:09,  1.16it/s] 58%|█████▊    | 401/690 [05:47<04:07,  1.17it/s] 58%|█████▊    | 402/690 [05:48<04:08,  1.16it/s] 58%|█████▊    | 403/690 [05:49<04:06,  1.16it/s] 59%|█████▊    | 404/690 [05:50<04:05,  1.17it/s] 59%|█████▊    | 405/690 [05:51<04:06,  1.16it/s] 59%|█████▉    | 406/690 [05:51<04:05,  1.16it/s] 59%|█████▉    | 407/690 [05:52<04:04,  1.16it/s] 59%|█████▉    | 408/690 [05:53<04:02,  1.16it/s] 59%|█████▉    | 409/690 [05:54<04:03,  1.15it/s] 59%|█████▉    | 410/690 [05:55<04:04,  1.15it/s] 60%|█████▉    | 411/690 [05:56<04:02,  1.15it/s] 60%|█████▉    | 412/690 [05:57<04:00,  1.16it/s] 60%|█████▉    | 413/690 [05:58<03:59,  1.16it/s] 60%|██████    | 414/690 [05:58<03:58,  1.16it/s] 60%|██████    | 415/690 [05:59<03:57,  1.16it/s] 60%|██████    | 416/690 [06:00<03:56,  1.16it/s] 60%|██████    | 417/690 [06:01<03:55,  1.16it/s] 61%|██████    | 418/690 [06:02<03:54,  1.16it/s] 61%|██████    | 419/690 [06:03<03:55,  1.15it/s] 61%|██████    | 420/690 [06:04<03:53,  1.16it/s] 61%|██████    | 421/690 [06:04<03:53,  1.15it/s] 61%|██████    | 422/690 [06:05<03:52,  1.15it/s] 61%|██████▏   | 423/690 [06:06<03:51,  1.15it/s] 61%|██████▏   | 424/690 [06:07<03:48,  1.16it/s] 62%|██████▏   | 425/690 [06:08<03:48,  1.16it/s] 62%|██████▏   | 426/690 [06:09<03:49,  1.15it/s] 62%|██████▏   | 427/690 [06:10<03:47,  1.16it/s] 62%|██████▏   | 428/690 [06:10<03:45,  1.16it/s] 62%|██████▏   | 429/690 [06:11<03:45,  1.16it/s] 62%|██████▏   | 430/690 [06:12<03:43,  1.16it/s] 62%|██████▏   | 431/690 [06:13<03:42,  1.16it/s] 63%|██████▎   | 432/690 [06:14<03:43,  1.15it/s] 63%|██████▎   | 433/690 [06:15<03:41,  1.16it/s] 63%|██████▎   | 434/690 [06:16<03:40,  1.16it/s] 63%|██████▎   | 435/690 [06:17<03:39,  1.16it/s] 63%|██████▎   | 436/690 [06:17<03:37,  1.17it/s] 63%|██████▎   | 437/690 [06:18<03:37,  1.16it/s] 63%|██████▎   | 438/690 [06:19<03:36,  1.16it/s] 64%|██████▎   | 439/690 [06:20<03:37,  1.16it/s] 64%|██████▍   | 440/690 [06:21<03:36,  1.16it/s] 64%|██████▍   | 441/690 [06:22<03:35,  1.16it/s] 64%|██████▍   | 442/690 [06:23<03:34,  1.15it/s] 64%|██████▍   | 443/690 [06:23<03:34,  1.15it/s] 64%|██████▍   | 444/690 [06:24<03:32,  1.16it/s] 64%|██████▍   | 445/690 [06:25<03:31,  1.16it/s] 65%|██████▍   | 446/690 [06:26<03:29,  1.16it/s] 65%|██████▍   | 447/690 [06:27<03:29,  1.16it/s] 65%|██████▍   | 448/690 [06:28<03:29,  1.15it/s] 65%|██████▌   | 449/690 [06:29<03:27,  1.16it/s] 65%|██████▌   | 450/690 [06:29<03:27,  1.15it/s] 65%|██████▌   | 451/690 [06:30<03:27,  1.15it/s] 66%|██████▌   | 452/690 [06:31<03:26,  1.15it/s] 66%|██████▌   | 453/690 [06:32<03:25,  1.16it/s] 66%|██████▌   | 454/690 [06:33<03:25,  1.15it/s] 66%|██████▌   | 455/690 [06:34<03:23,  1.16it/s] 66%|██████▌   | 456/690 [06:35<03:22,  1.15it/s] 66%|██████▌   | 457/690 [06:36<03:20,  1.16it/s] 66%|██████▋   | 458/690 [06:36<03:19,  1.16it/s] 67%|██████▋   | 459/690 [06:37<03:19,  1.16it/s] 67%|██████▋   | 460/690 [06:38<03:17,  1.16it/s] 67%|██████▋   | 461/690 [06:39<03:16,  1.16it/s] 67%|██████▋   | 462/690 [06:40<03:16,  1.16it/s] 67%|██████▋   | 463/690 [06:41<03:15,  1.16it/s] 67%|██████▋   | 464/690 [06:42<03:14,  1.16it/s] 67%|██████▋   | 465/690 [06:42<03:13,  1.17it/s] 68%|██████▊   | 466/690 [06:43<03:12,  1.16it/s] 68%|██████▊   | 467/690 [06:44<03:11,  1.17it/s] 68%|██████▊   | 468/690 [06:45<03:11,  1.16it/s] 68%|██████▊   | 469/690 [06:46<03:10,  1.16it/s] 68%|██████▊   | 470/690 [06:47<03:10,  1.16it/s] 68%|██████▊   | 471/690 [06:48<03:09,  1.15it/s] 68%|██████▊   | 472/690 [06:48<03:08,  1.16it/s] 69%|██████▊   | 473/690 [06:49<03:08,  1.15it/s] 69%|██████▊   | 474/690 [06:50<03:08,  1.15it/s] 69%|██████▉   | 475/690 [06:51<03:06,  1.15it/s] 69%|██████▉   | 476/690 [06:52<03:05,  1.16it/s] 69%|██████▉   | 477/690 [06:53<03:05,  1.15it/s] 69%|██████▉   | 478/690 [06:54<03:03,  1.15it/s] 69%|██████▉   | 479/690 [06:55<03:03,  1.15it/s] 70%|██████▉   | 480/690 [06:55<03:02,  1.15it/s] 70%|██████▉   | 481/690 [06:56<03:00,  1.16it/s] 70%|██████▉   | 482/690 [06:57<02:59,  1.16it/s] 70%|███████   | 483/690 [06:58<02:59,  1.15it/s] 70%|███████   | 484/690 [06:59<02:58,  1.16it/s] 70%|███████   | 485/690 [07:00<02:57,  1.16it/s] 70%|███████   | 486/690 [07:01<02:56,  1.15it/s] 71%|███████   | 487/690 [07:01<02:56,  1.15it/s] 71%|███████   | 488/690 [07:02<02:54,  1.16it/s] 71%|███████   | 489/690 [07:03<02:53,  1.16it/s] 71%|███████   | 490/690 [07:04<02:53,  1.15it/s] 71%|███████   | 491/690 [07:05<02:52,  1.15it/s] 71%|███████▏  | 492/690 [07:06<02:51,  1.16it/s] 71%|███████▏  | 493/690 [07:07<02:50,  1.16it/s] 72%|███████▏  | 494/690 [07:08<02:49,  1.15it/s] 72%|███████▏  | 495/690 [07:08<02:48,  1.16it/s] 72%|███████▏  | 496/690 [07:09<02:48,  1.15it/s] 72%|███████▏  | 49{'loss': 0.6291, 'learning_rate': 1.3768115942028985e-05, 'epoch': 2.17}
7/690 [07:10<02:47,  1.15it/s] 72%|███████▏  | 498/690 [07:11<02:46,  1.16it/s] 72%|███████▏  | 499/690 [07:12<02:45,  1.15it/s] 72%|███████▏  | 500/690 [07:13<02:43,  1.16it/s]                                                  72%|███████▏  | 500/690 [07:13<02:43,  1.16it/s][INFO|trainer.py:2985] 2024-02-12 20:11:21,067 >> Saving model checkpoint to /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500
[INFO|configuration_utils.py:473] 2024-02-12 20:11:21,080 >> Configuration saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500/config.json
[INFO|modeling_utils.py:2462] 2024-02-12 20:11:42,573 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-02-12 20:11:42,575 >> tokenizer config file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-02-12 20:11:42,576 >> Special tokens file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500/special_tokens_map.json
 73%|███████▎  | 501/690 [08:18<1:04:01, 20.32s/it] 73%|███████▎  | 502/690 [08:19<45:24, 14.49s/it]   73%|███████▎  | 503/690 [08:20<32:25, 10.40s/it] 73%|███████▎  | 504/690 [08:21<23:22,  7.54s/it] 73%|███████▎  | 505/690 [08:22<17:04,  5.54s/it] 73%|███████▎  | 506/690 [08:23<12:39,  4.13s/it] 73%|███████▎  | 507/690 [08:24<09:34,  3.14s/it] 74%|███████▎  | 508/690 [08:24<07:26,  2.45s/it] 74%|███████▍  | 509/690 [08:25<05:58,  1.98s/it] 74%|███████▍  | 510/690 [08:26<04:54,  1.64s/it] 74%|███████▍  | 511/690 [08:27<04:12,  1.41s/it] 74%|███████▍  | 512/690 [08:28<03:40,  1.24s/it] 74%|███████▍  | 513/690 [08:29<03:18,  1.12s/it] 74%|███████▍  | 514/690 [08:30<03:03,  1.04s/it] 75%|███████▍  | 515/690 [08:30<02:53,  1.01it/s] 75%|███████▍  | 516/690 [08:31<02:45,  1.05it/s] 75%|███████▍  | 517/690 [08:32<02:38,  1.09it/s] 75%|███████▌  | 518/690 [08:33<02:34,  1.11it/s] 75%|███████▌  | 519/690 [08:34<02:32,  1.12it/s] 75%|███████▌  | 520/690 [08:35<02:29,  1.13it/s] 76%|███████▌  | 521/690 [08:36<02:28,  1.14it/s] 76%|███████▌  | 522/690 [08:36<02:26,  1.15it/s] 76%|███████▌  | 523/690 [08:37<02:24,  1.15it/s] 76%|███████▌  | 524/690 [08:38<02:23,  1.15it/s] 76%|███████▌  | 525/690 [08:39<02:23,  1.15it/s] 76%|███████▌  | 526/690 [08:40<02:21,  1.16it/s] 76%|███████▋  | 527/690 [08:41<02:20,  1.16it/s] 77%|███████▋  | 528/690 [08:42<02:19,  1.16it/s] 77%|███████▋  | 529/690 [08:43<02:19,  1.16it/s] 77%|███████▋  | 530/690 [08:43<02:17,  1.17it/s] 77%|███████▋  | 531/690 [08:44<02:16,  1.16it/s] 77%|███████▋  | 532/690 [08:45<02:15,  1.16it/s] 77%|███████▋  | 533/690 [08:46<02:14,  1.17it/s] 77%|███████▋  | 534/690 [08:47<02:14,  1.16it/s] 78%|███████▊  | 535/690 [08:48<02:12,  1.17it/s] 78%|███████▊  | 536/690 [08:49<02:13,  1.16it/s] 78%|███████▊  | 537/690 [08:49<02:11,  1.16it/s] 78%|███████▊  | 538/690 [08:50<02:10,  1.16it/s] 78%|███████▊  | 539/690 [08:51<02:10,  1.16it/s] 78%|███████▊  | 540/690 [08:52<02:09,  1.15it/s] 78%|███████▊  | 541/690 [08:53<02:08,  1.16it/s] 79%|███████▊  | 542/690 [08:54<02:07,  1.16it/s] 79%|███████▊  | 543/690 [08:55<02:06,  1.16it/s] 79%|███████▉  | 544/690 [08:55<02:05,  1.16it/s] 79%|███████▉  | 545/690 [08:56<02:04,  1.17it/s] 79%|███████▉  | 546/690 [08:57<02:02,  1.17it/s] 79%|███████▉  | 547/690 [08:58<02:02,  1.16it/s] 79%|███████▉  | 548/690 [08:59<02:01,  1.17it/s] 80%|███████▉  | 549/690 [09:00<02:01,  1.16it/s] 80%|███████▉  | 550/690 [09:01<02:00,  1.16it/s] 80%|███████▉  | 551/690 [09:01<01:58,  1.17it/s] 80%|████████  | 552/690 [09:02<01:59,  1.16it/s] 80%|████████  | 553/690 [09:03<01:57,  1.16it/s] 80%|████████  | 554/690 [09:04<01:57,  1.16it/s] 80%|████████  | 555/690 [09:05<01:56,  1.16it/s] 81%|████████  | 556/690 [09:06<01:56,  1.15it/s] 81%|████████  | 557/690 [09:07<01:54,  1.16it/s] 81%|████████  | 558/690 [09:07<01:53,  1.16it/s] 81%|████████  | 559/690 [09:08<01:53,  1.15it/s] 81%|████████  | 560/690 [09:09<01:52,  1.16it/s] 81%|████████▏ | 561/690 [09:10<01:52,  1.15it/s] 81%|████████▏ | 562/690 [09:11<01:50,  1.16it/s] 82%|████████▏ | 563/690 [09:12<01:50,  1.15it/s] 82%|████████▏ | 564/690 [09:13<01:49,  1.15it/s] 82%|████████▏ | 565/690 [09:14<01:47,  1.16it/s] 82%|████████▏ | 566/690 [09:14<01:47,  1.16it/s] 82%|████████▏ | 567/690 [09:15<01:45,  1.16it/s] 82%|████████▏ | 568/690 [09:16<01:44,  1.17it/s] 82%|████████▏ | 569/690 [09:17<01:43,  1.17it/s] 83%|████████▎ | 570/690 [09:18<01:43,  1.16it/s] 83%|████████▎ | 571/690 [09:19<01:42,  1.16it/s] 83%|████████▎ | 572/690 [09:20<01:41,  1.16it/s] 83%|████████▎ | 573/690 [09:20<01:41,  1.15it/s] 83%|████████▎ | 574/690 [09:21<01:40,  1.16it/s] 83%|████████▎ | 575/690 [09:22<01:39,  1.15it/s] 83%|████████▎ | 576/690 [09:23<01:38,  1.16it/s] 84%|████████▎ | 577/690 [09:24<01:37,  1.16it/s] 84%|████████▍ | 578/690 [09:25<01:36,  1.17it/s] 84%|████████▍ | 579/690 [09:26<01:35,  1.16it/s] 84%|████████▍ | 580/690 [09:26<01:35,  1.15it/s] 84%|████████▍ | 581/690 [09:27<01:33,  1.16it/s] 84%|████████▍ | 582/690 [09:28<01:33,  1.16it/s] 84%|████████▍ | 583/690 [09:29<01:33,  1.15it/s] 85%|████████▍ | 584/690 [09:30<01:31,  1.16it/s] 85%|████████▍ | 585/690 [09:31<01:31,  1.15it/s] 85%|████████▍ | 586/690 [09:32<01:29,  1.16it/s] 85%|████████▌ | 587/690 [09:32<01:28,  1.17it/s] 85%|████████▌ | 588/690 [09:33<01:27,  1.17it/s] 85%|████████▌ | 589/690 [09:34<01:27,  1.16it/s] 86%|████████▌ | 590/690 [09:35<01:25,  1.17it/s] 86%|████████▌ | 591/690 [09:36<01:25,  1.16it/s] 86%|████████▌ | 592/690 [09:37<01:24,  1.16it/s] 86%|████████▌ | 593/690 [09:38<01:23,  1.16it/s] 86%|████████▌ | 594/690 [09:39<01:22,  1.16it/s] 86%|████████▌ | 595/690 [09:39<01:21,  1.16it/s] 86%|████████▋ | 596/690 [09:40<01:21,  1.16it/s] 87%|████████▋ | 597/690 [09:41<01:19,  1.17it/s] 87%|████████▋ | 598/690 [09:42<01:18,  1.17it/s] 87%|████████▋ | 599/690 [09:43<01:18,  1.16it/s] 87%|████████▋ | 600/690 [09:44<01:17,  1.16it/s] 87%|████████▋ | 601/690 [09:45<01:16,  1.17it/s] 87%|████████▋ | 602/690 [09:45<01:15,  1.16it/s] 87%|████████▋ | 603/690 [09:46<01:15,  1.16it/s] 88%|████████▊ | 604/690 [09:47<01:14,  1.16it/s] 88%|████████▊ | 605/690 [09:48<01:13,  1.16it/s] 88%|████████▊ | 606/690 [09:49<01:12,  1.15it/s] 88%|████████▊ | 607/690 [09:50<01:11,  1.16it/s] 88%|████████▊ | 608/690 [09:51<01:11,  1.15it/s] 88%|████████▊ | 609/690 [09:51<01:09,  1.16it/s] 88%|████████▊ | 610/690 [09:52<01:08,  1.16it/s] 89%|████████▊ | 611/690 [09:53<01:08,  1.16it/s] 89%|████████▊ | 612/690 [09:54<01:06,  1.17it/s] 89%|████████▉ | 613/690 [09:55<01:06,  1.16it/s] 89%|████████▉ | 614/690 [09:56<01:05,  1.17it/s] 89%|████████▉ | 615/690 [09:57<01:04,  1.16it/s] 89%|████████▉ | 616/690 [09:57<01:03,  1.16it/s] 89%|████████▉ | 617/690 [09:58<01:02,  1.17it/s] 90%|████████▉ | 618/690 [09:59<01:01,  1.16it/s] 90%|████████▉ | 619/690 [10:00<01:01,  1.16it/s] 90%|████████▉ | 620/690 [10:01<01:00,  1.16it/s] 90%|█████████ | 621/690 [10:02<00:59,  1.15it/s] 90%|█████████ | 622/690 [10:03<00:58,  1.16it/s] 90%|█████████ | 623/690 [10:04<00:57,  1.16it/s] 90%|█████████ | 624/690 [10:04<00:56,  1.16it/s] 91%|█████████ | 625/690 [10:05<00:56,  1.16it/s] 91%|█████████ | 626/690 [10:06<00:55,  1.16it/s] 91%|█████████ | 627/690 [10:07<00:54,  1.16it/s] 91%|█████████ | 628/690 [10:08<00:53,  1.16it/s] 91%|█████████ | 629/690 [10:09<00:52,  1.16it/s] 91%|█████████▏| 630/690 [10:10<00:51,  1.17it/s] 91%|█████████▏| 631/690 [10:10<00:50,  1.16it/s] 92%|█████████▏| 632/690 [10:11<00:50,  1.15it/s] 92%|█████████▏| 633/690 [10:12<00:49,  1.15it/s] 92%|█████████▏| 634/690 [10:13<00:48,  1.16it/s] 92%|█████████▏| 635/690 [10:14<00:47,  1.15it/s] 92%|█████████▏| 636/690 [10:15<00:46,  1.16it/s] 92%|█████████▏| 637/690 [10:16<00:45,  1.15it/s] 92%|█████████▏| 638/690 [10:16<00:44,  1.16it/s] 93%|█████████▎| 639/690 [10:17<00:44,  1.16it/s] 93%|█████████▎| 640/690 [10:18<00:43,  1.16it/s] 93%|█████████▎| 641/690 [10:19<00:42,  1.15it/s] 93%|█████████▎| 642/690 [10:20<00:41,  1.16it/s] 93%|█████████▎| 643/690 [10:21<00:40,  1.15it/s] 93%|█████████▎| 644/690 [10:22<00:39,  1.16it/s] 93%|█████████▎| 645/690 [10:23<00:39,  1.15it/s] 94%|█████████▎| 646/690 [10:23<00:38,  1.16it/s] 94%|█████████▍| 647/690 [10:24<00:37,  1.15it/s] 94%|█████████▍| 648/690 [10:25<00:36,  1.16it/s] 94%|█████████▍| 649/690 [10:26<00:35,  1.15it/s] 94%|█████████▍| 650/690 [10:27<00:34,  1.15it/s] 94%|█████████▍| 651/690 [10:28<00:33,  1.15it/s] 94%|█████████▍| 652/690 [10:29<00:32,  1.15it/s] 95%|█████████▍| 653/690 [10:29<00:32,  1.15it/s] 95%|█████████▍| 654/690 [10:30<00:31,  1.15it/s] 95%|█████████▍| 655/690 [10:31<00:30,  1.14it/s] 95%|█████████▌| 656/690 [10:32<00:29,  1.15it/s] 95%|█████████▌| 657/690 [10:33<00:28,  1.16it/s] 95%|█████████▌| 658/690 [10:34<00:27,  1.16it/s] 96%|█████████▌| 659/690 [10:35<00:26,  1.15it/s] 96%|█████████▌| 660/690 [10:36<00:26,  1.15it/s] 96%|█████████▌| 661/690 [10:36<00:24,  1.16it/s] 96%|█████████▌| 662/690 [10:37<00:24,  1.16it/s] 96%|█████████▌| 663/690 [10:38<00:23,  1.15it/s] 96%|█████████▌| 664/690 [10:39<00:22,  1.16it/s] 96%|█████████▋| 665/690 [10:40<00:21,  1.17it/s] 97%|█████████▋| 666/690 [10:41<00:20,  1.16it/s] 97%|█████████▋| 667/690 [10:42<00:19,  1.16it/s] 97%|█████████▋| 668/690 [10:42<00:19,  1.15it/s] 97%|█████████▋| 669/690 [10:43<00:18,  1.16it/s] 97%|█████████▋| 670/690 [10:44<00:17,  1.16it/s] 97%|█████████▋| 671/690 [10:45<00:16,  1.15it/s] 97%|█████████▋| 672/690 [10:46<00:15,  1.16it/s] 98%|█████████▊| 673/690 [10:47<00:14,  1.15it/s] 98%|█████████▊| 674/690 [10:48<00:13,  1.16it/s] 98%|█████████▊| 675/690 [10:48<00:12,  1.16it/s] 98%|█████████▊| 676/690 [10:49<00:12,  1.16it/s] 98%|█████████▊| 677/690 [10:50<00:11,  1.16it/s] 98%|█████████▊| 678/690 [10:51<00:10,  1.15it/s] 98%|█████████▊| 679/690 [10:52<00:09,  1.16it/s] 99%|█████████▊| 680/690 [10:53<00:08,  1.15it/s] 99%|█████████▊| 681/690 [10:54<00:07,  1.15it/s] 99%|█████████▉| 682/690 [10:55<00:06,  1.16it/s] 99%|█████████▉| 683/690 [10:55<00:06,  1.15it/s] 99%|█████████▉| 684/690 [10:56<00:05,  1.15it/s] 99%|█████████▉| 685/690 [10:57<00:04,  1.15it/s] 99%|█████████▉| 686/690 [10:58<00:03,  1.16it/s]100%|█████████▉| 687/690 [10:59<00:02,  1.15it/s]100%|█████████▉| 688/690 [11:00<00:01,  1.16it/s]100%|█████████▉| 689/690 [11:01<00:00,  1.16it/s]100%|██████████| 690/690 [11:01<00:00,  1.16it/s][INFO|trainer.py:1988] 2024-02-12 20:15:09,628 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


{'train_runtime': 662.1755, 'train_samples_per_second': 16.618, 'train_steps_per_second': 1.042, 'train_loss': 0.5416578209918478, 'epoch': 3.0}
                                                 100%|██████████| 690/690 [11:02<00:00,  1.16it/s]100%|██████████| 690/690 [11:02<00:00,  1.04it/s]
[INFO|trainer.py:2985] 2024-02-12 20:15:09,767 >> Saving model checkpoint to /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola
[INFO|configuration_utils.py:473] 2024-02-12 20:15:09,769 >> Configuration saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/config.json
[INFO|modeling_utils.py:2462] 2024-02-12 20:15:35,697 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-02-12 20:15:35,699 >> tokenizer config file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-02-12 20:15:35,700 >> Special tokens file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/special_tokens_map.json
***** train metrics *****
  epoch                    =        3.0
  train_loss               =     0.5417
  train_runtime            = 0:11:02.17
  train_samples            =       3668
  train_samples_per_second =     16.618
  train_steps_per_second   =      1.042
02/12/2024 20:15:35 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:737] 2024-02-12 20:15:35,762 >> The following columns in the evaluation set don't have a corresponding argument in `LlamaForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `LlamaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3291] 2024-02-12 20:15:35,765 >> ***** Running Evaluation *****
[INFO|trainer.py:3293] 2024-02-12 20:15:35,765 >>   Num examples = 408
[INFO|trainer.py:3296] 2024-02-12 20:15:35,765 >>   Batch size = 8
  0%|          | 0/26 [00:00<?, ?it/s]  8%|▊         | 2/26 [00:00<00:02,  8.31it/s] 12%|█▏        | 3/26 [00:00<00:04,  5.60it/s] 15%|█▌        | 4/26 [00:00<00:04,  4.96it/s] 19%|█▉        | 5/26 [00:00<00:04,  4.66it/s] 23%|██▎       | 6/26 [00:01<00:04,  4.44it/s] 27%|██▋       | 7/26 [00:01<00:04,  4.22it/s] 31%|███       | 8/26 [00:01<00:04,  4.15it/s] 35%|███▍      | 9/26 [00:01<00:04,  4.14it/s] 38%|███▊      | 10/26 [00:02<00:03,  4.05it/s] 42%|████▏     | 11/26 [00:02<00:03,  4.08it/s] 46%|████▌     | 12/26 [00:02<00:03,  4.01it/s] 50%|█████     | 13/26 [00:02<00:03,  4.05it/s] 54%|█████▍    | 14/26 [00:03<00:02,  4.05it/s] 58%|█████▊    | 15/26 [00:03<00:02,  4.08it/s] 62%|██████▏   | 16/26 [00:03<00:02,  4.02it/s] 65%|██████▌   | 17/26 [00:03<00:02,  3.98it/s] 69%|██████▉   | 18/26 [00:04<00:01,  4.01it/s] 73%|███████▎  | 19/26 [00:04<00:01,  3.98it/s] 77%|███████▋  | 20/26 [00:04<00:01,  3.87it/s] 81%|████████  | 21/26 [00:05<00:01,  3.92it/s] 85%|████████▍ | 22/26 [00:05<00:00,  4.00it/s] 88%|████████▊ | 23/26 [00:05<00:00,  3.94it/s] 92%|█████████▏| 24/26 [00:05<00:00,  3.94it/s] 96%|█████████▌| 25/26 [00:06<00:00,  3.98it/s]100%|██████████| 26/26 [00:06<00:00,  4.04it/s]100%|██████████| 26/26 [00:06<00:00,  4.08it/s]
***** eval metrics *****
  epoch                   =        3.0
  eval_accuracy           =     0.7132
  eval_combined_score     =     0.7576
  eval_f1                 =      0.802
  eval_loss               =     0.8239
  eval_runtime            = 0:00:06.62
  eval_samples            =        408
  eval_samples_per_second =     61.601
  eval_steps_per_second   =      3.926
/usr/bin/bash: line 1: --token: command not found
srun: error: v010: task 0: Exited with exit code 127
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/jet/home/mmisra/miniconda3/envs/benchmark/lib/python3.8/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/jet/home/mmisra/miniconda3/envs/benchmark/lib/python3.8/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
02/12/2024 20:18:26 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
02/12/2024 20:18:26 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/runs/Feb12_20-18-26_v010.ib.bridges2.psc.edu,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
output_dir=/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
02/12/2024 20:18:27 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, 16-bits training: False
Downloading data:   0%|          | 0.00/251k [00:00<?, ?B/s]Downloading data: 100%|██████████| 251k/251k [00:00<00:00, 740kB/s]Downloading data: 100%|██████████| 251k/251k [00:00<00:00, 739kB/s]
Downloading data:   0%|          | 0.00/37.6k [00:00<?, ?B/s]Downloading data: 100%|██████████| 37.6k/37.6k [00:00<00:00, 501kB/s]
Downloading data:   0%|          | 0.00/37.7k [00:00<?, ?B/s]Downloading data: 100%|██████████| 37.7k/37.7k [00:00<00:00, 416kB/s]
Generating train split:   0%|          | 0/8551 [00:00<?, ? examples/s]Generating train split: 100%|██████████| 8551/8551 [00:00<00:00, 295885.74 examples/s]
Generating validation split:   0%|          | 0/1043 [00:00<?, ? examples/s]Generating validation split: 100%|██████████| 1043/1043 [00:00<00:00, 383170.63 examples/s]
Generating test split:   0%|          | 0/1063 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 1063/1063 [00:00<00:00, 473507.34 examples/s]
Found cached dataset glue (/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)
02/12/2024 20:18:29 - INFO - datasets.builder - Found cached dataset glue (/ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)
Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
02/12/2024 20:18:29 - INFO - datasets.info - Loading Dataset info from /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c
[INFO|configuration_utils.py:729] 2024-02-12 20:18:29,352 >> loading configuration file config.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/config.json
[INFO|configuration_utils.py:792] 2024-02-12 20:18:29,354 >> Model config LlamaConfig {
  "_name_or_path": "datajuicer/LLaMA-1B-dj-refine-100B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "finetuning_task": "cola",
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5504,
  "max_position_embeddings": 2048,
  "max_sequence_length": 2048,
  "model_type": "llama",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_key_value_heads": 16,
  "pad_token_id": 32004,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.38.0.dev0",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:18:29,392 >> loading file tokenizer.model from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/tokenizer.model
[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:18:29,392 >> loading file tokenizer.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/tokenizer.json
[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:18:29,392 >> loading file added_tokens.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/added_tokens.json
[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:18:29,393 >> loading file special_tokens_map.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/special_tokens_map.json
[INFO|tokenization_utils_base.py:2029] 2024-02-12 20:18:29,393 >> loading file tokenizer_config.json from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/tokenizer_config.json
[WARNING|logging.py:314] 2024-02-12 20:18:29,480 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING|logging.py:314] 2024-02-12 20:18:29,498 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|modeling_utils.py:3259] 2024-02-12 20:18:29,594 >> loading weights file pytorch_model.bin from cache at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/models--datajuicer--LLaMA-1B-dj-refine-100B/snapshots/1bd6974aad6057a3e17b69fa4f818c07aedeae51/pytorch_model.bin
[WARNING|modeling_utils.py:3996] 2024-02-12 20:18:36,451 >> Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at datajuicer/LLaMA-1B-dj-refine-100B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|modeling_utils.py:3984] 2024-02-12 20:18:36,452 >> Some weights of the model checkpoint at datajuicer/LLaMA-1B-dj-refine-100B were not used when initializing LlamaForSequenceClassification: ['lm_head.weight']
- This IS expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:3996] 2024-02-12 20:18:36,452 >> Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at datajuicer/LLaMA-1B-dj-refine-100B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Running tokenizer on dataset:   0%|          | 0/8551 [00:00<?, ? examples/s]Caching processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-a1d80642fea3478e.arrow
02/12/2024 20:18:36 - INFO - datasets.arrow_dataset - Caching processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-a1d80642fea3478e.arrow
Running tokenizer on dataset:  23%|██▎       | 2000/8551 [00:00<00:00, 6945.65 examples/s]Running tokenizer on dataset:  47%|████▋     | 4000/8551 [00:00<00:00, 10225.64 examples/s]Running tokenizer on dataset:  70%|███████   | 6000/8551 [00:00<00:00, 11798.35 examples/s]Running tokenizer on dataset:  94%|█████████▎| 8000/8551 [00:00<00:00, 12852.08 examples/s]Running tokenizer on dataset: 100%|██████████| 8551/8551 [00:00<00:00, 11652.99 examples/s]
Running tokenizer on dataset:   0%|          | 0/1043 [00:00<?, ? examples/s]Caching processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-37f47d5615610b8a.arrow
02/12/2024 20:18:37 - INFO - datasets.arrow_dataset - Caching processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-37f47d5615610b8a.arrow
Running tokenizer on dataset: 100%|██████████| 1043/1043 [00:00<00:00, 12970.72 examples/s]
Running tokenizer on dataset:   0%|          | 0/1063 [00:00<?, ? examples/s]Caching processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-7e7254e584eca33f.arrow
02/12/2024 20:18:37 - INFO - datasets.arrow_dataset - Caching processed dataset at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/hg_cache/glue/cola/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-7e7254e584eca33f.arrow
Running tokenizer on dataset: 100%|██████████| 1063/1063 [00:00<00:00, 12840.99 examples/s]
02/12/2024 20:18:38 - INFO - __main__ - Sample 1824 of the training set: {'sentence': 'I acknowledged that my father, he was tight as an owl.', 'label': 0, 'idx': 1824, 'input_ids': [32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 1, 306, 24084, 3192, 393, 590, 4783, 29892, 540, 471, 19932, 408, 385, 8152, 29880, 29889], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
02/12/2024 20:18:38 - INFO - __main__ - Sample 409 of the training set: {'sentence': 'For him to do that would be a mistake.', 'label': 1, 'idx': 409, 'input_ids': [32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 1, 1152, 1075, 304, 437, 393, 723, 367, 263, 10171, 29889], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
02/12/2024 20:18:38 - INFO - __main__ - Sample 4506 of the training set: {'sentence': 'Mary sang a song, but Lee never did.', 'label': 1, 'idx': 4506, 'input_ids': [32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 32004, 1, 6182, 13625, 263, 4823, 29892, 541, 9371, 2360, 1258, 29889], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
Running tokenizer on dataset:   0%|          | 0/1043 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 1043/1043 [00:00<00:00, 10286.61 examples/s]
02/12/2024 20:18:38 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:737] 2024-02-12 20:18:41,192 >> The following columns in the training set don't have a corresponding argument in `LlamaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `LlamaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:1747] 2024-02-12 20:18:41,683 >> ***** Running training *****
[INFO|trainer.py:1748] 2024-02-12 20:18:41,683 >>   Num examples = 8,551
[INFO|trainer.py:1749] 2024-02-12 20:18:41,683 >>   Num Epochs = 3
[INFO|trainer.py:1750] 2024-02-12 20:18:41,683 >>   Instantaneous batch size per device = 8
[INFO|trainer.py:1753] 2024-02-12 20:18:41,683 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:1754] 2024-02-12 20:18:41,684 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1755] 2024-02-12 20:18:41,684 >>   Total optimization steps = 1,605
[INFO|trainer.py:1756] 2024-02-12 20:18:41,684 >>   Number of trainable parameters = 1,280,153,600
  0%|          | 0/1605 [00:00<?, ?it/s][rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/1605 [00:02<1:07:59,  2.54s/it]  0%|          | 2/1605 [00:03<40:10,  1.50s/it]    0%|          | 3/1605 [00:04<32:00,  1.20s/it]  0%|          | 4/1605 [00:05<28:16,  1.06s/it]  0%|          | 5/1605 [00:05<26:12,  1.02it/s]  0%|          | 6/1605 [00:06<24:57,  1.07it/s]  0%|          | 7/1605 [00:07<24:19,  1.10it/s]  0%|          | 8/1605 [00:08<23:38,  1.13it/s]  1%|          | 9/1605 [00:09<23:11,  1.15it/s]  1%|          | 10/1605 [00:10<22:55,  1.16it/s]  1%|          | 11/1605 [00:10<22:50,  1.16it/s]  1%|          | 12/1605 [00:11<22:33,  1.18it/s]  1%|          | 13/1605 [00:12<22:42,  1.17it/s]  1%|          | 14/1605 [00:13<22:36,  1.17it/s]  1%|          | 15/1605 [00:14<22:37,  1.17it/s]  1%|          | 16/1605 [00:15<22:36,  1.17it/s]  1%|          | 17/1605 [00:16<22:29,  1.18it/s]  1%|          | 18/1605 [00:16<22:38,  1.17it/s]  1%|          | 19/1605 [00:17<22:31,  1.17it/s]  1%|          | 20/1605 [00:18<22:25,  1.18it/s]  1%|▏         | 21/1605 [00:19<22:27,  1.18it/s]  1%|▏         | 22/1605 [00:20<22:30,  1.17it/s]  1%|▏         | 23/1605 [00:21<22:23,  1.18it/s]  1%|▏         | 24/1605 [00:21<22:20,  1.18it/s]  2%|▏         | 25/1605 [00:22<22:15,  1.18it/s]  2%|▏         | 26/1605 [00:23<22:12,  1.18it/s]  2%|▏         | 27/1605 [00:24<22:22,  1.18it/s]  2%|▏         | 28/1605 [00:25<22:14,  1.18it/s]  2%|▏         | 29/1605 [00:26<22:23,  1.17it/s]  2%|▏         | 30/1605 [00:27<22:30,  1.17it/s]  2%|▏         | 31/1605 [00:27<22:24,  1.17it/s]  2%|▏         | 32/1605 [00:28<22:23,  1.17it/s]  2%|▏         | 33/1605 [00:29<22:34,  1.16it/s]  2%|▏         | 34/1605 [00:30<22:23,  1.17it/s]  2%|▏         | 35/1605 [00:31<22:34,  1.16it/s]  2%|▏         | 36/1605 [00:32<22:24,  1.17it/s]  2%|▏         | 37/1605 [00:33<22:19,  1.17it/s]  2%|▏         | 38/1605 [00:33<22:17,  1.17it/s]  2%|▏         | 39/1605 [00:34<22:19,  1.17it/s]  2%|▏         | 40/1605 [00:35<22:21,  1.17it/s]  3%|▎         | 41/1605 [00:36<22:27,  1.16it/s]  3%|▎         | 42/1605 [00:37<22:17,  1.17it/s]  3%|▎         | 43/1605 [00:38<22:15,  1.17it/s]  3%|▎         | 44/1605 [00:39<22:11,  1.17it/s]  3%|▎         | 45/1605 [00:39<22:11,  1.17it/s]  3%|▎         | 46/1605 [00:40<22:07,  1.17it/s]  3%|▎         | 47/1605 [00:41<21:59,  1.18it/s]  3%|▎         | 48/1605 [00:42<21:58,  1.18it/s]  3%|▎         | 49/1605 [00:43<22:15,  1.17it/s]  3%|▎         | 50/1605 [00:44<22:15,  1.16it/s]  3%|▎         | 51/1605 [00:45<22:05,  1.17it/s]  3%|▎         | 52/1605 [00:45<21:58,  1.18it/s]  3%|▎         | 53/1605 [00:46<21:57,  1.18it/s]  3%|▎         | 54/1605 [00:47<22:01,  1.17it/s]  3%|▎         | 55/1605 [00:48<22:08,  1.17it/s]  3%|▎         | 56/1605 [00:49<22:07,  1.17it/s]  4%|▎         | 57/1605 [00:50<22:08,  1.16it/s]  4%|▎         | 58/1605 [00:51<22:11,  1.16it/s]  4%|▎         | 59/1605 [00:51<22:05,  1.17it/s]  4%|▎         | 60/1605 [00:52<22:06,  1.16it/s]  4%|▍         | 61/1605 [00:53<21:54,  1.17it/s]  4%|▍         | 62/1605 [00:54<21:51,  1.18it/s]  4%|▍         | 63/1605 [00:55<21:52,  1.18it/s]  4%|▍         | 64/1605 [00:56<21:52,  1.17it/s]  4%|▍         | 65/1605 [00:57<21:57,  1.17it/s]  4%|▍         | 66/1605 [00:57<21:59,  1.17it/s]  4%|▍         | 67/1605 [00:58<21:58,  1.17it/s]  4%|▍         | 68/1605 [00:59<21:51,  1.17it/s]  4%|▍         | 69/1605 [01:00<21:55,  1.17it/s]  4%|▍         | 70/1605 [01:01<21:48,  1.17it/s]  4%|▍         | 71/1605 [01:02<21:44,  1.18it/s]  4%|▍         | 72/1605 [01:02<21:51,  1.17it/s]  5%|▍         | 73/1605 [01:03<21:46,  1.17it/s]  5%|▍         | 74/1605 [01:04<21:49,  1.17it/s]  5%|▍         | 75/1605 [01:05<21:50,  1.17it/s]  5%|▍         | 76/1605 [01:06<21:38,  1.18it/s]  5%|▍         | 77/1605 [01:07<21:42,  1.17it/s]  5%|▍         | 78/1605 [01:08<21:41,  1.17it/s]  5%|▍         | 79/1605 [01:08<21:31,  1.18it/s]  5%|▍         | 80/1605 [01:09<21:35,  1.18it/s]  5%|▌         | 81/1605 [01:10<21:30,  1.18it/s]  5%|▌         | 82/1605 [01:11<21:30,  1.18it/s]  5%|▌         | 83/1605 [01:12<21:39,  1.17it/s]  5%|▌         | 84/1605 [01:13<21:32,  1.18it/s]  5%|▌         | 85/1605 [01:14<21:29,  1.18it/s]  5%|▌         | 86/1605 [01:14<21:26,  1.18it/s]  5%|▌         | 87/1605 [01:15<21:24,  1.18it/s]  5%|▌         | 88/1605 [01:16<21:38,  1.17it/s]  6%|▌         | 89/1605 [01:17<21:32,  1.17it/s]  6%|▌         | 90/1605 [01:18<21:34,  1.17it/s]  6%|▌         | 91/1605 [01:19<21:33,  1.17it/s]  6%|▌         | 92/1605 [01:20<21:37,  1.17it/s]  6%|▌         | 93/1605 [01:20<21:32,  1.17it/s]  6%|▌         | 94/1605 [01:21<21:30,  1.17it/s]  6%|▌         | 95/1605 [01:22<21:31,  1.17it/s]  6%|▌         | 96/1605 [01:23<21:32,  1.17it/s]  6%|▌         | 97/1605 [01:24<21:23,  1.18it/s]  6%|▌         | 98/1605 [01:25<21:27,  1.17it/s]  6%|▌         | 99/1605 [01:26<21:38,  1.16it/s]  6%|▌         | 100/1605 [01:26<21:34,  1.16it/s]  6%|▋         | 101/1605 [01:27<21:34,  1.16it/s]  6%|▋         | 102/1605 [01:28<21:22,  1.17it/s]  6%|▋         | 103/1605 [01:29<21:29,  1.16it/s]  6%|▋         | 104/1605 [01:30<21:26,  1.17it/s]  7%|▋         | 105/1605 [01:31<21:22,  1.17it/s]  7%|▋         | 106/1605 [01:31<21:21,  1.17it/s]  7%|▋         | 107/1605 [01:32<21:23,  1.17it/s]  7%|▋         | 108/1605 [01:33<21:21,  1.17it/s]  7%|▋         | 109/1605 [01:34<21:22,  1.17it/s]  7%|▋         | 110/1605 [01:35<21:18,  1.17it/s]  7%|▋         | 111/1605 [01:36<21:17,  1.17it/s]  7%|▋         | 112/1605 [01:37<21:03,  1.18it/s]  7%|▋         | 113/1605 [01:37<21:11,  1.17it/s]  7%|▋         | 114/1605 [01:38<21:25,  1.16it/s]  7%|▋         | 115/1605 [01:39<21:12,  1.17it/s]  7%|▋         | 116/1605 [01:40<21:11,  1.17it/s]  7%|▋         | 117/1605 [01:41<21:10,  1.17it/s]  7%|▋         | 118/1605 [01:42<21:10,  1.17it/s]  7%|▋         | 119/1605 [01:43<21:08,  1.17it/s]  7%|▋         | 120/1605 [01:43<21:03,  1.18it/s]  8%|▊         | 121/1605 [01:44<21:04,  1.17it/s]  8%|▊         | 122/1605 [01:45<21:03,  1.17it/s]  8%|▊         | 123/1605 [01:46<21:08,  1.17it/s]  8%|▊         | 124/1605 [01:47<20:59,  1.18it/s]  8%|▊         | 125/1605 [01:48<21:07,  1.17it/s]  8%|▊         | 126/1605 [01:49<21:05,  1.17it/s]  8%|▊         | 127/1605 [01:49<21:05,  1.17it/s]  8%|▊         | 128/1605 [01:50<20:55,  1.18it/s]  8%|▊         | 129/1605 [01:51<20:57,  1.17it/s]  8%|▊         | 130/1605 [01:52<21:01,  1.17it/s]  8%|▊         | 131/1605 [01:53<20:56,  1.17it/s]  8%|▊         | 132/1605 [01:54<20:52,  1.18it/s]  8%|▊         | 133/1605 [01:55<20:51,  1.18it/s]  8%|▊         | 134/1605 [01:55<20:55,  1.17it/s]  8%|▊         | 135/1605 [01:56<20:50,  1.18it/s]  8%|▊         | 136/1605 [01:57<20:53,  1.17it/s]  9%|▊         | 137/1605 [01:58<20:51,  1.17it/s]  9%|▊         | 138/1605 [01:59<20:51,  1.17it/s]  9%|▊         | 139/1605 [02:00<20:57,  1.17it/s]  9%|▊         | 140/1605 [02:01<20:51,  1.17it/s]  9%|▉         | 141/1605 [02:01<20:53,  1.17it/s]  9%|▉         | 142/1605 [02:02<20:45,  1.17it/s]  9%|▉         | 143/1605 [02:03<20:57,  1.16it/s]  9%|▉         | 144/1605 [02:04<20:50,  1.17it/s]  9%|▉         | 145/1605 [02:05<20:49,  1.17it/s]  9%|▉         | 146/1605 [02:06<20:49,  1.17it/s]  9%|▉         | 147/1605 [02:07<20:53,  1.16it/s]  9%|▉         | 148/1605 [02:07<20:51,  1.16it/s]  9%|▉         | 149/1605 [02:08<20:33,  1.18it/s]  9%|▉         | 150/1605 [02:09<20:37,  1.18it/s]  9%|▉         | 151/1605 [02:10<20:40,  1.17it/s]  9%|▉         | 152/1605 [02:11<20:42,  1.17it/s] 10%|▉         | 153/1605 [02:12<20:43,  1.17it/s] 10%|▉         | 154/1605 [02:12<20:39,  1.17it/s] 10%|▉         | 155/1605 [02:13<20:48,  1.16it/s] 10%|▉         | 156/1605 [02:14<20:40,  1.17it/s] 10%|▉         | 157/1605 [02:15<20:41,  1.17it/s] 10%|▉         | 158/1605 [02:16<20:48,  1.16it/s] 10%|▉         | 159/1605 [02:17<20:46,  1.16it/s] 10%|▉         | 160/1605 [02:18<20:41,  1.16it/s] 10%|█         | 161/1605 [02:19<20:37,  1.17it/s] 10%|█         | 162/1605 [02:19<20:40,  1.16it/s] 10%|█         | 163/1605 [02:20<20:38,  1.16it/s] 10%|█         | 164/1605 [02:21<20:36,  1.17it/s] 10%|█         | 165/1605 [02:22<20:31,  1.17it/s] 10%|█         | 166/1605 [02:23<20:30,  1.17it/s] 10%|█         | 167/1605 [02:24<20:33,  1.17it/s] 10%|█         | 168/1605 [02:25<20:26,  1.17it/s] 11%|█         | 169/1605 [02:25<20:25,  1.17it/s] 11%|█         | 170/1605 [02:26<20:22,  1.17it/s] 11%|█         | 171/1605 [02:27<20:23,  1.17it/s] 11%|█         | 172/1605 [02:28<20:25,  1.17it/s] 11%|█         | 173/1605 [02:29<20:24,  1.17it/s] 11%|█         | 174/1605 [02:30<20:27,  1.17it/s] 11%|█         | 175/1605 [02:30<20:20,  1.17it/s] 11%|█         | 176/1605 [02:31<20:24,  1.17it/s] 11%|█         | 177/1605 [02:32<20:29,  1.16it/s] 11%|█         | 178/1605 [02:33<20:14,  1.17it/s] 11%|█         | 179/1605 [02:34<20:25,  1.16it/s] 11%|█         | 180/1605 [02:35<20:12,  1.18it/s] 11%|█▏        | 181/1605 [02:36<20:09,  1.18it/s] 11%|█▏        | 182/1605 [02:36<20:10,  1.18it/s] 11%|█▏        | 183/1605 [02:37<20:04,  1.18it/s] 11%|█▏        | 184/1605 [02:38<20:04,  1.18it/s] 12%|█▏        | 185/1605 [02:39<20:10,  1.17it/s] 12%|█▏        | 186/1605 [02:40<20:15,  1.17it/s] 12%|█▏        | 187/1605 [02:41<20:12,  1.17it/s] 12%|█▏        | 188/1605 [02:42<20:13,  1.17it/s] 12%|█▏        | 189/1605 [02:42<20:19,  1.16it/s] 12%|█▏        | 190/1605 [02:43<20:14,  1.17it/s] 12%|█▏        | 191/1605 [02:44<20:13,  1.16it/s] 12%|█▏        | 192/1605 [02:45<20:08,  1.17it/s] 12%|█▏        | 193/1605 [02:46<20:00,  1.18it/s] 12%|█▏        | 194/1605 [02:47<20:03,  1.17it/s] 12%|█▏        | 195/1605 [02:48<19:59,  1.18it/s] 12%|█▏        | 196/1605 [02:48<19:58,  1.18it/s] 12%|█▏        | 197/1605 [02:49<19:54,  1.18it/s] 12%|█▏        | 198/1605 [02:50<19:53,  1.18it/s] 12%|█▏        | 199/1605 [02:51<19:56,  1.18it/s] 12%|█▏        | 200/1605 [02:52<20:02,  1.17it/s] 13%|█▎        | 201/1605 [02:53<19:57,  1.17it/s] 13%|█▎        | 202/1605 [02:54<20:02,  1.17it/s] 13%|█▎        | 203/1605 [02:54<19:56,  1.17it/s] 13%|█▎        | 204/1605 [02:55<19:55,  1.17it/s] 13%|█▎        | 205/1605 [02:56<20:04,  1.16it/s] 13%|█▎        | 206/1605 [02:57<19:54,  1.17it/s] 13%|█▎        | 207/1605 [02:58<19:50,  1.17it/s] 13%|█▎        | 208/1605 [02:59<19:55,  1.17it/s] 13%|█▎        | 209/1605 [03:00<19:55,  1.17it/s] 13%|█▎        | 210/1605 [03:00<19:55,  1.17it/s] 13%|█▎        | 211/1605 [03:01<19:59,  1.16it/s] 13%|█▎        | 212/1605 [03:02<19:51,  1.17it/s] 13%|█▎        | 213/1605 [03:03<19:52,  1.17it/s] 13%|█▎        | 214/1605 [03:04<19:44,  1.17it/s] 13%|█▎        | 215/1605 [03:05<19:46,  1.17it/s] 13%|█▎        | 216/1605 [03:06<19:47,  1.17it/s] 14%|█▎        | 217/1605 [03:06<19:46,  1.17it/s] 14%|█▎        | 218/1605 [03:07<19:41,  1.17it/s] 14%|█▎        | 219/1605 [03:08<19:45,  1.17it/s] 14%|█▎        | 220/1605 [03:09<19:40,  1.17it/s] 14%|█▍        | 221/1605 [03:10<19:38,  1.17it/s] 14%|█▍        | 222/1605 [03:11<19:39,  1.17it/s] 14%|█▍        | 223/1605 [03:11<19:37,  1.17it/s] 14%|█▍        | 224/1605 [03:12<19:41,  1.17it/s] 14%|█▍        | 225/1605 [03:13<19:36,  1.17it/s] 14%|█▍        | 226/1605 [03:14<19:32,  1.18it/s] 14%|█▍        | 227/1605 [03:15<19:31,  1.18it/s] 14%|█▍        | 228/1605 [03:16<19:32,  1.17it/s] 14%|█▍        | 229/1605 [03:17<19:26,  1.18it/s] 14%|█▍        | 230/1605 [03:17<19:34,  1.17it/s] 14%|█▍        | 231/1605 [03:18<19:25,  1.18it/s] 14%|█▍        | 232/1605 [03:19<19:28,  1.18it/s] 15%|█▍        | 233/1605 [03:20<19:25,  1.18it/s] 15%|█▍        | 234/1605 [03:21<19:33,  1.17it/s] 15%|█▍        | 235/1605 [03:22<19:32,  1.17it/s] 15%|█▍        | 236/1605 [03:23<19:34,  1.17it/s] 15%|█▍        | 237/1605 [03:23<19:33,  1.17it/s] 15%|█▍        | 238/1605 [03:24<19:26,  1.17it/s] 15%|█▍        | 239/1605 [03:25<19:23,  1.17it/s] 15%|█▍        | 240/1605 [03:26<19:20,  1.18it/s] 15%|█▌        | 241/1605 [03:27<19:20,  1.18it/s] 15%|█▌        | 242/1605 [03:28<19:19,  1.18it/s] 15%|█▌        | 243/1605 [03:29<19:29,  1.16it/s] 15%|█▌        | 244/1605 [03:29<19:27,  1.17it/s] 15%|█▌        | 245/1605 [03:30<19:21,  1.17it/s] 15%|█▌        | 246/1605 [03:31<19:24,  1.17it/s] 15%|█▌        | 247/1605 [03:32<19:17,  1.17it/s] 15%|█▌        | 248/1605 [03:33<19:19,  1.17it/s] 16%|█▌        | 249/1605 [03:34<19:18,  1.17it/s] 16%|█▌        | 250/1605 [03:35<19:23,  1.16it/s] 16%|█▌        | 251/1605 [03:35<19:15,  1.17it/s] 16%|█▌        | 252/1605 [03:36<19:17,  1.17it/s] 16%|█▌        | 253/1605 [03:37<19:18,  1.17it/s] 16%|█▌        | 254/1605 [03:38<19:16,  1.17it/s] 16%|█▌        | 255/1605 [03:39<19:20,  1.16it/s] 16%|█▌        | 256/1605 [03:40<19:26,  1.16it/s] 16%|█▌        | 257/1605 [03:41<19:10,  1.17it/s] 16%|█▌        | 258/1605 [03:41<19:10,  1.17it/s] 16%|█▌        | 259/1605 [03:42<19:10,  1.17it/s] 16%|█▌        | 260/1605 [03:43<19:09,  1.17it/s] 16%|█▋        | 261/1605 [03:44<19:02,  1.18it/s] 16%|█▋        | 262/1605 [03:45<19:15,  1.16it/s] 16%|█▋        | 263/1605 [03:46<19:08,  1.17it/s] 16%|█▋        | 264/1605 [03:46<19:04,  1.17it/s] 17%|█▋        | 265/1605 [03:47<19:03,  1.17it/s] 17%|█▋        | 266/1605 [03:48<19:01,  1.17it/s] 17%|█▋        | 267/1605 [03:49<19:06,  1.17it/s] 17%|█▋        | 268/1605 [03:50<19:01,  1.17it/s] 17%|█▋        | 269/1605 [03:51<19:01,  1.17it/s] 17%|█▋        | 270/1605 [03:52<19:06,  1.16it/s] 17%|█▋        | 271/1605 [03:52<19:02,  1.17it/s] 17%|█▋        | 272/1605 [03:53<19:10,  1.16it/s] 17%|█▋        | 273/1605 [03:54<19:03,  1.16it/s] 17%|█▋        | 274/1605 [03:55<18:58,  1.17it/s] 17%|█▋        | 275/1605 [03:56<18:57,  1.17it/s] 17%|█▋        | 276/1605 [03:57<18:56,  1.17it/s] 17%|█▋        | 277/1605 [03:58<18:48,  1.18it/s] 17%|█▋        | 278/1605 [03:58<18:53,  1.17it/s] 17%|█▋        | 279/1605 [03:59<18:50,  1.17it/s] 17%|█▋        | 280/1605 [04:00<18:51,  1.17it/s] 18%|█▊        | 281/1605 [04:01<18:45,  1.18it/s] 18%|█▊        | 282/1605 [04:02<18:47,  1.17it/s] 18%|█▊        | 283/1605 [04:03<18:51,  1.17it/s] 18%|█▊        | 284/1605 [04:04<18:58,  1.16it/s] 18%|█▊        | 285/1605 [04:04<18:47,  1.17it/s] 18%|█▊        | 286/1605 [04:05<18:56,  1.16it/s] 18%|█▊        | 287/1605 [04:06<18:57,  1.16it/s] 18%|█▊        | 288/1605 [04:07<19:00,  1.15it/s] 18%|█▊        | 289/1605 [04:08<18:54,  1.16it/s] 18%|█▊        | 290/1605 [04:09<18:52,  1.16it/s] 18%|█▊        | 291/1605 [04:10<18:44,  1.17it/s] 18%|█▊        | 292/1605 [04:11<18:58,  1.15it/s] 18%|█▊        | 293/1605 [04:11<18:47,  1.16it/s] 18%|█▊        | 294/1605 [04:12<18:44,  1.17it/s] 18%|█▊        | 295/1605 [04:13<18:51,  1.16it/s] 18%|█▊        | 296/1605 [04:14<18:43,  1.17it/s] 19%|█▊        | 297/1605 [04:15<18:37,  1.17it/s] 19%|█▊        | 298/1605 [04:16<18:34,  1.17it/s] 19%|█▊        | 299/1605 [04:17<18:38,  1.17it/s] 19%|█▊        | 300/1605 [04:17<18:37,  1.17it/s] 19%|█▉        | 301/1605 [04:18<18:35,  1.17it/s] 19%|█▉        | 302/1605 [04:19<18:33,  1.17it/s] 19%|█▉        | 303/1605 [04:20<18:31,  1.17it/s] 19%|█▉        | 304/1605 [04:21<18:26,  1.18it/s] 19%|█▉        | 305/1605 [04:22<18:25,  1.18it/s] 19%|█▉        | 306/1605 [04:22<18:35,  1.16it/s] 19%|█▉        | 307/1605 [04:23<18:24,  1.17it/s] 19%|█▉        | 308/1605 [04:24<18:35,  1.16it/s] 19%|█▉        | 309/1605 [04:25<18:39,  1.16it/s] 19%|█▉        | 310/1605 [04:26<18:30,  1.17it/s] 19%|█▉        | 311/1605 [04:27<18:30,  1.16it/s] 19%|█▉        | 312/1605 [04:28<18:28,  1.17it/s] 20%|█▉        | 313/1605 [04:28<18:25,  1.17it/s] 20%|█▉        | 314/1605 [04:29<18:17,  1.18it/s] 20%|█▉        | 315/1605 [04:30<18:18,  1.17it/s] 20%|█▉        | 316/1605 [04:31<18:20,  1.17it/s] 20%|█▉        | 317/1605 [04:32<18:20,  1.17it/s] 20%|█▉        | 318/1605 [04:33<18:15,  1.17it/s] 20%|█▉        | 319/1605 [04:34<18:17,  1.17it/s] 20%|█▉        | 320/1605 [04:34<18:19,  1.17it/s] 20%|██        | 321/1605 [04:35<18:16,  1.17it/s] 20%|██        | 322/1605 [04:36<18:15,  1.17it/s] 20%|██        | 323/1605 [04:37<18:15,  1.17it/s] 20%|██        | 324/1605 [04:38<18:12,  1.17it/s] 20%|██        | 325/1605 [04:39<18:18,  1.17it/s] 20%|██        | 326/1605 [04:40<18:12,  1.17it/s] 20%|██        | 327/1605 [04:40<18:15,  1.17it/s] 20%|██        | 328/1605 [04:41<18:10,  1.17it/s] 20%|██        | 329/1605 [04:42<18:11,  1.17it/s] 21%|██        | 330/1605 [04:43<18:14,  1.16it/s] 21%|██        | 331/1605 [04:44<18:09,  1.17it/s] 21%|██        | 332/1605 [04:45<18:11,  1.17it/s] 21%|██        | 333/1605 [04:46<18:10,  1.17it/s] 21%|██        | 334/1605 [04:46<18:03,  1.17it/s] 21%|██        | 335/1605 [04:47<18:03,  1.17it/s] 21%|██        | 336/1605 [04:48<17:59,  1.18it/s] 21%|██        | 337/1605 [04:49<17:53,  1.18it/s] 21%|██        | 338/1605 [04:50<18:01,  1.17it/s] 21%|██        | 339/1605 [04:51<17:57,  1.17it/s] 21%|██        | 340/1605 [04:52<17:51,  1.18it/s] 21%|██        | 341/1605 [04:52<17:58,  1.17it/s] 21%|██▏       | 342/1605 [04:53<18:00,  1.17it/s] 21%|██▏       | 343/1605 [04:54<17:55,  1.17it/s] 21%|██▏       | 344/1605 [04:55<17:58,  1.17it/s] 21%|██▏       | 345/1605 [04:56<17:59,  1.17it/s] 22%|██▏       | 346/1605 [04:57<18:01,  1.16it/s] 22%|██▏       | 347/1605 [04:58<17:56,  1.17it/s] 22%|██▏       | 348/1605 [04:58<17:58,  1.17it/s] 22%|██▏       | 349/1605 [04:59<17:54,  1.17it/s] 22%|██▏       | 350/1605 [05:00<18:08,  1.15it/s] 22%|██▏       | 351/1605 [05:01<18:00,  1.16it/s] 22%|██▏       | 352/1605 [05:02<17:59,  1.16it/s] 22%|██▏       | 353/1605 [05:03<18:00,  1.16it/s] 22%|██▏       | 354/1605 [05:04<17:53,  1.17it/s] 22%|██▏       | 355/1605 [05:04<17:52,  1.17it/s] 22%|██▏       | 356/1605 [05:05<17:46,  1.17it/s] 22%|██▏       | 357/1605 [05:06<17:50,  1.17it/s] 22%|██▏       | 358/1605 [05:07<17:55,  1.16it/s] 22%|██▏       | 359/1605 [05:08<17:50,  1.16it/s] 22%|██▏       | 360/1605 [05:09<17:50,  1.16it/s] 22%|██▏       | 361/1605 [05:10<17:55,  1.16it/s] 23%|██▎       | 362/1605 [05:10<17:44,  1.17it/s] 23%|██▎       | 363/1605 [05:11<17:49,  1.16it/s] 23%|██▎       | 364/1605 [05:12<17:40,  1.17it/s] 23%|██▎       | 365/1605 [05:13<17:46,  1.16it/s] 23%|██▎       | 366/1605 [05:14<17:46,  1.16it/s] 23%|██▎       | 367/1605 [05:15<17:40,  1.17it/s] 23%|██▎       | 368/1605 [05:16<17:40,  1.17it/s] 23%|██▎       | 369/1605 [05:16<17:32,  1.17it/s] 23%|██▎       | 370/1605 [05:17<17:31,  1.17it/s] 23%|██▎       | 371/1605 [05:18<17:31,  1.17it/s] 23%|██▎       | 372/1605 [05:19<17:36,  1.17it/s] 23%|██▎       | 373/1605 [05:20<17:28,  1.17it/s] 23%|██▎       | 374/1605 [05:21<17:34,  1.17it/s] 23%|██▎       | 375/1605 [05:22<17:34,  1.17it/s] 23%|██▎       | 376/1605 [05:22<17:33,  1.17it/s] 23%|██▎       | 377/1605 [05:23<17:32,  1.17it/s] 24%|██▎       | 378/1605 [05:24<17:23,  1.18it/s] 24%|██▎       | 379/1605 [05:25<17:24,  1.17it/s] 24%|██▎       | 380/1605 [05:26<17:17,  1.18it/s] 24%|██▎       | 381/1605 [05:27<17:17,  1.18it/s] 24%|██▍       | 382/1605 [05:27<17:18,  1.18it/s] 24%|██▍       | 383/1605 [05:28<17:27,  1.17it/s] 24%|██▍       | 384/1605 [05:29<17:24,  1.17it/s] 24%|██▍       | 385/1605 [05:30<17:20,  1.17it/s] 24%|██▍       | 386/1605 [05:31<17:13,  1.18it/s] 24%|██▍       | 387/1605 [05:32<17:15,  1.18it/s] 24%|██▍       | 388/1605 [05:33<17:15,  1.18it/s] 24%|██▍       | 389/1605 [05:33<17:21,  1.17it/s] 24%|██▍       | 390/1605 [05:34<17:12,  1.18it/s] 24%|██▍       | 391/1605 [05:35<17:21,  1.17it/s] 24%|██▍       | 392/1605 [05:36<17:31,  1.15it/s] 24%|██▍       | 393/1605 [05:37<17:24,  1.16it/s] 25%|██▍       | 394/1605 [05:38<17:21,  1.16it/s] 25%|██▍       | 395/1605 [05:39<17:10,  1.17it/s] 25%|██▍       | 396/1605 [05:39<17:09,  1.17it/s] 25%|██▍       | 397/1605 [05:40<17:15,  1.17it/s] 25%|██▍       | 398/1605 [05:41<17:10,  1.17it/s] 25%|██▍       | 399/1605 [05:42<17:08,  1.17it/s] 25%|██▍       | 400/1605 [05:43<17:11,  1.17it/s] 25%|██▍       | 401/1605 [05:44<17:01,  1.18it/s] 25%|██▌       | 402/1605 [05:45<17:07,  1.17it/s] 25%|██▌       | 403/1605 [05:45<17:06,  1.17it/s] 25%|██▌       | 404/1605 [05:46<17:03,  1.17it/s] 25%|██▌       | 405/1605 [05:47<17:01,  1.17it/s] 25%|██▌       | 406/1605 [05:48<17:12,  1.16it/s] 25%|██▌       | 407/1605 [05:49<17:07,  1.17it/s] 25%|██▌       | 408/1605 [05:50<17:00,  1.17it/s] 25%|██▌       | 409/1605 [05:51<17:03,  1.17it/s] 26%|██▌       | 410/1605 [05:51<16:58,  1.17it/s] 26%|██▌       | 411/1605 [05:52<16:56,  1.17it/s] 26%|██▌       | 412/1605 [05:53<17:00,  1.17it/s] 26%|██▌       | 413/1605 [05:54<17:01,  1.17it/s] 26%|██▌       | 414/1605 [05:55<16:54,  1.17it/s] 26%|██▌       | 415/1605 [05:56<17:00,  1.17it/s] 26%|██▌       | 416/1605 [05:57<16:52,  1.17it/s] 26%|██▌       | 417/1605 [05:57<16:58,  1.17it/s] 26%|██▌       | 418/1605 [05:58<16:51,  1.17it/s] 26%|██▌       | 419/1605 [05:59<16:52,  1.17it/s] 26%|██▌       | 420/1605 [06:00<16:55,  1.17it/s] 26%|██▌       | 421/1605 [06:01<16:57,  1.16it/s] 26%|██▋       | 422/1605 [06:02<16:51,  1.17it/s] 26%|██▋       | 423/1605 [06:03<16:45,  1.18it/s] 26%|██▋       | 424/1605 [06:03<16:45,  1.17it/s] 26%|██▋       | 425/1605 [06:04<16:44,  1.17it/s] 27%|██▋       | 426/1605 [06:05<16:57,  1.16it/s] 27%|██▋       | 427/1605 [06:06<16:55,  1.16it/s] 27%|██▋       | 428/1605 [06:07<16:47,  1.17it/s] 27%|██▋       | 429/1605 [06:08<16:52,  1.16it/s] 27%|██▋       | 430/1605 [06:09<16:45,  1.17it/s] 27%|██▋       | 431/1605 [06:09<16:55,  1.16it/s] 27%|██▋       | 432/1605 [06:10<16:54,  1.16it/s] 27%|██▋       | 433/1605 [06:11<16:51,  1.16it/s] 27%|██▋       | 434/1605 [06:12<16:50,  1.16it/s] 27%|██▋       | 435/1605 [06:13<16:39,  1.17it/s] 27%|██▋       | 436/1605 [06:14<16:41,  1.17it/s] 27%|██▋       | 437/1605 [06:15<16:43,  1.16it/s] 27%|██▋       | 438/1605 [06:15<16:45,  1.16it/s] 27%|██▋       | 439/1605 [06:16<16:38,  1.17it/s] 27%|██▋       | 440/1605 [06:17<16:40,  1.16it/s] 27%|██▋       | 441/1605 [06:18<16:38,  1.17it/s] 28%|██▊       | 442/1605 [06:19<16:35,  1.17it/s] 28%|██▊       | 443/1605 [06:20<16:35,  1.17it/s] 28%|██▊       | 444/1605 [06:21<16:37,  1.16it/s] 28%|██▊       | 445/1605 [06:21<16:34,  1.17it/s] 28%|██▊       | 446/1605 [06:22<16:33,  1.17it/s] 28%|██▊       | 447/1605 [06:23<16:33,  1.17it/s] 28%|██▊       | 448/1605 [06:24<16:29,  1.17it/s] 28%|██▊       | 449/1605 [06:25<16:27,  1.17it/s] 28%|██▊       | 450/1605 [06:26<16:26,  1.17it/s] 28%|██▊       | 451/1605 [06:27<16:28,  1.17it/s] 28%|██▊       | 452/1605 [06:27<16:28,  1.17it/s] 28%|██▊       | 453/1605 [06:28<16:28,  1.17it/s] 28%|██▊       | 454/1605 [06:29<16:24,  1.17it/s] 28%|██▊       | 455/1605 [06:30<16:21,  1.17it/s] 28%|██▊       | 456/1605 [06:31<16:19,  1.17it/s] 28%|██▊       | 457/1605 [06:32<16:23,  1.17it/s] 29%|██▊       | 458/1605 [06:33<16:20,  1.17it/s] 29%|██▊       | 459/1605 [06:33<16:19,  1.17it/s] 29%|██▊       | 460/1605 [06:34<16:22,  1.17it/s] 29%|██▊       | 461/1605 [06:35<16:18,  1.17it/s] 29%|██▉       | 462/1605 [06:36<16:14,  1.17it/s] 29%|██▉       | 463/1605 [06:37<16:22,  1.16it/s] 29%|██▉       | 464/1605 [06:38<16:24,  1.16it/s] 29%|██▉       | 465/1605 [06:39<16:14,  1.17it/s] 29%|██▉       | 466/1605 [06:39<16:18,  1.16it/s] 29%|██▉       | 467/1605 [06:40<16:12,  1.17it/s] 29%|██▉       | 468/1605 [06:41<16:13,  1.17it/s] 29%|██▉       | 469/1605 [06:42<16:12,  1.17it/s] 29%|██▉       | 470/1605 [06:43<16:09,  1.17it/s] 29%|██▉       | 471/1605 [06:44<16:10,  1.17it/s] 29%|██▉       | 472/1605 [06:45<16:06,  1.17it/s] 29%|██▉       | 473/1605 [06:45<16:05,  1.17it/s] 30%|██▉       | 474/1605 [06:46<16:05,  1.17it/s] 30%|██▉       | 475/1605 [06:47<16:05,  1.17it/s] 30%|██▉       | 476/1605 [06:48<16:01,  1.17it/s] 30%|██▉       | 477/1605 [06:49<16:02,  1.17it/s] 30%|██▉       | 478/1605 [06:50<16:03,  1.17it/s] 30%|██▉       | 479/1605 [06:51<16:03,  1.17it/s] 30%|██▉       | 480/1605 [06:51<15:58,  1.17it/s] 30%|██▉       | 481/1605 [06:52<16:01,  1.17it/s] 30%|███       | 482/1605 [06:53<16:06,  1.16it/s] 30%|███       | 483/1605 [06:54<16:01,  1.17it/s] 30%|███       | 484/1605 [06:55<16:00,  1.17it/s] 30%|███       | 485/1605 [06:56<15:57,  1.17it/s] 30%|███       | 486/1605 [06:57<16:01,  1.16it/s] 30%|███       | 487/1605 [06:57<15:59,  1.17it/s] 30%|███       | 488/1605 [06:58<15:59,  1.1{'loss': 0.7089, 'learning_rate': 3.442367601246106e-05, 'epoch': 0.93}
6it/s] 30%|███       | 489/1605 [06:59<16:07,  1.15it/s] 31%|███       | 490/1605 [07:00<16:08,  1.15it/s] 31%|███       | 491/1605 [07:01<16:00,  1.16it/s] 31%|███       | 492/1605 [07:02<16:06,  1.15it/s] 31%|███       | 493/1605 [07:03<15:51,  1.17it/s] 31%|███       | 494/1605 [07:03<16:00,  1.16it/s] 31%|███       | 495/1605 [07:04<15:56,  1.16it/s] 31%|███       | 496/1605 [07:05<15:50,  1.17it/s] 31%|███       | 497/1605 [07:06<15:58,  1.16it/s] 31%|███       | 498/1605 [07:07<15:55,  1.16it/s] 31%|███       | 499/1605 [07:08<15:46,  1.17it/s] 31%|███       | 500/1605 [07:09<15:43,  1.17it/s]                                                   31%|███       | 500/1605 [07:09<15:43,  1.17it/s][INFO|trainer.py:2985] 2024-02-12 20:25:51,003 >> Saving model checkpoint to /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500
[INFO|configuration_utils.py:473] 2024-02-12 20:25:51,025 >> Configuration saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500/config.json
[INFO|modeling_utils.py:2462] 2024-02-12 20:26:14,185 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-02-12 20:26:14,189 >> tokenizer config file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-02-12 20:26:14,190 >> Special tokens file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-500/special_tokens_map.json
 31%|███       | 501/1605 [08:14<6:10:19, 20.13s/it] 31%|███▏      | 502/1605 [08:15<4:23:43, 14.35s/it] 31%|███▏      | 503/1605 [08:15<3:09:05, 10.30s/it] 31%|███▏      | 504/1605 [08:16<2:16:54,  7.46s/it] 31%|███▏      | 505/1605 [08:17<1:40:18,  5.47s/it] 32%|███▏      | 506/1605 [08:18<1:14:52,  4.09s/it] 32%|███▏      | 507/1605 [08:19<57:01,  3.12s/it]   32%|███▏      | 508/1605 [08:20<44:28,  2.43s/it] 32%|███▏      | 509/1605 [08:20<35:47,  1.96s/it] 32%|███▏      | 510/1605 [08:21<29:43,  1.63s/it] 32%|███▏      | 511/1605 [08:22<25:22,  1.39s/it] 32%|███▏      | 512/1605 [08:23<22:27,  1.23s/it] 32%|███▏      | 513/1605 [08:24<20:16,  1.11s/it] 32%|███▏      | 514/1605 [08:25<18:54,  1.04s/it] 32%|███▏      | 515/1605 [08:26<17:52,  1.02it/s] 32%|███▏      | 516/1605 [08:26<17:05,  1.06it/s] 32%|███▏      | 517/1605 [08:27<16:36,  1.09it/s] 32%|███▏      | 518/1605 [08:28<16:14,  1.11it/s] 32%|███▏      | 519/1605 [08:29<15:55,  1.14it/s] 32%|███▏      | 520/1605 [08:30<15:46,  1.15it/s] 32%|███▏      | 521/1605 [08:31<15:37,  1.16it/s] 33%|███▎      | 522/1605 [08:31<15:29,  1.17it/s] 33%|███▎      | 523/1605 [08:32<15:28,  1.16it/s] 33%|███▎      | 524/1605 [08:33<15:28,  1.16it/s] 33%|███▎      | 525/1605 [08:34<15:27,  1.16it/s] 33%|███▎      | 526/1605 [08:35<15:21,  1.17it/s] 33%|███▎      | 527/1605 [08:36<15:22,  1.17it/s] 33%|███▎      | 528/1605 [08:37<15:17,  1.17it/s] 33%|███▎      | 529/1605 [08:37<15:20,  1.17it/s] 33%|███▎      | 530/1605 [08:38<15:24,  1.16it/s] 33%|███▎      | 531/1605 [08:39<15:16,  1.17it/s] 33%|███▎      | 532/1605 [08:40<15:21,  1.16it/s] 33%|███▎      | 533/1605 [08:41<15:23,  1.16it/s] 33%|███▎      | 534/1605 [08:42<15:20,  1.16it/s] 33%|███▎      | 535/1605 [08:43<15:13,  1.17it/s] 33%|███▎      | 536/1605 [08:43<15:07,  1.18it/s] 33%|███▎      | 537/1605 [08:44<15:14,  1.17it/s] 34%|███▎      | 538/1605 [08:45<15:12,  1.17it/s] 34%|███▎      | 539/1605 [08:46<15:25,  1.15it/s] 34%|███▎      | 540/1605 [08:47<15:19,  1.16it/s] 34%|███▎      | 541/1605 [08:48<15:14,  1.16it/s] 34%|███▍      | 542/1605 [08:49<15:09,  1.17it/s] 34%|███▍      | 543/1605 [08:49<15:02,  1.18it/s] 34%|███▍      | 544/1605 [08:50<15:05,  1.17it/s] 34%|███▍      | 545/1605 [08:51<15:06,  1.17it/s] 34%|███▍      | 546/1605 [08:52<15:04,  1.17it/s] 34%|███▍      | 547/1605 [08:53<15:01,  1.17it/s] 34%|███▍      | 548/1605 [08:54<14:54,  1.18it/s] 34%|███▍      | 549/1605 [08:55<14:57,  1.18it/s] 34%|███▍      | 550/1605 [08:55<14:58,  1.17it/s] 34%|███▍      | 551/1605 [08:56<14:57,  1.17it/s] 34%|███▍      | 552/1605 [08:57<14:51,  1.18it/s] 34%|███▍      | 553/1605 [08:58<14:58,  1.17it/s] 35%|███▍      | 554/1605 [08:59<15:01,  1.17it/s] 35%|███▍      | 555/1605 [09:00<14:56,  1.17it/s] 35%|███▍      | 556/1605 [09:01<14:54,  1.17it/s] 35%|███▍      | 557/1605 [09:01<14:50,  1.18it/s] 35%|███▍      | 558/1605 [09:02<14:52,  1.17it/s] 35%|███▍      | 559/1605 [09:03<14:55,  1.17it/s] 35%|███▍      | 560/1605 [09:04<14:57,  1.16it/s] 35%|███▍      | 561/1605 [09:05<14:46,  1.18it/s] 35%|███▌      | 562/1605 [09:06<14:51,  1.17it/s] 35%|███▌      | 563/1605 [09:07<14:51,  1.17it/s] 35%|███▌      | 564/1605 [09:07<14:51,  1.17it/s] 35%|███▌      | 565/1605 [09:08<14:48,  1.17it/s] 35%|███▌      | 566/1605 [09:09<14:50,  1.17it/s] 35%|███▌      | 567/1605 [09:10<14:47,  1.17it/s] 35%|███▌      | 568/1605 [09:11<14:46,  1.17it/s] 35%|███▌      | 569/1605 [09:12<14:45,  1.17it/s] 36%|███▌      | 570/1605 [09:13<14:39,  1.18it/s] 36%|███▌      | 571/1605 [09:13<14:47,  1.17it/s] 36%|███▌      | 572/1605 [09:14<14:47,  1.16it/s] 36%|███▌      | 573/1605 [09:15<14:40,  1.17it/s] 36%|███▌      | 574/1605 [09:16<14:38,  1.17it/s] 36%|███▌      | 575/1605 [09:17<14:40,  1.17it/s] 36%|███▌      | 576/1605 [09:18<14:42,  1.17it/s] 36%|███▌      | 577/1605 [09:19<14:36,  1.17it/s] 36%|███▌      | 578/1605 [09:19<14:33,  1.18it/s] 36%|███▌      | 579/1605 [09:20<14:33,  1.17it/s] 36%|███▌      | 580/1605 [09:21<14:44,  1.16it/s] 36%|███▌      | 581/1605 [09:22<14:45,  1.16it/s] 36%|███▋      | 582/1605 [09:23<14:39,  1.16it/s] 36%|███▋      | 583/1605 [09:24<14:38,  1.16it/s] 36%|███▋      | 584/1605 [09:25<14:37,  1.16it/s] 36%|███▋      | 585/1605 [09:25<14:28,  1.17it/s] 37%|███▋      | 586/1605 [09:26<14:29,  1.17it/s] 37%|███▋      | 587/1605 [09:27<14:32,  1.17it/s] 37%|███▋      | 588/1605 [09:28<14:29,  1.17it/s] 37%|███▋      | 589/1605 [09:29<14:35,  1.16it/s] 37%|███▋      | 590/1605 [09:30<14:32,  1.16it/s] 37%|███▋      | 591/1605 [09:31<14:30,  1.16it/s] 37%|███▋      | 592/1605 [09:31<14:32,  1.16it/s] 37%|███▋      | 593/1605 [09:32<14:25,  1.17it/s] 37%|███▋      | 594/1605 [09:33<14:28,  1.16it/s] 37%|███▋      | 595/1605 [09:34<14:21,  1.17it/s] 37%|███▋      | 596/1605 [09:35<14:23,  1.17it/s] 37%|███▋      | 597/1605 [09:36<14:26,  1.16it/s] 37%|███▋      | 598/1605 [09:37<14:27,  1.16it/s] 37%|███▋      | 599/1605 [09:37<14:22,  1.17it/s] 37%|███▋      | 600/1605 [09:38<14:24,  1.16it/s] 37%|███▋      | 601/1605 [09:39<14:19,  1.17it/s] 38%|███▊      | 602/1605 [09:40<14:19,  1.17it/s] 38%|███▊      | 603/1605 [09:41<14:17,  1.17it/s] 38%|███▊      | 604/1605 [09:42<14:17,  1.17it/s] 38%|███▊      | 605/1605 [09:43<14:16,  1.17it/s] 38%|███▊      | 606/1605 [09:43<14:16,  1.17it/s] 38%|███▊      | 607/1605 [09:44<14:14,  1.17it/s] 38%|███▊      | 608/1605 [09:45<14:16,  1.16it/s] 38%|███▊      | 609/1605 [09:46<14:09,  1.17it/s] 38%|███▊      | 610/1605 [09:47<14:10,  1.17it/s] 38%|███▊      | 611/1605 [09:48<14:08,  1.17it/s] 38%|███▊      | 612/1605 [09:49<14:07,  1.17it/s] 38%|███▊      | 613/1605 [09:49<14:06,  1.17it/s] 38%|███▊      | 614/1605 [09:50<14:09,  1.17it/s] 38%|███▊      | 615/1605 [09:51<14:05,  1.17it/s] 38%|███▊      | 616/1605 [09:52<14:08,  1.17it/s] 38%|███▊      | 617/1605 [09:53<14:07,  1.17it/s] 39%|███▊      | 618/1605 [09:54<14:05,  1.17it/s] 39%|███▊      | 619/1605 [09:54<13:58,  1.18it/s] 39%|███▊      | 620/1605 [09:55<14:00,  1.17it/s] 39%|███▊      | 621/1605 [09:56<13:57,  1.17it/s] 39%|███▉      | 622/1605 [09:57<13:59,  1.17it/s] 39%|███▉      | 623/1605 [09:58<13:57,  1.17it/s] 39%|███▉      | 624/1605 [09:59<13:53,  1.18it/s] 39%|███▉      | 625/1605 [10:00<14:01,  1.16it/s] 39%|███▉      | 626/1605 [10:00<13:52,  1.18it/s] 39%|███▉      | 627/1605 [10:01<13:58,  1.17it/s] 39%|███▉      | 628/1605 [10:02<13:52,  1.17it/s] 39%|███▉      | 629/1605 [10:03<13:54,  1.17it/s] 39%|███▉      | 630/1605 [10:04<13:55,  1.17it/s] 39%|███▉      | 631/1605 [10:05<13:52,  1.17it/s] 39%|███▉      | 632/1605 [10:06<13:58,  1.16it/s] 39%|███▉      | 633/1605 [10:06<13:49,  1.17it/s] 40%|███▉      | 634/1605 [10:07<13:50,  1.17it/s] 40%|███▉      | 635/1605 [10:08<13:48,  1.17it/s] 40%|███▉      | 636/1605 [10:09<13:49,  1.17it/s] 40%|███▉      | 637/1605 [10:10<13:52,  1.16it/s] 40%|███▉      | 638/1605 [10:11<13:46,  1.17it/s] 40%|███▉      | 639/1605 [10:12<13:48,  1.17it/s] 40%|███▉      | 640/1605 [10:12<13:47,  1.17it/s] 40%|███▉      | 641/1605 [10:13<13:44,  1.17it/s] 40%|████      | 642/1605 [10:14<13:46,  1.17it/s] 40%|████      | 643/1605 [10:15<13:40,  1.17it/s] 40%|████      | 644/1605 [10:16<13:47,  1.16it/s] 40%|████      | 645/1605 [10:17<13:46,  1.16it/s] 40%|████      | 646/1605 [10:18<13:45,  1.16it/s] 40%|████      | 647/1605 [10:18<13:45,  1.16it/s] 40%|████      | 648/1605 [10:19<13:40,  1.17it/s] 40%|████      | 649/1605 [10:20<13:37,  1.17it/s] 40%|████      | 650/1605 [10:21<13:35,  1.17it/s] 41%|████      | 651/1605 [10:22<13:36,  1.17it/s] 41%|████      | 652/1605 [10:23<13:32,  1.17it/s] 41%|████      | 653/1605 [10:24<13:35,  1.17it/s] 41%|████      | 654/1605 [10:24<13:30,  1.17it/s] 41%|████      | 655/1605 [10:25<13:31,  1.17it/s] 41%|████      | 656/1605 [10:26<13:39,  1.16it/s] 41%|████      | 657/1605 [10:27<13:41,  1.15it/s] 41%|████      | 658/1605 [10:28<13:33,  1.16it/s] 41%|████      | 659/1605 [10:29<13:34,  1.16it/s] 41%|████      | 660/1605 [10:30<13:32,  1.16it/s] 41%|████      | 661/1605 [10:30<13:30,  1.16it/s] 41%|████      | 662/1605 [10:31<13:25,  1.17it/s] 41%|████▏     | 663/1605 [10:32<13:24,  1.17it/s] 41%|████▏     | 664/1605 [10:33<13:31,  1.16it/s] 41%|████▏     | 665/1605 [10:34<13:26,  1.17it/s] 41%|████▏     | 666/1605 [10:35<13:28,  1.16it/s] 42%|████▏     | 667/1605 [10:36<13:23,  1.17it/s] 42%|████▏     | 668/1605 [10:36<13:18,  1.17it/s] 42%|████▏     | 669/1605 [10:37<13:20,  1.17it/s] 42%|████▏     | 670/1605 [10:38<13:20,  1.17it/s] 42%|████▏     | 671/1605 [10:39<13:19,  1.17it/s] 42%|████▏     | 672/1605 [10:40<13:15,  1.17it/s] 42%|████▏     | 673/1605 [10:41<13:18,  1.17it/s] 42%|████▏     | 674/1605 [10:42<13:14,  1.17it/s] 42%|████▏     | 675/1605 [10:42<13:22,  1.16it/s] 42%|████▏     | 676/1605 [10:43<13:17,  1.17it/s] 42%|████▏     | 677/1605 [10:44<13:17,  1.16it/s] 42%|████▏     | 678/1605 [10:45<13:12,  1.17it/s] 42%|████▏     | 679/1605 [10:46<13:12,  1.17it/s] 42%|████▏     | 680/1605 [10:47<13:09,  1.17it/s] 42%|████▏     | 681/1605 [10:48<13:20,  1.15it/s] 42%|████▏     | 682/1605 [10:48<13:11,  1.17it/s] 43%|████▎     | 683/1605 [10:49<13:10,  1.17it/s] 43%|████▎     | 684/1605 [10:50<13:04,  1.17it/s] 43%|████▎     | 685/1605 [10:51<13:11,  1.16it/s] 43%|████▎     | 686/1605 [10:52<13:05,  1.17it/s] 43%|████▎     | 687/1605 [10:53<13:07,  1.17it/s] 43%|████▎     | 688/1605 [10:54<13:06,  1.17it/s] 43%|████▎     | 689/1605 [10:54<13:04,  1.17it/s] 43%|████▎     | 690/1605 [10:55<13:01,  1.17it/s] 43%|████▎     | 691/1605 [10:56<12:58,  1.17it/s] 43%|████▎     | 692/1605 [10:57<12:57,  1.18it/s] 43%|████▎     | 693/1605 [10:58<13:00,  1.17it/s] 43%|████▎     | 694/1605 [10:59<12:53,  1.18it/s] 43%|████▎     | 695/1605 [11:00<12:50,  1.18it/s] 43%|████▎     | 696/1605 [11:00<12:58,  1.17it/s] 43%|████▎     | 697/1605 [11:01<12:55,  1.17it/s] 43%|████▎     | 698/1605 [11:02<12:51,  1.18it/s] 44%|████▎     | 699/1605 [11:03<12:51,  1.17it/s] 44%|████▎     | 700/1605 [11:04<12:54,  1.17it/s] 44%|████▎     | 701/1605 [11:05<12:52,  1.17it/s] 44%|████▎     | 702/1605 [11:06<12:50,  1.17it/s] 44%|████▍     | 703/1605 [11:06<12:52,  1.17it/s] 44%|████▍     | 704/1605 [11:07<12:50,  1.17it/s] 44%|████▍     | 705/1605 [11:08<12:46,  1.17it/s] 44%|████▍     | 706/1605 [11:09<12:47,  1.17it/s] 44%|████▍     | 707/1605 [11:10<12:46,  1.17it/s] 44%|████▍     | 708/1605 [11:11<12:47,  1.17it/s] 44%|████▍     | 709/1605 [11:12<12:47,  1.17it/s] 44%|████▍     | 710/1605 [11:12<12:42,  1.17it/s] 44%|████▍     | 711/1605 [11:13<12:43,  1.17it/s] 44%|████▍     | 712/1605 [11:14<12:41,  1.17it/s] 44%|████▍     | 713/1605 [11:15<12:42,  1.17it/s] 44%|████▍     | 714/1605 [11:16<12:41,  1.17it/s] 45%|████▍     | 715/1605 [11:17<12:42,  1.17it/s] 45%|████▍     | 716/1605 [11:18<12:38,  1.17it/s] 45%|████▍     | 717/1605 [11:18<12:36,  1.17it/s] 45%|████▍     | 718/1605 [11:19<12:39,  1.17it/s] 45%|████▍     | 719/1605 [11:20<12:37,  1.17it/s] 45%|████▍     | 720/1605 [11:21<12:38,  1.17it/s] 45%|████▍     | 721/1605 [11:22<12:39,  1.16it/s] 45%|████▍     | 722/1605 [11:23<12:37,  1.17it/s] 45%|████▌     | 723/1605 [11:24<12:32,  1.17it/s] 45%|████▌     | 724/1605 [11:24<12:28,  1.18it/s] 45%|████▌     | 725/1605 [11:25<12:35,  1.16it/s] 45%|████▌     | 726/1605 [11:26<12:35,  1.16it/s] 45%|████▌     | 727/1605 [11:27<12:33,  1.17it/s] 45%|████▌     | 728/1605 [11:28<12:25,  1.18it/s] 45%|████▌     | 729/1605 [11:29<12:30,  1.17it/s] 45%|████▌     | 730/1605 [11:29<12:27,  1.17it/s] 46%|████▌     | 731/1605 [11:30<12:23,  1.18it/s] 46%|████▌     | 732/1605 [11:31<12:27,  1.17it/s] 46%|████▌     | 733/1605 [11:32<12:27,  1.17it/s] 46%|████▌     | 734/1605 [11:33<12:21,  1.17it/s] 46%|████▌     | 735/1605 [11:34<12:20,  1.17it/s] 46%|████▌     | 736/1605 [11:35<12:21,  1.17it/s] 46%|████▌     | 737/1605 [11:35<12:19,  1.17it/s] 46%|████▌     | 738/1605 [11:36<12:22,  1.17it/s] 46%|████▌     | 739/1605 [11:37<12:27,  1.16it/s] 46%|████▌     | 740/1605 [11:38<12:26,  1.16it/s] 46%|████▌     | 741/1605 [11:39<12:21,  1.16it/s] 46%|████▌     | 742/1605 [11:40<12:21,  1.16it/s] 46%|████▋     | 743/1605 [11:41<12:16,  1.17it/s] 46%|████▋     | 744/1605 [11:41<12:18,  1.17it/s] 46%|████▋     | 745/1605 [11:42<12:17,  1.17it/s] 46%|████▋     | 746/1605 [11:43<12:15,  1.17it/s] 47%|████▋     | 747/1605 [11:44<12:18,  1.16it/s] 47%|████▋     | 748/1605 [11:45<12:11,  1.17it/s] 47%|████▋     | 749/1605 [11:46<12:10,  1.17it/s] 47%|████▋     | 750/1605 [11:47<12:10,  1.17it/s] 47%|████▋     | 751/1605 [11:47<12:07,  1.17it/s] 47%|████▋     | 752/1605 [11:48<12:09,  1.17it/s] 47%|████▋     | 753/1605 [11:49<12:04,  1.18it/s] 47%|████▋     | 754/1605 [11:50<12:07,  1.17it/s] 47%|████▋     | 755/1605 [11:51<12:10,  1.16it/s] 47%|████▋     | 756/1605 [11:52<12:08,  1.17it/s] 47%|████▋     | 757/1605 [11:53<12:07,  1.17it/s] 47%|████▋     | 758/1605 [11:53<12:05,  1.17it/s] 47%|████▋     | 759/1605 [11:54<12:02,  1.17it/s] 47%|████▋     | 760/1605 [11:55<11:57,  1.18it/s] 47%|████▋     | 761/1605 [11:56<12:02,  1.17it/s] 47%|████▋     | 762/1605 [11:57<12:01,  1.17it/s] 48%|████▊     | 763/1605 [11:58<11:59,  1.17it/s] 48%|████▊     | 764/1605 [11:59<11:55,  1.18it/s] 48%|████▊     | 765/1605 [11:59<11:52,  1.18it/s] 48%|████▊     | 766/1605 [12:00<11:52,  1.18it/s] 48%|████▊     | 767/1605 [12:01<11:53,  1.18it/s] 48%|████▊     | 768/1605 [12:02<11:51,  1.18it/s] 48%|████▊     | 769/1605 [12:03<11:52,  1.17it/s] 48%|████▊     | 770/1605 [12:04<11:49,  1.18it/s] 48%|████▊     | 771/1605 [12:05<11:51,  1.17it/s] 48%|████▊     | 772/1605 [12:05<11:49,  1.17it/s] 48%|████▊     | 773/1605 [12:06<11:49,  1.17it/s] 48%|████▊     | 774/1605 [12:07<11:49,  1.17it/s] 48%|████▊     | 775/1605 [12:08<11:50,  1.17it/s] 48%|████▊     | 776/1605 [12:09<11:57,  1.16it/s] 48%|████▊     | 777/1605 [12:10<11:52,  1.16it/s] 48%|████▊     | 778/1605 [12:11<11:50,  1.16it/s] 49%|████▊     | 779/1605 [12:11<11:44,  1.17it/s] 49%|████▊     | 780/1605 [12:12<11:49,  1.16it/s] 49%|████▊     | 781/1605 [12:13<11:45,  1.17it/s] 49%|████▊     | 782/1605 [12:14<11:38,  1.18it/s] 49%|████▉     | 783/1605 [12:15<11:38,  1.18it/s] 49%|████▉     | 784/1605 [12:16<11:39,  1.17it/s] 49%|████▉     | 785/1605 [12:17<11:42,  1.17it/s] 49%|████▉     | 786/1605 [12:17<11:38,  1.17it/s] 49%|████▉     | 787/1605 [12:18<11:36,  1.18it/s] 49%|████▉     | 788/1605 [12:19<11:37,  1.17it/s] 49%|████▉     | 789/1605 [12:20<11:34,  1.17it/s] 49%|████▉     | 790/1605 [12:21<11:35,  1.17it/s] 49%|████▉     | 791/1605 [12:22<11:30,  1.18it/s] 49%|████▉     | 792/1605 [12:22<11:37,  1.17it/s] 49%|████▉     | 793/1605 [12:23<11:32,  1.17it/s] 49%|████▉     | 794/1605 [12:24<11:31,  1.17it/s] 50%|████▉     | 795/1605 [12:25<11:30,  1.17it/s] 50%|████▉     | 796/1605 [12:26<11:27,  1.18it/s] 50%|████▉     | 797/1605 [12:27<11:26,  1.18it/s] 50%|████▉     | 798/1605 [12:28<11:29,  1.17it/s] 50%|████▉     | 799/1605 [12:28<11:23,  1.18it/s] 50%|████▉     | 800/1605 [12:29<11:26,  1.17it/s] 50%|████▉     | 801/1605 [12:30<11:26,  1.17it/s] 50%|████▉     | 802/1605 [12:31<11:25,  1.17it/s] 50%|█████     | 803/1605 [12:32<11:30,  1.16it/s] 50%|█████     | 804/1605 [12:33<11:26,  1.17it/s] 50%|█████     | 805/1605 [12:34<11:21,  1.17it/s] 50%|█████     | 806/1605 [12:34<11:22,  1.17it/s] 50%|█████     | 807/1605 [12:35<11:22,  1.17it/s] 50%|█████     | 808/1605 [12:36<11:21,  1.17it/s] 50%|█████     | 809/1605 [12:37<11:19,  1.17it/s] 50%|█████     | 810/1605 [12:38<11:21,  1.17it/s] 51%|█████     | 811/1605 [12:39<11:18,  1.17it/s] 51%|█████     | 812/1605 [12:40<11:13,  1.18it/s] 51%|█████     | 813/1605 [12:40<11:15,  1.17it/s] 51%|█████     | 814/1605 [12:41<11:12,  1.18it/s] 51%|█████     | 815/1605 [12:42<11:10,  1.18it/s] 51%|█████     | 816/1605 [12:43<11:07,  1.18it/s] 51%|█████     | 817/1605 [12:44<11:11,  1.17it/s] 51%|█████     | 818/1605 [12:45<11:12,  1.17it/s] 51%|█████     | 819/1605 [12:45<11:08,  1.18it/s] 51%|█████     | 820/1605 [12:46<11:06,  1.18it/s] 51%|█████     | 821/1605 [12:47<11:06,  1.18it/s] 51%|█████     | 822/1605 [12:48<11:06,  1.17it/s] 51%|█████▏    | 823/1605 [12:49<11:06,  1.17it/s] 51%|█████▏    | 824/1605 [12:50<11:04,  1.18it/s] 51%|█████▏    | 825/1605 [12:51<11:10,  1.16it/s] 51%|█████▏    | 826/1605 [12:51<11:09,  1.16it/s] 52%|█████▏    | 827/1605 [12:52<11:05,  1.17it/s] 52%|█████▏    | 828/1605 [12:53<11:02,  1.17it/s] 52%|█████▏    | 829/1605 [12:54<10:59,  1.18it/s] 52%|█████▏    | 830/1605 [12:55<10:59,  1.17it/s] 52%|█████▏    | 831/1605 [12:56<10:58,  1.17it/s] 52%|█████▏    | 832/1605 [12:57<10:58,  1.17it/s] 52%|█████▏    | 833/1605 [12:57<11:01,  1.17it/s] 52%|█████▏    | 834/1605 [12:58<10:58,  1.17it/s] 52%|█████▏    | 835/1605 [12:59<10:55,  1.18it/s] 52%|█████▏    | 836/1605 [13:00<10:55,  1.17it/s] 52%|█████▏    | 837/1605 [13:01<10:52,  1.18it/s] 52%|█████▏    | 838/1605 [13:02<10:55,  1.17it/s] 52%|█████▏    | 839/1605 [13:03<10:53,  1.17it/s] 52%|█████▏    | 840/1605 [13:03<10:55,  1.17it/s] 52%|█████▏    | 841/1605 [13:04<10:53,  1.17it/s] 52%|█████▏    | 842/1605 [13:05<10:50,  1.17it/s] 53%|█████▎    | 843/1605 [13:06<10:56,  1.16it/s] 53%|█████▎    | 844/1605 [13:07<10:49,  1.17it/s] 53%|█████▎    | 845/1605 [13:08<10:50,  1.17it/s] 53%|█████▎    | 846/1605 [13:09<10:55,  1.16it/s] 53%|█████▎    | 847/1605 [13:09<10:53,  1.16it/s] 53%|█████▎    | 848/1605 [13:10<10:48,  1.17it/s] 53%|█████▎    | 849/1605 [13:11<10:47,  1.17it/s] 53%|█████▎    | 850/1605 [13:12<10:43,  1.17it/s] 53%|█████▎    | 851/1605 [13:13<10:46,  1.17it/s] 53%|█████▎    | 852/1605 [13:14<10:47,  1.16it/s] 53%|█████▎    | 853/1605 [13:15<10:43,  1.17it/s] 53%|█████▎    | 854/1605 [13:15<10:42,  1.17it/s] 53%|█████▎    | 855/1605 [13:16<10:40,  1.17it/s] 53%|█████▎    | 856/1605 [13:17<10:40,  1.17it/s] 53%|█████▎    | 857/1605 [13:18<10:36,  1.17it/s] 53%|█████▎    | 858/1605 [13:19<10:38,  1.17it/s] 54%|█████▎    | 859/1605 [13:20<10:35,  1.17it/s] 54%|█████▎    | 860/1605 [13:21<10:37,  1.17it/s] 54%|█████▎    | 861/1605 [13:21<10:38,  1.17it/s] 54%|█████▎    | 862/1605 [13:22<10:34,  1.17it/s] 54%|█████▍    | 863/1605 [13:23<10:34,  1.17it/s] 54%|█████▍    | 864/1605 [13:24<10:29,  1.18it/s] 54%|█████▍    | 865/1605 [13:25<10:32,  1.17it/s] 54%|█████▍    | 866/1605 [13:26<10:29,  1.17it/s] 54%|█████▍    | 867/1605 [13:27<10:28,  1.17it/s] 54%|█████▍    | 868/1605 [13:27<10:26,  1.18it/s] 54%|█████▍    | 869/1605 [13:28<10:29,  1.17it/s] 54%|█████▍    | 870/1605 [13:29<10:26,  1.17it/s] 54%|█████▍    | 871/1605 [13:30<10:24,  1.18it/s] 54%|█████▍    | 872/1605 [13:31<10:21,  1.18it/s] 54%|█████▍    | 873/1605 [13:32<10:20,  1.18it/s] 54%|█████▍    | 874/1605 [13:32<10:24,  1.17it/s] 55%|█████▍    | 875/1605 [13:33<10:22,  1.17it/s] 55%|█████▍    | 876/1605 [13:34<10:19,  1.18it/s] 55%|█████▍    | 877/1605 [13:35<10:23,  1.17it/s] 55%|█████▍    | 878/1605 [13:36<10:23,  1.17it/s] 55%|█████▍    | 879/1605 [13:37<10:20,  1.17it/s] 55%|█████▍    | 880/1605 [13:38<10:18,  1.17it/s] 55%|█████▍    | 881/1605 [13:38<10:20,  1.17it/s] 55%|█████▍    | 882/1605 [13:39<10:16,  1.17it/s] 55%|█████▌    | 883/1605 [13:40<10:14,  1.17it/s] 55%|█████▌    | 884/1605 [13:41<10:22,  1.16it/s] 55%|█████▌    | 885/1605 [13:42<10:20,  1.16it/s] 55%|█████▌    | 886/1605 [13:43<10:20,  1.16it/s] 55%|█████▌    | 887/1605 [13:44<10:15,  1.17it/s] 55%|█████▌    | 888/1605 [13:44<10:14,  1.17it/s] 55%|█████▌    | 889/1605 [13:45<10:12,  1.17it/s] 55%|█████▌    | 890/1605 [13:46<10:13,  1.17it/s] 56%|█████▌    | 891/1605 [13:47<10:13,  1.16it/s] 56%|█████▌    | 892/1605 [13:48<10:11,  1.17it/s] 56%|█████▌    | 893/1605 [13:49<10:05,  1.18it/s] 56%|█████▌    | 894/1605 [13:50<10:06,  1.17it/s] 56%|█████▌    | 895/1605 [13:50<10:08,  1.17it/s] 56%|█████▌    | 896/1605 [13:51<10:04,  1.17it/s] 56%|█████▌    | 897/1605 [13:52<10:06,  1.17it/s] 56%|█████▌    | 898/1605 [13:53<10:04,  1.17it/s] 56%|█████▌    | 899/1605 [13:54<10:03,  1.17it/s] 56%|█████▌    | 900/1605 [13:55<10:02,  1.17it/s] 56%|█████▌    | 901/1605 [13:56<09:57,  1.18it/s] 56%|█████▌    | 902/1605 [13:56<10:02,  1.17it/s] 56%|█████▋    | 903/1605 [13:57<09:58,  1.17it/s] 56%|█████▋    | 904/1605 [13:58<09:57,  1.17it/s] 56%|█████▋    | 905/1605 [13:59<09:57,  1.17it/s] 56%|█████▋    | 906/1605 [14:00<09:54,  1.18it/s] 57%|█████▋    | 907/1605 [14:01<09:55,  1.17it/s] 57%|█████▋    | 908/1605 [14:02<09:58,  1.16it/s] 57%|█████▋    | 909/1605 [14:02<09:57,  1.16it/s] 57%|█████▋    | 910/1605 [14:03<09:57,  1.16it/s] 57%|█████▋    | 911/1605 [14:04<09:52,  1.17it/s] 57%|█████▋    | 912/1605 [14:05<09:57,  1.16it/s] 57%|█████▋    | 913/1605 [14:06<09:52,  1.17it/s] 57%|█████▋    | 914/1605 [14:07<09:49,  1.17it/s] 57%|█████▋    | 915/1605 [14:08<09:45,  1.18it/s] 57%|█████▋    | 916/1605 [14:08<09:49,  1.17it/s] 57%|█████▋    | 917/1605 [14:09<09:48,  1.17it/s] 57%|█████▋    | 918/1605 [14:10<09:46,  1.17it/s] 57%|█████▋    | 919/1605 [14:11<09:49,  1.16it/s] 57%|█████▋    | 920/1605 [14:12<09:45,  1.17it/s] 57%|█████▋    | 921/1605 [14:13<09:45,  1.17it/s] 57%|█████▋    | 922/1605 [14:14<09:42,  1.17it/s] 58%|█████▊    | 923/1605 [14:14<09:42,  1.17it/s] 58%|█████▊    | 924/1605 [14:15<09:41,  1.17it/s] 58%|█████▊    | 925/1605 [14:16<09:41,  1.17it/s] 58%|█████▊    | 926/1605 [14:17<09:46,  1.16it/s] 58%|█████▊    | 927/1605 [14:18<09:43,  1.16it/s] 58%|█████▊    | 928/1605 [14:19<09:43,  1.16it/s] 58%|█████▊    | 929/1605 [14:20<09:41,  1.16it/s] 58%|█████▊    | 930/1605 [14:20<09:38,  1.17it/s] 58%|█████▊    | 931/1605 [14:21<09:37,  1.17it/s] 58%|█████▊    | 932/1605 [14:22<09:38,  1.16it/s] 58%|█████▊    | 933/1605 [14:23<09:37,  1.16it/s] 58%|█████▊    | 934/1605 [14:24<09:35,  1.17it/s] 58%|█████▊    | 935/1605 [14:25<09:33,  1.17it/s] 58%|█████▊    | 936/1605 [14:26<09:34,  1.17it/s] 58%|█████▊    | 937/1605 [14:26<09:31,  1.17it/s] 58%|█████▊    | 938/1605 [14:27<09:31,  1.17it/s] 59%|█████▊    | 939/1605 [14:28<09:32,  1.16it/s] 59%|█████▊    | 940/1605 [14:29<09:27,  1.17it/s] 59%|█████▊    | 941/1605 [14:30<09:27,  1.17it/s] 59%|█████▊    | 942/1605 [14:31<09:23,  1.18it/s] 59%|█████▉    | 943/1605 [14:32<09:24,  1.17it/s] 59%|█████▉    | 944/1605 [14:32<09:23,  1.17it/s] 59%|█████▉    | 945/1605 [14:33<09:23,  1.17it/s] 59%|█████▉    | 946/1605 [14:34<09:17,  1.18it/s] 59%|█████▉    | 947/1605 [14:35<09:19,  1.18it/s] 59%|█████▉    | 948/1605 [14:36<09:18,  1.18it/s] 59%|█████▉    | 949/1605 [14:37<09:20,  1.17it/s] 59%|█████▉    | 950/1605 [14:37<09:18,  1.17it/s] 59%|█████▉    | 951/1605 [14:38<09:20,  1.17it/s] 59%|█████▉    | 952/1605 [14:39<09:16,  1.17it/s] 59%|█████▉    | 953/1605 [14:40<09:14,  1.18it/s] 59%|█████▉    | 954/1605 [14:41<09:15,  1.17it/s] 60%|█████▉    | 955/1605 [14:42<09:13,  1.17it/s] 60%|█████▉    | 956/1605 [14:43<09:16,  1.17it/s] 60%|█████▉    | 957/1605 [14:43<09:11,  1.18it/s] 60%|█████▉    | 958/1605 [14:44<09:13,  1.17it/s] 60%|█████▉    | 959/1605 [14:45<09:09,  1.18it/s] 60%|█████▉    | 960/1605 [14:46<09:13,  1.16it/s] 60%|█████▉    | 961/1605 [14:47<09:11,  1.17it/s] 60%|█████▉    | 962/1605 [14:48<09:10,  1.17it/s] 60%|██████    | 963/1605 [14:49<09:11,  1.16it/s] 60%|██████    | 964/1605 [14:49<09:09,  1.17it/s] 60%|██████    | 965/1605 [14:50<09:07,  1.17it/s] 60%|██████    | 966/1605 [14:51<09:05,  1.17it/s] 60%|██████    | 967/1605 [14:52<09:06,  1.17it/s] 60%|██████    | 968/1605 [14:53<09:04,  1.17it/s] 60%|██████    | 969/1605 [14:54<09:01,  1.17it/s] 60%|██████    | 970/1605 [14:55<09:05,  1.16it/s] 60%|██████    | 971/1605 [14:55<09:03,  1.17it/s] 61%|██████    | 972/1605 [14:56<09:05,  1.16it/s] 61%|██████    | 973/1605 [14:57<09:01,  1.17it/s] 61%|██████    | 974/1605 [14:58<09:01,  1.16it/s] 61%|██████    | 975/1605 [14:59<08:57,  1.17it/s] 61%|██████    | 976/1605 [15:00<08:57,  1.17it/s] 61%|██████    | 977/1605 [15:01<08:56,  1.17it/s] 61%|██████    | 978/1605 [15:01<08:55,  1.17it/s] 61%|██████    | 979/1605 [15:02<08:55,  1.17it/s] 61%|██████    | 980/1605 [15:03<08:53,  1.17it/s] 61%|██████    | 981/1605 [15:04<08:51,  1.17it/s] 61%|██████    | 982/1605 [15:05<08:55,  1.16it/s] 61%|██████    | 983/1605 [15:06<08:52,  1.17it/s] 61%|██████▏   | 984/1605 [15:07<08:52,  1.17it/s] 61%|██████▏   | 985/1605 [15:07<08:49,  1.17it/s] 61%|██████▏   | 986/1605 [15:08<08:47,  1.17it/s] 61%|██████▏ {'loss': 0.6254, 'learning_rate': 1.884735202492212e-05, 'epoch': 1.87}
  | 987/1605 [15:09<08:48,  1.17it/s] 62%|██████▏   | 988/1605 [15:10<08:47,  1.17it/s] 62%|██████▏   | 989/1605 [15:11<08:47,  1.17it/s] 62%|██████▏   | 990/1605 [15:12<08:45,  1.17it/s] 62%|██████▏   | 991/1605 [15:13<08:49,  1.16it/s] 62%|██████▏   | 992/1605 [15:13<08:47,  1.16it/s] 62%|██████▏   | 993/1605 [15:14<08:44,  1.17it/s] 62%|██████▏   | 994/1605 [15:15<08:41,  1.17it/s] 62%|██████▏   | 995/1605 [15:16<08:41,  1.17it/s] 62%|██████▏   | 996/1605 [15:17<08:44,  1.16it/s] 62%|██████▏   | 997/1605 [15:18<08:41,  1.17it/s] 62%|██████▏   | 998/1605 [15:19<08:38,  1.17it/s] 62%|██████▏   | 999/1605 [15:19<08:40,  1.17it/s] 62%|██████▏   | 1000/1605 [15:20<08:40,  1.16it/s]                                                    62%|██████▏   | 1000/1605 [15:20<08:40,  1.16it/s][INFO|trainer.py:2985] 2024-02-12 20:34:02,707 >> Saving model checkpoint to /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1000
[INFO|configuration_utils.py:473] 2024-02-12 20:34:02,709 >> Configuration saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1000/config.json
[INFO|modeling_utils.py:2462] 2024-02-12 20:34:27,233 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1000/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-02-12 20:34:27,236 >> tokenizer config file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-02-12 20:34:27,237 >> Special tokens file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1000/special_tokens_map.json
 62%|██████▏   | 1001/1605 [16:34<3:47:23, 22.59s/it] 62%|██████▏   | 1002/1605 [16:34<2:41:29, 16.07s/it] 62%|██████▏   | 1003/1605 [16:35<1:55:27, 11.51s/it] 63%|██████▎   | 1004/1605 [16:36<1:23:13,  8.31s/it] 63%|██████▎   | 1005/1605 [16:37<1:00:40,  6.07s/it] 63%|██████▎   | 1006/1605 [16:38<44:55,  4.50s/it]   63%|██████▎   | 1007/1605 [16:39<33:54,  3.40s/it] 63%|██████▎   | 1008/1605 [16:40<26:14,  2.64s/it] 63%|██████▎   | 1009/1605 [16:40<20:49,  2.10s/it] 63%|██████▎   | 1010/1605 [16:41<17:07,  1.73s/it] 63%|██████▎   | 1011/1605 [16:42<14:30,  1.47s/it] 63%|██████▎   | 1012/1605 [16:43<12:35,  1.27s/it] 63%|██████▎   | 1013/1605 [16:44<11:22,  1.15s/it] 63%|██████▎   | 1014/1605 [16:45<10:22,  1.05s/it] 63%|██████▎   | 1015/1605 [16:45<09:46,  1.01it/s] 63%|██████▎   | 1016/1605 [16:46<09:18,  1.05it/s] 63%|██████▎   | 1017/1605 [16:47<08:59,  1.09it/s] 63%|██████▎   | 1018/1605 [16:48<08:45,  1.12it/s] 63%|██████▎   | 1019/1605 [16:49<08:39,  1.13it/s] 64%|██████▎   | 1020/1605 [16:50<08:29,  1.15it/s] 64%|██████▎   | 1021/1605 [16:51<08:23,  1.16it/s] 64%|██████▎   | 1022/1605 [16:51<08:23,  1.16it/s] 64%|██████▎   | 1023/1605 [16:52<08:19,  1.16it/s] 64%|██████▍   | 1024/1605 [16:53<08:19,  1.16it/s] 64%|██████▍   | 1025/1605 [16:54<08:19,  1.16it/s] 64%|██████▍   | 1026/1605 [16:55<08:14,  1.17it/s] 64%|██████▍   | 1027/1605 [16:56<08:13,  1.17it/s] 64%|██████▍   | 1028/1605 [16:57<08:13,  1.17it/s] 64%|██████▍   | 1029/1605 [16:57<08:11,  1.17it/s] 64%|██████▍   | 1030/1605 [16:58<08:07,  1.18it/s] 64%|██████▍   | 1031/1605 [16:59<08:08,  1.17it/s] 64%|██████▍   | 1032/1605 [17:00<08:06,  1.18it/s] 64%|██████▍   | 1033/1605 [17:01<08:03,  1.18it/s] 64%|██████▍   | 1034/1605 [17:02<08:07,  1.17it/s] 64%|██████▍   | 1035/1605 [17:02<08:05,  1.17it/s] 65%|██████▍   | 1036/1605 [17:03<08:08,  1.17it/s] 65%|██████▍   | 1037/1605 [17:04<08:09,  1.16it/s] 65%|██████▍   | 1038/1605 [17:05<08:07,  1.16it/s] 65%|██████▍   | 1039/1605 [17:06<08:02,  1.17it/s] 65%|██████▍   | 1040/1605 [17:07<08:00,  1.18it/s] 65%|██████▍   | 1041/1605 [17:08<07:57,  1.18it/s] 65%|██████▍   | 1042/1605 [17:08<08:00,  1.17it/s] 65%|██████▍   | 1043/1605 [17:09<07:58,  1.18it/s] 65%|██████▌   | 1044/1605 [17:10<07:57,  1.18it/s] 65%|██████▌   | 1045/1605 [17:11<07:58,  1.17it/s] 65%|██████▌   | 1046/1605 [17:12<07:58,  1.17it/s] 65%|██████▌   | 1047/1605 [17:13<07:55,  1.17it/s] 65%|██████▌   | 1048/1605 [17:14<07:58,  1.16it/s] 65%|██████▌   | 1049/1605 [17:14<07:56,  1.17it/s] 65%|██████▌   | 1050/1605 [17:15<07:53,  1.17it/s] 65%|██████▌   | 1051/1605 [17:16<07:53,  1.17it/s] 66%|██████▌   | 1052/1605 [17:17<07:51,  1.17it/s] 66%|██████▌   | 1053/1605 [17:18<07:52,  1.17it/s] 66%|██████▌   | 1054/1605 [17:19<07:49,  1.17it/s] 66%|██████▌   | 1055/1605 [17:20<07:49,  1.17it/s] 66%|██████▌   | 1056/1605 [17:20<07:49,  1.17it/s] 66%|██████▌   | 1057/1605 [17:21<07:45,  1.18it/s] 66%|██████▌   | 1058/1605 [17:22<07:48,  1.17it/s] 66%|██████▌   | 1059/1605 [17:23<07:45,  1.17it/s] 66%|██████▌   | 1060/1605 [17:24<07:46,  1.17it/s] 66%|██████▌   | 1061/1605 [17:25<07:44,  1.17it/s] 66%|██████▌   | 1062/1605 [17:26<07:43,  1.17it/s] 66%|██████▌   | 1063/1605 [17:26<07:42,  1.17it/s] 66%|██████▋   | 1064/1605 [17:27<07:40,  1.17it/s] 66%|██████▋   | 1065/1605 [17:28<07:37,  1.18it/s] 66%|██████▋   | 1066/1605 [17:29<07:38,  1.17it/s] 66%|██████▋   | 1067/1605 [17:30<07:41,  1.17it/s] 67%|██████▋   | 1068/1605 [17:31<07:36,  1.18it/s] 67%|██████▋   | 1069/1605 [17:31<07:38,  1.17it/s] 67%|██████▋   | 1070/1605 [17:32<07:37,  1.17it/s] 67%|██████▋   | 1071/1605 [17:33<07:35,  1.17it/s] 67%|██████▋   | 1072/1605 [17:34<07:34,  1.17it/s] 67%|██████▋   | 1073/1605 [17:35<07:34,  1.17it/s] 67%|██████▋   | 1074/1605 [17:36<07:31,  1.18it/s] 67%|██████▋   | 1075/1605 [17:37<07:32,  1.17it/s] 67%|██████▋   | 1076/1605 [17:37<07:30,  1.17it/s] 67%|██████▋   | 1077/1605 [17:38<07:33,  1.16it/s] 67%|██████▋   | 1078/1605 [17:39<07:30,  1.17it/s] 67%|██████▋   | 1079/1605 [17:40<07:29,  1.17it/s] 67%|██████▋   | 1080/1605 [17:41<07:27,  1.17it/s] 67%|██████▋   | 1081/1605 [17:42<07:29,  1.17it/s] 67%|██████▋   | 1082/1605 [17:43<07:28,  1.17it/s] 67%|██████▋   | 1083/1605 [17:43<07:26,  1.17it/s] 68%|██████▊   | 1084/1605 [17:44<07:25,  1.17it/s] 68%|██████▊   | 1085/1605 [17:45<07:24,  1.17it/s] 68%|██████▊   | 1086/1605 [17:46<07:21,  1.18it/s] 68%|██████▊   | 1087/1605 [17:47<07:21,  1.17it/s] 68%|██████▊   | 1088/1605 [17:48<07:22,  1.17it/s] 68%|██████▊   | 1089/1605 [17:49<07:18,  1.18it/s] 68%|██████▊   | 1090/1605 [17:49<07:18,  1.17it/s] 68%|██████▊   | 1091/1605 [17:50<07:20,  1.17it/s] 68%|██████▊   | 1092/1605 [17:51<07:18,  1.17it/s] 68%|██████▊   | 1093/1605 [17:52<07:16,  1.17it/s] 68%|██████▊   | 1094/1605 [17:53<07:18,  1.17it/s] 68%|██████▊   | 1095/1605 [17:54<07:14,  1.17it/s] 68%|██████▊   | 1096/1605 [17:55<07:16,  1.16it/s] 68%|██████▊   | 1097/1605 [17:55<07:17,  1.16it/s] 68%|██████▊   | 1098/1605 [17:56<07:15,  1.16it/s] 68%|██████▊   | 1099/1605 [17:57<07:16,  1.16it/s] 69%|██████▊   | 1100/1605 [17:58<07:15,  1.16it/s] 69%|██████▊   | 1101/1605 [17:59<07:13,  1.16it/s] 69%|██████▊   | 1102/1605 [18:00<07:08,  1.17it/s] 69%|██████▊   | 1103/1605 [18:01<07:08,  1.17it/s] 69%|██████▉   | 1104/1605 [18:01<07:06,  1.17it/s] 69%|██████▉   | 1105/1605 [18:02<07:07,  1.17it/s] 69%|██████▉   | 1106/1605 [18:03<07:08,  1.16it/s] 69%|██████▉   | 1107/1605 [18:04<07:06,  1.17it/s] 69%|██████▉   | 1108/1605 [18:05<07:05,  1.17it/s] 69%|██████▉   | 1109/1605 [18:06<07:05,  1.17it/s] 69%|██████▉   | 1110/1605 [18:07<07:04,  1.17it/s] 69%|██████▉   | 1111/1605 [18:07<06:59,  1.18it/s] 69%|██████▉   | 1112/1605 [18:08<06:57,  1.18it/s] 69%|██████▉   | 1113/1605 [18:09<06:58,  1.18it/s] 69%|██████▉   | 1114/1605 [18:10<06:59,  1.17it/s] 69%|██████▉   | 1115/1605 [18:11<06:57,  1.17it/s] 70%|██████▉   | 1116/1605 [18:12<06:57,  1.17it/s] 70%|██████▉   | 1117/1605 [18:13<06:56,  1.17it/s] 70%|██████▉   | 1118/1605 [18:13<06:55,  1.17it/s] 70%|██████▉   | 1119/1605 [18:14<06:55,  1.17it/s] 70%|██████▉   | 1120/1605 [18:15<06:55,  1.17it/s] 70%|██████▉   | 1121/1605 [18:16<06:53,  1.17it/s] 70%|██████▉   | 1122/1605 [18:17<06:53,  1.17it/s] 70%|██████▉   | 1123/1605 [18:18<06:53,  1.17it/s] 70%|███████   | 1124/1605 [18:18<06:50,  1.17it/s] 70%|███████   | 1125/1605 [18:19<06:52,  1.16it/s] 70%|███████   | 1126/1605 [18:20<06:49,  1.17it/s] 70%|███████   | 1127/1605 [18:21<06:50,  1.16it/s] 70%|███████   | 1128/1605 [18:22<06:49,  1.16it/s] 70%|███████   | 1129/1605 [18:23<06:47,  1.17it/s] 70%|███████   | 1130/1605 [18:24<06:44,  1.17it/s] 70%|███████   | 1131/1605 [18:25<06:46,  1.17it/s] 71%|███████   | 1132/1605 [18:25<06:45,  1.17it/s] 71%|███████   | 1133/1605 [18:26<06:44,  1.17it/s] 71%|███████   | 1134/1605 [18:27<06:43,  1.17it/s] 71%|███████   | 1135/1605 [18:28<06:41,  1.17it/s] 71%|███████   | 1136/1605 [18:29<06:39,  1.18it/s] 71%|███████   | 1137/1605 [18:30<06:39,  1.17it/s] 71%|███████   | 1138/1605 [18:30<06:38,  1.17it/s] 71%|███████   | 1139/1605 [18:31<06:34,  1.18it/s] 71%|███████   | 1140/1605 [18:32<06:39,  1.16it/s] 71%|███████   | 1141/1605 [18:33<06:36,  1.17it/s] 71%|███████   | 1142/1605 [18:34<06:33,  1.18it/s] 71%|███████   | 1143/1605 [18:35<06:37,  1.16it/s] 71%|███████▏  | 1144/1605 [18:36<06:35,  1.17it/s] 71%|███████▏  | 1145/1605 [18:36<06:32,  1.17it/s] 71%|███████▏  | 1146/1605 [18:37<06:33,  1.17it/s] 71%|███████▏  | 1147/1605 [18:38<06:33,  1.16it/s] 72%|███████▏  | 1148/1605 [18:39<06:30,  1.17it/s] 72%|███████▏  | 1149/1605 [18:40<06:32,  1.16it/s] 72%|███████▏  | 1150/1605 [18:41<06:29,  1.17it/s] 72%|███████▏  | 1151/1605 [18:42<06:28,  1.17it/s] 72%|███████▏  | 1152/1605 [18:42<06:26,  1.17it/s] 72%|███████▏  | 1153/1605 [18:43<06:25,  1.17it/s] 72%|███████▏  | 1154/1605 [18:44<06:26,  1.17it/s] 72%|███████▏  | 1155/1605 [18:45<06:23,  1.17it/s] 72%|███████▏  | 1156/1605 [18:46<06:23,  1.17it/s] 72%|███████▏  | 1157/1605 [18:47<06:22,  1.17it/s] 72%|███████▏  | 1158/1605 [18:48<06:22,  1.17it/s] 72%|███████▏  | 1159/1605 [18:48<06:19,  1.17it/s] 72%|███████▏  | 1160/1605 [18:49<06:17,  1.18it/s] 72%|███████▏  | 1161/1605 [18:50<06:19,  1.17it/s] 72%|███████▏  | 1162/1605 [18:51<06:19,  1.17it/s] 72%|███████▏  | 1163/1605 [18:52<06:19,  1.16it/s] 73%|███████▎  | 1164/1605 [18:53<06:19,  1.16it/s] 73%|███████▎  | 1165/1605 [18:54<06:20,  1.16it/s] 73%|███████▎  | 1166/1605 [18:54<06:17,  1.16it/s] 73%|███████▎  | 1167/1605 [18:55<06:14,  1.17it/s] 73%|███████▎  | 1168/1605 [18:56<06:16,  1.16it/s] 73%|███████▎  | 1169/1605 [18:57<06:13,  1.17it/s] 73%|███████▎  | 1170/1605 [18:58<06:14,  1.16it/s] 73%|███████▎  | 1171/1605 [18:59<06:12,  1.17it/s] 73%|███████▎  | 1172/1605 [19:00<06:10,  1.17it/s] 73%|███████▎  | 1173/1605 [19:00<06:08,  1.17it/s] 73%|███████▎  | 1174/1605 [19:01<06:07,  1.17it/s] 73%|███████▎  | 1175/1605 [19:02<06:04,  1.18it/s] 73%|███████▎  | 1176/1605 [19:03<06:03,  1.18it/s] 73%|███████▎  | 1177/1605 [19:04<06:06,  1.17it/s] 73%|███████▎  | 1178/1605 [19:05<06:07,  1.16it/s] 73%|███████▎  | 1179/1605 [19:06<06:05,  1.17it/s] 74%|███████▎  | 1180/1605 [19:06<06:05,  1.16it/s] 74%|███████▎  | 1181/1605 [19:07<06:01,  1.17it/s] 74%|███████▎  | 1182/1605 [19:08<05:59,  1.18it/s] 74%|███████▎  | 1183/1605 [19:09<05:58,  1.18it/s] 74%|███████▍  | 1184/1605 [19:10<05:57,  1.18it/s] 74%|███████▍  | 1185/1605 [19:11<05:58,  1.17it/s] 74%|███████▍  | 1186/1605 [19:12<06:13,  1.12it/s] 74%|███████▍  | 1187/1605 [19:13<06:10,  1.13it/s] 74%|███████▍  | 1188/1605 [19:13<06:08,  1.13it/s] 74%|███████▍  | 1189/1605 [19:14<06:06,  1.14it/s] 74%|███████▍  | 1190/1605 [19:15<06:04,  1.14it/s] 74%|███████▍  | 1191/1605 [19:16<06:02,  1.14it/s] 74%|███████▍  | 1192/1605 [19:17<06:01,  1.14it/s] 74%|███████▍  | 1193/1605 [19:18<05:59,  1.15it/s] 74%|███████▍  | 1194/1605 [19:19<05:56,  1.15it/s] 74%|███████▍  | 1195/1605 [19:20<05:57,  1.15it/s] 75%|███████▍  | 1196/1605 [19:20<05:52,  1.16it/s] 75%|███████▍  | 1197/1605 [19:21<05:52,  1.16it/s] 75%|███████▍  | 1198/1605 [19:22<05:51,  1.16it/s] 75%|███████▍  | 1199/1605 [19:23<05:51,  1.15it/s] 75%|███████▍  | 1200/1605 [19:24<05:47,  1.17it/s] 75%|███████▍  | 1201/1605 [19:25<05:50,  1.15it/s] 75%|███████▍  | 1202/1605 [19:26<05:50,  1.15it/s] 75%|███████▍  | 1203/1605 [19:26<05:58,  1.12it/s] 75%|███████▌  | 1204/1605 [19:27<05:52,  1.14it/s] 75%|███████▌  | 1205/1605 [19:28<05:48,  1.15it/s] 75%|███████▌  | 1206/1605 [19:29<05:46,  1.15it/s] 75%|███████▌  | 1207/1605 [19:30<05:43,  1.16it/s] 75%|███████▌  | 1208/1605 [19:31<05:42,  1.16it/s] 75%|███████▌  | 1209/1605 [19:32<05:41,  1.16it/s] 75%|███████▌  | 1210/1605 [19:32<05:39,  1.16it/s] 75%|███████▌  | 1211/1605 [19:33<05:41,  1.15it/s] 76%|███████▌  | 1212/1605 [19:34<05:39,  1.16it/s] 76%|███████▌  | 1213/1605 [19:35<05:41,  1.15it/s] 76%|███████▌  | 1214/1605 [19:36<05:39,  1.15it/s] 76%|███████▌  | 1215/1605 [19:37<05:36,  1.16it/s] 76%|███████▌  | 1216/1605 [19:38<05:36,  1.16it/s] 76%|███████▌  | 1217/1605 [19:39<05:36,  1.15it/s] 76%|███████▌  | 1218/1605 [19:39<05:34,  1.16it/s] 76%|███████▌  | 1219/1605 [19:40<05:31,  1.16it/s] 76%|███████▌  | 1220/1605 [19:41<05:31,  1.16it/s] 76%|███████▌  | 1221/1605 [19:42<05:29,  1.16it/s] 76%|███████▌  | 1222/1605 [19:43<05:33,  1.15it/s] 76%|███████▌  | 1223/1605 [19:44<05:28,  1.16it/s] 76%|███████▋  | 1224/1605 [19:45<05:28,  1.16it/s] 76%|███████▋  | 1225/1605 [19:45<05:26,  1.17it/s] 76%|███████▋  | 1226/1605 [19:46<05:28,  1.16it/s] 76%|███████▋  | 1227/1605 [19:47<05:23,  1.17it/s] 77%|███████▋  | 1228/1605 [19:48<05:25,  1.16it/s] 77%|███████▋  | 1229/1605 [19:49<05:23,  1.16it/s] 77%|███████▋  | 1230/1605 [19:50<05:21,  1.17it/s] 77%|███████▋  | 1231/1605 [19:51<05:18,  1.18it/s] 77%|███████▋  | 1232/1605 [19:51<05:18,  1.17it/s] 77%|███████▋  | 1233/1605 [19:52<05:19,  1.17it/s] 77%|███████▋  | 1234/1605 [19:53<05:17,  1.17it/s] 77%|███████▋  | 1235/1605 [19:54<05:16,  1.17it/s] 77%|███████▋  | 1236/1605 [19:55<05:15,  1.17it/s] 77%|███████▋  | 1237/1605 [19:56<05:15,  1.17it/s] 77%|███████▋  | 1238/1605 [19:57<05:13,  1.17it/s] 77%|███████▋  | 1239/1605 [19:57<05:12,  1.17it/s] 77%|███████▋  | 1240/1605 [19:58<05:10,  1.18it/s] 77%|███████▋  | 1241/1605 [19:59<05:09,  1.18it/s] 77%|███████▋  | 1242/1605 [20:00<05:09,  1.17it/s] 77%|███████▋  | 1243/1605 [20:01<05:10,  1.16it/s] 78%|███████▊  | 1244/1605 [20:02<05:09,  1.17it/s] 78%|███████▊  | 1245/1605 [20:03<05:08,  1.17it/s] 78%|███████▊  | 1246/1605 [20:03<05:07,  1.17it/s] 78%|███████▊  | 1247/1605 [20:04<05:05,  1.17it/s] 78%|███████▊  | 1248/1605 [20:05<05:03,  1.18it/s] 78%|███████▊  | 1249/1605 [20:06<05:03,  1.17it/s] 78%|███████▊  | 1250/1605 [20:07<05:03,  1.17it/s] 78%|███████▊  | 1251/1605 [20:08<05:05,  1.16it/s] 78%|███████▊  | 1252/1605 [20:09<05:05,  1.15it/s] 78%|███████▊  | 1253/1605 [20:09<05:02,  1.16it/s] 78%|███████▊  | 1254/1605 [20:10<04:59,  1.17it/s] 78%|███████▊  | 1255/1605 [20:11<04:58,  1.17it/s] 78%|███████▊  | 1256/1605 [20:12<04:58,  1.17it/s] 78%|███████▊  | 1257/1605 [20:13<04:56,  1.17it/s] 78%|███████▊  | 1258/1605 [20:14<04:57,  1.17it/s] 78%|███████▊  | 1259/1605 [20:15<04:55,  1.17it/s] 79%|███████▊  | 1260/1605 [20:15<04:55,  1.17it/s] 79%|███████▊  | 1261/1605 [20:16<04:54,  1.17it/s] 79%|███████▊  | 1262/1605 [20:17<04:52,  1.17it/s] 79%|███████▊  | 1263/1605 [20:18<04:53,  1.17it/s] 79%|███████▉  | 1264/1605 [20:19<04:52,  1.17it/s] 79%|███████▉  | 1265/1605 [20:20<04:53,  1.16it/s] 79%|███████▉  | 1266/1605 [20:21<04:50,  1.17it/s] 79%|███████▉  | 1267/1605 [20:21<04:49,  1.17it/s] 79%|███████▉  | 1268/1605 [20:22<04:48,  1.17it/s] 79%|███████▉  | 1269/1605 [20:23<04:47,  1.17it/s] 79%|███████▉  | 1270/1605 [20:24<04:47,  1.17it/s] 79%|███████▉  | 1271/1605 [20:25<04:44,  1.17it/s] 79%|███████▉  | 1272/1605 [20:26<04:44,  1.17it/s] 79%|███████▉  | 1273/1605 [20:27<04:44,  1.17it/s] 79%|███████▉  | 1274/1605 [20:27<04:45,  1.16it/s] 79%|███████▉  | 1275/1605 [20:28<04:43,  1.16it/s] 80%|███████▉  | 1276/1605 [20:29<04:44,  1.15it/s] 80%|███████▉  | 1277/1605 [20:30<04:41,  1.16it/s] 80%|███████▉  | 1278/1605 [20:31<04:39,  1.17it/s] 80%|███████▉  | 1279/1605 [20:32<04:37,  1.18it/s] 80%|███████▉  | 1280/1605 [20:33<04:37,  1.17it/s] 80%|███████▉  | 1281/1605 [20:33<04:35,  1.17it/s] 80%|███████▉  | 1282/1605 [20:34<04:34,  1.18it/s] 80%|███████▉  | 1283/1605 [20:35<04:33,  1.18it/s] 80%|████████  | 1284/1605 [20:36<04:32,  1.18it/s] 80%|████████  | 1285/1605 [20:37<04:34,  1.16it/s] 80%|████████  | 1286/1605 [20:38<04:32,  1.17it/s] 80%|████████  | 1287/1605 [20:39<04:32,  1.17it/s] 80%|████████  | 1288/1605 [20:39<04:32,  1.16it/s] 80%|████████  | 1289/1605 [20:40<04:30,  1.17it/s] 80%|████████  | 1290/1605 [20:41<04:32,  1.16it/s] 80%|████████  | 1291/1605 [20:42<04:29,  1.16it/s] 80%|████████  | 1292/1605 [20:43<04:27,  1.17it/s] 81%|████████  | 1293/1605 [20:44<04:26,  1.17it/s] 81%|████████  | 1294/1605 [20:45<04:26,  1.17it/s] 81%|████████  | 1295/1605 [20:45<04:26,  1.16it/s] 81%|████████  | 1296/1605 [20:46<04:23,  1.17it/s] 81%|████████  | 1297/1605 [20:47<04:23,  1.17it/s] 81%|████████  | 1298/1605 [20:48<04:22,  1.17it/s] 81%|████████  | 1299/1605 [20:49<04:21,  1.17it/s] 81%|████████  | 1300/1605 [20:50<04:19,  1.17it/s] 81%|████████  | 1301/1605 [20:50<04:20,  1.17it/s] 81%|████████  | 1302/1605 [20:51<04:18,  1.17it/s] 81%|████████  | 1303/1605 [20:52<04:19,  1.16it/s] 81%|████████  | 1304/1605 [20:53<04:18,  1.17it/s] 81%|████████▏ | 1305/1605 [20:54<04:16,  1.17it/s] 81%|████████▏ | 1306/1605 [20:55<04:16,  1.17it/s] 81%|████████▏ | 1307/1605 [20:56<04:14,  1.17it/s] 81%|████████▏ | 1308/1605 [20:56<04:14,  1.17it/s] 82%|████████▏ | 1309/1605 [20:57<04:12,  1.17it/s] 82%|████████▏ | 1310/1605 [20:58<04:13,  1.16it/s] 82%|████████▏ | 1311/1605 [20:59<04:14,  1.16it/s] 82%|████████▏ | 1312/1605 [21:00<04:11,  1.16it/s] 82%|████████▏ | 1313/1605 [21:01<04:11,  1.16it/s] 82%|████████▏ | 1314/1605 [21:02<04:10,  1.16it/s] 82%|████████▏ | 1315/1605 [21:03<04:10,  1.16it/s] 82%|████████▏ | 1316/1605 [21:03<04:07,  1.17it/s] 82%|████████▏ | 1317/1605 [21:04<04:07,  1.17it/s] 82%|████████▏ | 1318/1605 [21:05<04:05,  1.17it/s] 82%|████████▏ | 1319/1605 [21:06<04:06,  1.16it/s] 82%|████████▏ | 1320/1605 [21:07<04:03,  1.17it/s] 82%|████████▏ | 1321/1605 [21:08<04:03,  1.17it/s] 82%|████████▏ | 1322/1605 [21:09<04:03,  1.16it/s] 82%|████████▏ | 1323/1605 [21:09<04:01,  1.17it/s] 82%|████████▏ | 1324/1605 [21:10<03:59,  1.17it/s] 83%|████████▎ | 1325/1605 [21:11<04:00,  1.17it/s] 83%|████████▎ | 1326/1605 [21:12<03:57,  1.17it/s] 83%|████████▎ | 1327/1605 [21:13<03:59,  1.16it/s] 83%|████████▎ | 1328/1605 [21:14<03:59,  1.16it/s] 83%|████████▎ | 1329/1605 [21:15<03:57,  1.16it/s] 83%|████████▎ | 1330/1605 [21:15<03:56,  1.16it/s] 83%|████████▎ | 1331/1605 [21:16<03:56,  1.16it/s] 83%|████████▎ | 1332/1605 [21:17<03:55,  1.16it/s] 83%|████████▎ | 1333/1605 [21:18<03:54,  1.16it/s] 83%|████████▎ | 1334/1605 [21:19<03:51,  1.17it/s] 83%|████████▎ | 1335/1605 [21:20<03:51,  1.17it/s] 83%|████████▎ | 1336/1605 [21:21<03:51,  1.16it/s] 83%|████████▎ | 1337/1605 [21:21<03:48,  1.17it/s] 83%|████████▎ | 1338/1605 [21:22<03:48,  1.17it/s] 83%|████████▎ | 1339/1605 [21:23<03:47,  1.17it/s] 83%|████████▎ | 1340/1605 [21:24<03:48,  1.16it/s] 84%|████████▎ | 1341/1605 [21:25<03:46,  1.17it/s] 84%|████████▎ | 1342/1605 [21:26<03:44,  1.17it/s] 84%|████████▎ | 1343/1605 [21:27<03:44,  1.17it/s] 84%|████████▎ | 1344/1605 [21:27<03:43,  1.17it/s] 84%|████████▍ | 1345/1605 [21:28<03:43,  1.16it/s] 84%|████████▍ | 1346/1605 [21:29<03:41,  1.17it/s] 84%|████████▍ | 1347/1605 [21:30<03:40,  1.17it/s] 84%|████████▍ | 1348/1605 [21:31<03:39,  1.17it/s] 84%|████████▍ | 1349/1605 [21:32<03:38,  1.17it/s] 84%|████████▍ | 1350/1605 [21:33<03:37,  1.17it/s] 84%|████████▍ | 1351/1605 [21:33<03:36,  1.17it/s] 84%|████████▍ | 1352/1605 [21:34<03:35,  1.17it/s] 84%|████████▍ | 1353/1605 [21:35<03:35,  1.17it/s] 84%|████████▍ | 1354/1605 [21:36<03:33,  1.17it/s] 84%|████████▍ | 1355/1605 [21:37<03:34,  1.17it/s] 84%|████████▍ | 1356/1605 [21:38<03:32,  1.17it/s] 85%|████████▍ | 1357/1605 [21:38<03:31,  1.17it/s] 85%|████████▍ | 1358/1605 [21:39<03:31,  1.17it/s] 85%|████████▍ | 1359/1605 [21:40<03:29,  1.18it/s] 85%|████████▍ | 1360/1605 [21:41<03:31,  1.16it/s] 85%|████████▍ | 1361/1605 [21:42<03:28,  1.17it/s] 85%|████████▍ | 1362/1605 [21:43<03:28,  1.16it/s] 85%|████████▍ | 1363/1605 [21:44<03:26,  1.17it/s] 85%|████████▍ | 1364/1605 [21:44<03:25,  1.17it/s] 85%|████████▌ | 1365/1605 [21:45<03:24,  1.17it/s] 85%|████████▌ | 1366/1605 [21:46<03:23,  1.17it/s] 85%|████████▌ | 1367/1605 [21:47<03:23,  1.17it/s] 85%|████████▌ | 1368/1605 [21:48<03:22,  1.17it/s] 85%|████████▌ | 1369/1605 [21:49<03:21,  1.17it/s] 85%|████████▌ | 1370/1605 [21:50<03:21,  1.17it/s] 85%|████████▌ | 1371/1605 [21:50<03:20,  1.17it/s] 85%|████████▌ | 1372/1605 [21:51<03:19,  1.17it/s] 86%|████████▌ | 1373/1605 [21:52<03:19,  1.17it/s] 86%|████████▌ | 1374/1605 [21:53<03:17,  1.17it/s] 86%|████████▌ | 1375/1605 [21:54<03:16,  1.17it/s] 86%|████████▌ | 1376/1605 [21:55<03:16,  1.17it/s] 86%|████████▌ | 1377/1605 [21:56<03:14,  1.17it/s] 86%|████████▌ | 1378/1605 [21:56<03:14,  1.17it/s] 86%|████████▌ | 1379/1605 [21:57<03:13,  1.17it/s] 86%|████████▌ | 1380/1605 [21:58<03:11,  1.18it/s] 86%|████████▌ | 1381/1605 [21:59<03:10,  1.17it/s] 86%|████████▌ | 1382/1605 [22:00<03:10,  1.17it/s] 86%|████████▌ | 1383/1605 [22:01<03:08,  1.18it/s] 86%|████████▌ | 1384/1605 [22:02<03:08,  1.17it/s] 86%|████████▋ | 1385/1605 [22:02<03:07,  1.17it/s] 86%|████████▋ | 1386/1605 [22:03<03:06,  1.17it/s] 86%|████████▋ | 1387/1605 [22:04<03:05,  1.18it/s] 86%|████████▋ | 1388/1605 [22:05<03:04,  1.17it/s] 87%|████████▋ | 1389/1605 [22:06<03:05,  1.17it/s] 87%|████████▋ | 1390/1605 [22:07<03:05,  1.16it/s] 87%|████████▋ | 1391/1605 [22:08<03:02,  1.17it/s] 87%|████████▋ | 1392/1605 [22:08<03:03,  1.16it/s] 87%|████████▋ | 1393/1605 [22:09<03:01,  1.17it/s] 87%|████████▋ | 1394/1605 [22:10<02:59,  1.18it/s] 87%|████████▋ | 1395/1605 [22:11<02:57,  1.18it/s] 87%|████████▋ | 1396/1605 [22:12<02:57,  1.18it/s] 87%|████████▋ | 1397/1605 [22:13<02:57,  1.17it/s] 87%|████████▋ | 1398/1605 [22:14<02:56,  1.17it/s] 87%|████████▋ | 1399/1605 [22:14<02:56,  1.17it/s] 87%|████████▋ | 1400/1605 [22:15<02:54,  1.17it/s] 87%|████████▋ | 1401/1605 [22:16<02:54,  1.17it/s] 87%|████████▋ | 1402/1605 [22:17<02:52,  1.18it/s] 87%|████████▋ | 1403/1605 [22:18<02:52,  1.17it/s] 87%|████████▋ | 1404/1605 [22:19<02:50,  1.18it/s] 88%|████████▊ | 1405/1605 [22:19<02:50,  1.17it/s] 88%|████████▊ | 1406/1605 [22:20<02:49,  1.17it/s] 88%|████████▊ | 1407/1605 [22:21<02:48,  1.18it/s] 88%|████████▊ | 1408/1605 [22:22<02:48,  1.17it/s] 88%|████████▊ | 1409/1605 [22:23<02:47,  1.17it/s] 88%|████████▊ | 1410/1605 [22:24<02:46,  1.17it/s] 88%|████████▊ | 1411/1605 [22:25<02:47,  1.16it/s] 88%|████████▊ | 1412/1605 [22:25<02:45,  1.17it/s] 88%|████████▊ | 1413/1605 [22:26<02:44,  1.16it/s] 88%|████████▊ | 1414/1605 [22:27<02:43,  1.17it/s] 88%|████████▊ | 1415/1605 [22:28<02:43,  1.16it/s] 88%|████████▊ | 1416/1605 [22:29<02:43,  1.16it/s] 88%|████████▊ | 1417/1605 [22:30<02:42,  1.16it/s] 88%|████████▊ | 1418/1605 [22:31<02:40,  1.17it/s] 88%|████████▊ | 1419/1605 [22:31<02:39,  1.17it/s] 88%|████████▊ | 1420/1605 [22:32<02:39,  1.16it/s] 89%|████████▊ | 1421/1605 [22:33<02:36,  1.17it/s] 89%|████████▊ | 1422/1605 [22:34<02:36,  1.17it/s] 89%|████████▊ | 1423/1605 [22:35<02:35,  1.17it/s] 89%|████████▊ | 1424/1605 [22:36<02:34,  1.17it/s] 89%|████████▉ | 1425/1605 [22:37<02:33,  1.17it/s] 89%|████████▉ | 1426/1605 [22:37<02:31,  1.18it/s] 89%|████████▉ | 1427/1605 [22:38<02:32,  1.17it/s] 89%|████████▉ | 1428/1605 [22:39<02:31,  1.17it/s] 89%|████████▉ | 1429/1605 [22:40<02:31,  1.16it/s] 89%|████████▉ | 1430/1605 [22:41<02:30,  1.16it/s] 89%|████████▉ | 1431/1605 [22:42<02:29,  1.17it/s] 89%|████████▉ | 1432/1605 [22:43<02:28,  1.16it/s] 89%|████████▉ | 1433/1605 [22:43<02:27,  1.17it/s] 89%|████████▉ | 1434/1605 [22:44<02:25,  1.17it/s] 89%|████████▉ | 1435/1605 [22:45<02:24,  1.18it/s] 89%|████████▉ | 1436/1605 [22:46<02:24,  1.17it/s] 90%|████████▉ | 1437/1605 [22:47<02:23,  1.17it/s] 90%|████████▉ | 1438/1605 [22:48<02:21,  1.18it/s] 90%|████████▉ | 1439/1605 [22:49<02:21,  1.17it/s] 90%|████████▉ | 1440/1605 [22:49<02:20,  1.17it/s] 90%|████████▉ | 1441/1605 [22:50<02:19,  1.17it/s] 90%|████████▉ | 1442/1605 [22:51<02:20,  1.16it/s] 90%|████████▉ | 1443/1605 [22:52<02:20,  1.15it/s] 90%|████████▉ | 1444/1605 [22:53<02:18,  1.16it/s] 90%|█████████ | 1445/1605 [22:54<02:17,  1.17it/s] 90%|█████████ | 1446/1605 [22:55<02:16,  1.17it/s] 90%|█████████ | 1447/1605 [22:55<02:15,  1.17it/s] 90%|█████████ | 1448/1605 [22:56<02:15,  1.16it/s] 90%|█████████ | 1449/1605 [22:57<02:13,  1.17it/s] 90%|█████████ | 1450/1605 [22:58<02:12,  1.17it/s] 90%|█████████ | 1451/1605 [22:59<02:12,  1.16it/s] 90%|█████████ | 1452/1605 [23:00<02:10,  1.17it/s] 91%|█████████ | 1453/1605 [23:01<02:09,  1.17it/s] 91%|█████████ | 1454/1605 [23:01<02:09,  1.17it/s] 91%|█████████ | 1455/1605 [23:02<02:08,  1.17it/s] 91%|█████████ | 1456/1605 [23:03<02:06,  1.18it/s] 91%|█████████ | 1457/1605 [23:04<02:06,  1.17it/s] 91%|█████████ | 1458/1605 [23:05<02:04,  1.18it/s] 91%|█████████ | 1459/1605 [23:06<02:03,  1.18it/s] 91%|█████████ | 1460/1605 [23:07<02:03,  1.17it/s] 91%|█████████ | 1461/1605 [23:07<02:04,  1.16it/s] 91%|█████████ | 1462/1605 [23:08<02:03,  1.16it/s] 91%|█████████ | 1463/1605 [23:09<02:02,  1.16it/s] 91%|█████████ | 1464/1605 [23:10<02:00,  1.17it/s] 91%|█████████▏| 1465/1605 [23:11<02:00,  1.16it/s] 91%|█████████▏| 1466/1605 [23:12<01:58,  1.17it/s] 91%|█████████▏| 1467/1605 [23:13<01:57,  1.17it/s] 91%|█████████▏| 1468/1605 [23:13<01:57,  1.17it/s] 92%|█████████▏| 1469/1605 [23:14<01:55,  1.18it/s] 92%|█████████▏| 1470/1605 [23:15<01:55,  1.17it/s] 92%|█████████▏| 1471/1605 [23:16<01:54,  1.17it/s] 92%|█████████▏| 1472/1605 [23:17<01:53,  1.17it/s] 92%|█████████▏| 1473/1605 [23:18<01:52,  1.17it/s] 92%|█████████▏| 1474/1605 [23:19<01:52,  1.17it/s] 92%|█████████▏| 1475/1605 [23:19<01:51,  1.17it/s] 92%|█████████▏| 1476/1605 [23:20<01:50,  1.17it/s] 92%|█████████▏| 1477/1605 [23:21<01:49,  1.17it/s] 92%|█████████▏| 1478/1605 [23:22<01:48,  1.17it/s] 92%|█████████▏| 1479/1605 [23:23<01:47,  1.17it/s] 92%|█████████▏| 1480/1605 [23:24<01:46,  1.18it/s] 92%|█████████▏| 1481/1605 [23:25<01:44,  1.18it/s] 92%|█████████▏| 1482/1605 [23:25<01:44,  1.17it/s] 92%|█████████▏| 1483/1605 [23:26<01:44,  1.17it/s] 92%|█████████▏| 1484/1605 [23:27<01:43,  1.17it/s] 93%|█████████▎| 1485/1605 [23:28<01:42,  1.18it/s] 93%|█████████▎| 1486/1605 [23:29<01:42,  1.16it/s] 93%|█████████▎| 1487/1605 [23:30<01:40,  1.17it/s] 93%|█████████▎| 1488/1605 [23:31<01:40,  1.17it/s] 93%|█████████▎| 1489/1605 [23:31<01:39,  1.17it/s] 93%|█████████▎| 1490/1605 [23:32<01:38,  1.16it/s] 93%|█████████▎| 1491/1605 [23:33<01:36,  1.18it/s] 93%|█████████▎| 1492/1605 [23:34<01:37,  1.16it/s] 93%|█████████▎| 1493/1605 [23:35<01:35,  1.17it/s] 93%|█████████▎| 1494/1605 [23:36<01:35,  1.16it/s] 93%|█████████{'loss': 0.5751, 'learning_rate': 3.2710280373831774e-06, 'epoch': 2.8}
| 1495/1605 [23:37<01:34,  1.17it/s] 93%|█████████▎| 1496/1605 [23:37<01:33,  1.17it/s] 93%|█████████▎| 1497/1605 [23:38<01:32,  1.16it/s] 93%|█████████▎| 1498/1605 [23:39<01:31,  1.17it/s] 93%|█████████▎| 1499/1605 [23:40<01:30,  1.17it/s] 93%|█████████▎| 1500/1605 [23:41<01:29,  1.18it/s]                                                    93%|█████████▎| 1500/1605 [23:41<01:29,  1.18it/s][INFO|trainer.py:2985] 2024-02-12 20:42:23,152 >> Saving model checkpoint to /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1500
[INFO|configuration_utils.py:473] 2024-02-12 20:42:23,166 >> Configuration saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1500/config.json
[INFO|modeling_utils.py:2462] 2024-02-12 20:42:46,698 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1500/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-02-12 20:42:46,700 >> tokenizer config file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-02-12 20:42:46,701 >> Special tokens file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tmp-checkpoint-1500/special_tokens_map.json
 94%|█████████▎| 1501/1605 [25:01<42:46, 24.68s/it] 94%|█████████▎| 1502/1605 [25:02<30:05, 17.53s/it] 94%|█████████▎| 1503/1605 [25:03<21:17, 12.53s/it] 94%|█████████▎| 1504/1605 [25:04<15:11,  9.02s/it] 94%|█████████▍| 1505/1605 [25:04<10:57,  6.58s/it] 94%|█████████▍| 1506/1605 [25:05<08:01,  4.86s/it] 94%|█████████▍| 1507/1605 [25:06<05:58,  3.66s/it] 94%|█████████▍| 1508/1605 [25:07<04:32,  2.81s/it] 94%|█████████▍| 1509/1605 [25:08<03:33,  2.23s/it] 94%|█████████▍| 1510/1605 [25:09<02:52,  1.82s/it] 94%|█████████▍| 1511/1605 [25:10<02:23,  1.53s/it] 94%|█████████▍| 1512/1605 [25:10<02:03,  1.32s/it] 94%|█████████▍| 1513/1605 [25:11<01:49,  1.19s/it] 94%|█████████▍| 1514/1605 [25:12<01:38,  1.08s/it] 94%|█████████▍| 1515/1605 [25:13<01:31,  1.01s/it] 94%|█████████▍| 1516/1605 [25:14<01:25,  1.04it/s] 95%|█████████▍| 1517/1605 [25:15<01:22,  1.07it/s] 95%|█████████▍| 1518/1605 [25:16<01:18,  1.10it/s] 95%|█████████▍| 1519/1605 [25:16<01:16,  1.13it/s] 95%|█████████▍| 1520/1605 [25:17<01:14,  1.13it/s] 95%|█████████▍| 1521/1605 [25:18<01:13,  1.14it/s] 95%|█████████▍| 1522/1605 [25:19<01:11,  1.16it/s] 95%|█████████▍| 1523/1605 [25:20<01:10,  1.16it/s] 95%|█████████▍| 1524/1605 [25:21<01:09,  1.16it/s] 95%|█████████▌| 1525/1605 [25:22<01:09,  1.16it/s] 95%|█████████▌| 1526/1605 [25:22<01:07,  1.17it/s] 95%|█████████▌| 1527/1605 [25:23<01:06,  1.17it/s] 95%|█████████▌| 1528/1605 [25:24<01:05,  1.17it/s] 95%|█████████▌| 1529/1605 [25:25<01:04,  1.18it/s] 95%|█████████▌| 1530/1605 [25:26<01:04,  1.17it/s] 95%|█████████▌| 1531/1605 [25:27<01:03,  1.17it/s] 95%|█████████▌| 1532/1605 [25:27<01:02,  1.17it/s] 96%|█████████▌| 1533/1605 [25:28<01:01,  1.17it/s] 96%|█████████▌| 1534/1605 [25:29<01:00,  1.17it/s] 96%|█████████▌| 1535/1605 [25:30<00:59,  1.17it/s] 96%|█████████▌| 1536/1605 [25:31<00:59,  1.17it/s] 96%|█████████▌| 1537/1605 [25:32<00:58,  1.17it/s] 96%|█████████▌| 1538/1605 [25:33<00:56,  1.18it/s] 96%|█████████▌| 1539/1605 [25:33<00:56,  1.17it/s] 96%|█████████▌| 1540/1605 [25:34<00:55,  1.17it/s] 96%|█████████▌| 1541/1605 [25:35<00:54,  1.17it/s] 96%|█████████▌| 1542/1605 [25:36<00:53,  1.18it/s] 96%|█████████▌| 1543/1605 [25:37<00:52,  1.17it/s] 96%|█████████▌| 1544/1605 [25:38<00:51,  1.18it/s] 96%|█████████▋| 1545/1605 [25:39<00:51,  1.17it/s] 96%|█████████▋| 1546/1605 [25:39<00:50,  1.17it/s] 96%|█████████▋| 1547/1605 [25:40<00:49,  1.17it/s] 96%|█████████▋| 1548/1605 [25:41<00:49,  1.16it/s] 97%|█████████▋| 1549/1605 [25:42<00:47,  1.17it/s] 97%|█████████▋| 1550/1605 [25:43<00:47,  1.17it/s] 97%|█████████▋| 1551/1605 [25:44<00:46,  1.17it/s] 97%|█████████▋| 1552/1605 [25:45<00:45,  1.17it/s] 97%|█████████▋| 1553/1605 [25:45<00:44,  1.16it/s] 97%|█████████▋| 1554/1605 [25:46<00:43,  1.16it/s] 97%|█████████▋| 1555/1605 [25:47<00:43,  1.16it/s] 97%|█████████▋| 1556/1605 [25:48<00:41,  1.17it/s] 97%|█████████▋| 1557/1605 [25:49<00:40,  1.17it/s] 97%|█████████▋| 1558/1605 [25:50<00:40,  1.17it/s] 97%|█████████▋| 1559/1605 [25:51<00:39,  1.17it/s] 97%|█████████▋| 1560/1605 [25:51<00:38,  1.18it/s] 97%|█████████▋| 1561/1605 [25:52<00:37,  1.18it/s] 97%|█████████▋| 1562/1605 [25:53<00:36,  1.17it/s] 97%|█████████▋| 1563/1605 [25:54<00:35,  1.17it/s] 97%|█████████▋| 1564/1605 [25:55<00:34,  1.17it/s] 98%|█████████▊| 1565/1605 [25:56<00:34,  1.17it/s] 98%|█████████▊| 1566/1605 [25:57<00:33,  1.17it/s] 98%|█████████▊| 1567/1605 [25:57<00:32,  1.18it/s] 98%|█████████▊| 1568/1605 [25:58<00:31,  1.18it/s] 98%|█████████▊| 1569/1605 [25:59<00:30,  1.17it/s] 98%|█████████▊| 1570/1605 [26:00<00:30,  1.16it/s] 98%|█████████▊| 1571/1605 [26:01<00:29,  1.17it/s] 98%|█████████▊| 1572/1605 [26:02<00:28,  1.16it/s] 98%|█████████▊| 1573/1605 [26:02<00:27,  1.17it/s] 98%|█████████▊| 1574/1605 [26:03<00:26,  1.17it/s] 98%|█████████▊| 1575/1605 [26:04<00:25,  1.17it/s] 98%|█████████▊| 1576/1605 [26:05<00:24,  1.16it/s] 98%|█████████▊| 1577/1605 [26:06<00:23,  1.17it/s] 98%|█████████▊| 1578/1605 [26:07<00:22,  1.17it/s] 98%|█████████▊| 1579/1605 [26:08<00:22,  1.18it/s] 98%|█████████▊| 1580/1605 [26:08<00:21,  1.17it/s] 99%|█████████▊| 1581/1605 [26:09<00:20,  1.17it/s] 99%|█████████▊| 1582/1605 [26:10<00:19,  1.17it/s] 99%|█████████▊| 1583/1605 [26:11<00:18,  1.17it/s] 99%|█████████▊| 1584/1605 [26:12<00:17,  1.17it/s] 99%|█████████▉| 1585/1605 [26:13<00:17,  1.17it/s] 99%|█████████▉| 1586/1605 [26:14<00:16,  1.17it/s] 99%|█████████▉| 1587/1605 [26:14<00:15,  1.17it/s] 99%|█████████▉| 1588/1605 [26:15<00:14,  1.17it/s] 99%|█████████▉| 1589/1605 [26:16<00:13,  1.17it/s] 99%|█████████▉| 1590/1605 [26:17<00:12,  1.18it/s] 99%|█████████▉| 1591/1605 [26:18<00:11,  1.17it/s] 99%|█████████▉| 1592/1605 [26:19<00:11,  1.17it/s] 99%|█████████▉| 1593/1605 [26:20<00:10,  1.17it/s] 99%|█████████▉| 1594/1605 [26:20<00:09,  1.17it/s] 99%|█████████▉| 1595/1605 [26:21<00:08,  1.17it/s] 99%|█████████▉| 1596/1605 [26:22<00:07,  1.17it/s]100%|█████████▉| 1597/1605 [26:23<00:06,  1.17it/s]100%|█████████▉| 1598/1605 [26:24<00:05,  1.17it/s]100%|█████████▉| 1599/1605 [26:25<00:05,  1.17it/s]100%|█████████▉| 1600/1605 [26:26<00:04,  1.17it/s]100%|█████████▉| 1601/1605 [26:26<00:03,  1.17it/s]100%|█████████▉| 1602/1605 [26:27<00:02,  1.17it/s]100%|█████████▉| 1603/1605 [26:28<00:01,  1.17it/s]100%|█████████▉| 1604/1605 [26:29<00:00,  1.17it/s]100%|██████████| 1605/1605 [26:30<00:00,  1.17it/s][INFO|trainer.py:1988] 2024-02-12 20:45:12,086 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


{'train_runtime': 1590.5187, 'train_samples_per_second': 16.129, 'train_steps_per_second': 1.009, 'train_loss': 0.6298493453646746, 'epoch': 3.0}
                                                   100%|██████████| 1605/1605 [26:30<00:00,  1.17it/s]100%|██████████| 1605/1605 [26:30<00:00,  1.01it/s]
[INFO|trainer.py:2985] 2024-02-12 20:45:12,220 >> Saving model checkpoint to /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola
[INFO|configuration_utils.py:473] 2024-02-12 20:45:12,241 >> Configuration saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/config.json
[INFO|modeling_utils.py:2462] 2024-02-12 20:45:33,046 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2435] 2024-02-12 20:45:33,048 >> tokenizer config file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/tokenizer_config.json
[INFO|tokenization_utils_base.py:2444] 2024-02-12 20:45:33,049 >> Special tokens file saved in /ocean/projects/cis220031p/mmisra/transformers/examples/pytorch/language-modeling/scripts/experiments/cola/special_tokens_map.json
***** train metrics *****
  epoch                    =        3.0
  train_loss               =     0.6298
  train_runtime            = 0:26:30.51
  train_samples            =       8551
  train_samples_per_second =     16.129
  train_steps_per_second   =      1.009
02/12/2024 20:45:33 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:737] 2024-02-12 20:45:33,112 >> The following columns in the evaluation set don't have a corresponding argument in `LlamaForSequenceClassification.forward` and have been ignored: idx, sentence. If idx, sentence are not expected by `LlamaForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3291] 2024-02-12 20:45:33,115 >> ***** Running Evaluation *****
[INFO|trainer.py:3293] 2024-02-12 20:45:33,115 >>   Num examples = 1043
[INFO|trainer.py:3296] 2024-02-12 20:45:33,115 >>   Batch size = 8
  0%|          | 0/66 [00:00<?, ?it/s]  3%|▎         | 2/66 [00:00<00:08,  7.97it/s]  5%|▍         | 3/66 [00:00<00:11,  5.51it/s]  6%|▌         | 4/66 [00:00<00:12,  4.90it/s]  8%|▊         | 5/66 [00:01<00:13,  4.40it/s]  9%|▉         | 6/66 [00:01<00:14,  4.21it/s] 11%|█         | 7/66 [00:01<00:14,  4.11it/s] 12%|█▏        | 8/66 [00:01<00:14,  4.12it/s] 14%|█▎        | 9/66 [00:02<00:14,  4.04it/s] 15%|█▌        | 10/66 [00:02<00:13,  4.01it/s] 17%|█▋        | 11/66 [00:02<00:13,  4.08it/s] 18%|█▊        | 12/66 [00:02<00:13,  4.06it/s] 20%|█▉        | 13/66 [00:03<00:13,  4.00it/s] 21%|██        | 14/66 [00:03<00:13,  3.90it/s] 23%|██▎       | 15/66 [00:03<00:13,  3.91it/s] 24%|██▍       | 16/66 [00:03<00:12,  4.01it/s] 26%|██▌       | 17/66 [00:04<00:12,  3.96it/s] 27%|██▋       | 18/66 [00:04<00:12,  3.92it/s] 29%|██▉       | 19/66 [00:04<00:12,  3.91it/s] 30%|███       | 20/66 [00:04<00:11,  4.01it/s] 32%|███▏      | 21/66 [00:05<00:11,  3.93it/s] 33%|███▎      | 22/66 [00:05<00:11,  3.91it/s] 35%|███▍      | 23/66 [00:05<00:11,  3.86it/s] 36%|███▋      | 24/66 [00:05<00:10,  3.87it/s] 38%|███▊      | 25/66 [00:06<00:10,  4.00it/s] 39%|███▉      | 26/66 [00:06<00:10,  3.89it/s] 41%|████      | 27/66 [00:06<00:09,  3.96it/s] 42%|████▏     | 28/66 [00:06<00:09,  3.95it/s] 44%|████▍     | 29/66 [00:07<00:09,  3.93it/s] 45%|████▌     | 30/66 [00:07<00:08,  4.03it/s] 47%|████▋     | 31/66 [00:07<00:08,  3.94it/s] 48%|████▊     | 32/66 [00:07<00:08,  3.93it/s] 50%|█████     | 33/66 [00:08<00:08,  4.04it/s] 52%|█████▏    | 34/66 [00:08<00:07,  4.05it/s] 53%|█████▎    | 35/66 [00:08<00:07,  4.01it/s] 55%|█████▍    | 36/66 [00:08<00:07,  4.04it/s] 56%|█████▌    | 37/66 [00:09<00:07,  3.99it/s] 58%|█████▊    | 38/66 [00:09<00:07,  3.96it/s] 59%|█████▉    | 39/66 [00:09<00:06,  3.94it/s] 61%|██████    | 40/66 [00:09<00:06,  3.99it/s] 62%|██████▏   | 41/66 [00:10<00:06,  3.88it/s] 64%|██████▎   | 42/66 [00:10<00:06,  3.91it/s] 65%|██████▌   | 43/66 [00:10<00:05,  4.02it/s] 67%|██████▋   | 44/66 [00:10<00:05,  3.92it/s] 68%|██████▊   | 45/66 [00:11<00:05,  3.96it/s] 70%|██████▉   | 46/66 [00:11<00:05,  4.00it/s] 71%|███████   | 47/66 [00:11<00:04,  3.95it/s] 73%|███████▎  | 48/66 [00:11<00:04,  3.85it/s] 74%|███████▍  | 49/66 [00:12<00:04,  3.98it/s] 76%|███████▌  | 50/66 [00:12<00:04,  3.89it/s] 77%|███████▋  | 51/66 [00:12<00:03,  3.96it/s] 79%|███████▉  | 52/66 [00:12<00:03,  3.96it/s] 80%|████████  | 53/66 [00:13<00:03,  4.00it/s] 82%|████████▏ | 54/66 [00:13<00:02,  4.04it/s] 83%|████████▎ | 55/66 [00:13<00:02,  4.01it/s] 85%|████████▍ | 56/66 [00:13<00:02,  3.96it/s] 86%|████████▋ | 57/66 [00:14<00:02,  4.01it/s] 88%|████████▊ | 58/66 [00:14<00:02,  3.97it/s] 89%|████████▉ | 59/66 [00:14<00:01,  3.96it/s] 91%|█████████ | 60/66 [00:14<00:01,  3.91it/s] 92%|█████████▏| 61/66 [00:15<00:01,  3.99it/s] 94%|█████████▍| 62/66 [00:15<00:01,  3.98it/s] 95%|█████████▌| 63/66 [00:15<00:00,  4.02it/s] 97%|█████████▋| 64/66 [00:15<00:00,  3.88it/s] 98%|█████████▊| 65/66 [00:16<00:00,  3.90it/s]100%|██████████| 66/66 [00:16<00:00,  3.96it/s]100%|██████████| 66/66 [00:16<00:00,  4.01it/s]
***** eval metrics *****
  epoch                     =        3.0
  eval_loss                 =     0.6246
  eval_matthews_correlation =     0.0991
  eval_runtime              = 0:00:16.70
  eval_samples              =       1043
  eval_samples_per_second   =     62.443
  eval_steps_per_second     =      3.951
